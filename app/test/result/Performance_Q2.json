{"result": [{"answers": [{"content": "=>The best way to concatinate string is using '+'.For eg:- =>The another easy way is by using\njoint method.For eg:-", "id": 76578940, "owner_tier": 0.1, "score": -6.289308137877542e-11}, {"content": "''.join(sequence_of_strings) is what usually works best \u2013 simplest and fastest.", "id": 1316891, "owner_tier": 0.9, "score": 0.47169811314465415}, {"content": "Update: Python3.11 has some optimizations for % formatting yet it maybe still better to stick with f-strings. For Python 3.8.6/3.9, I had to do some dirty hacks, because perfplot was giving out some errors. Here assume that x[0] is a a and x[1] is b:  The plot is nearly same for large data. For small data,  Taken by perfplot and this is the code, large data == range(8), small data == range(4). When medium data is there, and four strings are there x[0], x[1], x[2], x[3] instead of two strings:  Better to stick with f-strings. Also the speed of %s is similar to .format().", "id": 64527807, "owner_tier": 0.3, "score": 0.10062893075471697}, {"content": "Probably the \"new f-strings in Python 3.6\" is the most efficient way of concatenating strings. Using %s Using .format Using f-strings", "id": 50474424, "owner_tier": 0.9, "score": 0.03773584899371069}, {"content": "As per John Fouhy's answer, don't optimize unless you have to, but if you're here and asking this question, it may be precisely because you have to. In my case, I needed to assemble some URLs from string variables... fast. I noticed no one (so far) seems to be considering the string format method, so I thought I'd try that and, mostly for mild interest, I thought I'd toss the string interpolation operator in there for good measure. To be honest, I didn't think either of these would stack up to a direct '+' operation or a ''.join(). But guess what? On my Python 2.7.5 system, the string interpolation operator rules them all and string.format() is the worst performer: The results: If I use a shorter domain and shorter path, interpolation still wins out. The difference is more pronounced, though, with longer strings. Now that I had a nice test script, I also tested under Python 2.6, 3.3 and 3.4, here's the results. In Python 2.6, the plus operator is the fastest! On Python 3, join wins out. Note: these tests are very repeatable on my system. So, 'plus' is always faster on 2.6, 'intp' is always faster on 2.7 and 'join' is always faster on Python 3.x. Lesson learned: tl;dr:", "id": 24718551, "owner_tier": 0.5, "score": 0.20754716974842766}, {"content": "One year later, let's test mkoistinen's answer with Python\u00a03.4.3: Nothing changed. join is still the fastest method. With string interpolation (intp) being arguably the best choice in terms of readability, you might want to use string interpolation nevertheless.", "id": 33981580, "owner_tier": 0.1, "score": 0.03773584899371069}, {"content": "If you know all components beforehand once, use the literal string interpolation, also known as f-strings or formatted strings, introduced in Python 3.6. Given the test case from mkoistinen's answer, having strings The contenders and their execution time on my computer using Python 3.6 on Linux as timed by IPython and the timeit module are f'http://{domain}/{lang}/{path}' - 0.151 \u00b5s 'http://%s/%s/%s' % (domain, lang, path) - 0.321 \u00b5s 'http://' + domain + '/' + lang + '/' + path - 0.356 \u00b5s ''.join(('http://', domain, '/', lang, '/', path)) - 0.249 \u00b5s (notice that building a constant-length tuple is slightly faster than building a constant-length list). Thus the shortest and the most beautiful code possible is also fastest. The speed can be contrasted with the fastest method for Python 2, which is + concatenation on my computer; and that takes 0.203 \u00b5s with 8-bit strings, and 0.259 \u00b5s if the strings are all Unicode. (In alpha versions of Python 3.6 the implementation of f'' strings was the slowest possible - actually the generated byte code is pretty much equivalent to the ''.join() case with unnecessary calls to str.__format__ which without arguments would just return self unchanged. These inefficiencies were addressed before 3.6 final.)", "id": 38362140, "owner_tier": 0.9, "score": 0.8301886791823899}, {"content": "I ran into a situation where I needed to have an appendable string of unknown size.  These are the benchmark results (python 2.7.3): This seems to show that '+=' is the fastest.  The results from the skymind link are a bit out of date. (I realize that the second example is not complete. The final list would need to be joined.  This does show, however, that simply preparing the list takes longer than the string concatenation.)", "id": 12321184, "owner_tier": 0.5, "score": 0.04402515716981132}, {"content": "It pretty much depends on the relative sizes of the new string after every new concatenation. With the + operator, for every concatenation, a new string is made. If the intermediary strings are relatively long, the + becomes increasingly slower, because the new intermediary string is being stored. Consider this case: Results 1 0.00493192672729 2 0.000509023666382 3 0.00042200088501 4 0.000482797622681 In the case of 1&2, we add a large string, and join() performs about 10 times faster.\nIn case 3&4, we add a small string, and '+' performs slightly faster.", "id": 22356177, "owner_tier": 0.1, "score": 0.09433962257861635}, {"content": "Inspired by JasonBaker's benchmarks, here's a simple one, comparing 10 \"abcdefghijklmnopqrstuvxyz\" strings, showing that .join() is faster; even with this tiny increase in variables:", "id": 14610440, "owner_tier": 0.5, "score": 0.031446540817610065}, {"content": "You may be interested in this: An optimization anecdote by Guido.  Although it is worth remembering also that this is an old article and it predates the existence of things like ''.join (although I guess string.joinfields is more-or-less the same) On the strength of that, the array module may be fastest if you can shoehorn your problem into it.  But ''.join is probably fast enough and has the benefit of being idiomatic and thus easier for other Python programmers to understand. Finally, the golden rule of optimization: don't optimize unless you know you need to, and measure rather than guessing. You can measure different methods using the timeit module. That can tell you which is fastest, instead of random strangers on the Internet making guesses.", "id": 1316959, "owner_tier": 0.9, "score": 0.9999999999371069}, {"content": "For a small set of short strings (i.e. 2 or 3 strings of no more than a few characters), plus is still way faster. Using mkoistinen's wonderful script in Python 2 and 3: So when your code is doing a huge number of separate small concatenations, plus is the preferred way if speed is crucial.", "id": 42001410, "owner_tier": 0.1, "score": 0.031446540817610065}, {"content": "It depends on what you're doing. After Python 2.5, string concatenation with the + operator is pretty fast. If you're just concatenating a couple of values, using the + operator works best: However, if you're putting together a string in a loop, you're better off using the list joining method: ...but notice that you have to be putting together a relatively high number of strings before the difference becomes noticeable.", "id": 1316982, "owner_tier": 0.9, "score": 0.28930817603773584}], "link": "https://stackoverflow.com/questions/1316887/what-is-the-most-efficient-string-concatenation-method-in-python", "question": {"content": "Is there an efficient mass string concatenation method in Python (like StringBuilder in C# or StringBuffer in Java)? I found following methods here: What should be used and why? (A related question is here.)", "id": 1316887, "title": "What is the most efficient string concatenation method in Python?", "traffic_rate": 36}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "string"]}, {"answers": [{"content": "Let's try it out! We can use timeit.timeit() to run a statement many times and return the overall duration. Here, we use s to setup the variables a and b (not included in the overall time), and then run the various options 10 million times. This shows that unless your application's bottleneck is string concatenation, it's probably not worth being too concerned about... Depending on the performance of your system, you might see a speed improvement in the order of a few seconds if you're performing literally millions of operations. Note that your results may vary quite drastically depending on the lengths (and number) of the strings you're concatenating, and the hardware you're running on.", "id": 61392407, "owner_tier": 0.5, "score": 0.9999999988888888}, {"content": "For exactly two strings a and b, just use a + b. The alternatives are for joining more than 2 strings, avoiding the temporary str object created by each use of +, as well as the quadratic behavior due to repeatedly copying the contents of earlier operations in the next result. (There's also f'{a}{b}', but it's syntactically  heavier and no faster than a + b.)", "id": 61392334, "owner_tier": 0.9, "score": 0.7777777766666667}, {"content": "Looks like .join() and .format() are basically the same and 4x faster. An F string, eg: is also a very quick and clean method, especially when working with more complex formats. ", "id": 61392417, "owner_tier": 0.5, "score": -1.111111111111111e-09}], "link": "https://stackoverflow.com/questions/61392258/most-efficient-method-to-concatenate-strings-in-python", "question": {"content": "At the time of asking this question, I'm using Python 3.8 When I say efficient, I'm only referring to the speed at which the strings are concatenated, or in more technical terms: I'm asking about the time complexity, not accounting the space complexity. The only methods I can think of at the moment are the following 3 given that: Method 1 result = a + b Method 2 result = ''.join((a, b)) Method 3 result = '{0}{1}'.format(a, b) I want to know which of these methods are faster, or if there are other methods that are more efficient. Also, if you know if either of these methods performs differently with more strings or longer strings, please include that in your answer. Edit After seeing all the comments and answers, I have learned a couple of new ways to concatenate strings, and I have also learned about the timeit library. I will report my personal findings below: It seems that for these small strings, the traditional a + b method is the fastest for string concatenation. Thanks for all of the answers!", "id": 61392258, "title": "Most Efficient Method to Concatenate Strings in Python", "traffic_rate": 8}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "string", "performance"]}, {"answers": [{"content": "Using in place string concatenation by '+' is THE WORST method of concatenation in terms of stability and cross implementation as it does not support all values. PEP8 standard discourages this and encourages the use of format(), join() and append() for long term use.  As quoted from the linked \"Programming Recommendations\" section: For example, do not rely on CPython's efficient implementation of in-place string concatenation for statements in the form a += b or a = a + b. This optimization is fragile even in CPython (it only works for some types) and isn't present at all in implementations that don't use refcounting. In performance sensitive parts of the library, the ''.join() form should be used instead. This will ensure that concatenation occurs in linear time across various implementations.", "id": 24759826, "owner_tier": 0.3, "score": 0.04065040648373983}, {"content": "You can do in different ways. I created this little summary through following articles.", "id": 56735266, "owner_tier": 0.5, "score": 0.018292682906504064}, {"content": "In Python >= 3.6, the new f-string is an efficient way to concatenate a string.", "id": 50474513, "owner_tier": 0.9, "score": 0.10772357721544715}, {"content": "As @jdi mentions Python documentation suggests to use str.join or io.StringIO for string concatenation. And says that a developer should expect quadratic time from += in a loop, even though there's an optimisation since Python 2.4. As this answer says: If Python detects that the left argument has no other references, it calls realloc to attempt to avoid a copy by resizing the string in place. This is not something you should ever rely on, because it's an implementation detail and because if realloc ends up needing to move the string frequently, performance degrades to O(n^2) anyway. I will show an example of real-world code that naively relied on += this optimisation, but it didn't apply. The code below converts an iterable of short strings into bigger chunks to be used in a bulk API. This code can literary run for hours because of quadratic time complexity. Below are alternatives with suggested data structures: And a micro-benchmark: ", "id": 52561012, "owner_tier": 0.7, "score": 0.010162601605691057}, {"content": "my use case was slight different. I had to construct a query where more then 20 fields were dynamic.\nI followed this approach of using format method this was comparatively simpler for me instead of using + or other ways", "id": 50083131, "owner_tier": 0.5, "score": 0.002032520304878049}, {"content": "You write this function Then you can call simply wherever you want", "id": 45116101, "owner_tier": 0.5, "score": 0.01422764225609756}, {"content": "The best way of appending a string to a string variable is to use + or +=. This is because it's readable and fast. They are also just as fast, which one you choose is a matter of taste, the latter one is the most common. Here are timings with the timeit module: However, those who recommend having lists and appending to them and then joining those lists, do so because appending a string to a list is presumably very fast compared to extending a string. And this can be true, in some cases. Here, for example, is one\nmillion appends of a one-character string, first to a string, then to a list: OK, turns out that even when the resulting string is a million characters long, appending was still faster. Now let's try with appending a thousand character long string a hundred thousand times: The end string, therefore, ends up being about 100MB long. That was pretty slow, appending to a list was much faster. That that timing doesn't include the final a.join(). So how long would that take?  Oups. Turns out even in this case, append/join is slower. So where does this recommendation come from? Python 2? Well, append/join is marginally faster there if you are using extremely long strings (which you usually aren't, what would you have a string that's 100MB in memory?) But the real clincher is Python 2.3. Where I won't even show you the timings, because it's so slow that it hasn't finished yet. These tests suddenly take minutes. Except for the append/join, which is just as fast as under later Pythons. Yup. String concatenation was very slow in Python back in the stone age. But on 2.4 it isn't anymore (or at least Python 2.4.7), so the recommendation to use append/join became outdated in 2008, when Python 2.3 stopped being updated, and you should have stopped using it. :-) (Update: Turns out when I did the testing more carefully that using + and += is faster for two strings on Python 2.3 as well. The recommendation to use ''.join() must be a misunderstanding) However, this is CPython. Other implementations may have other concerns. And this is just yet another reason why premature optimization is the root of all evil. Don't use a technique that's supposed \"faster\" unless you first measure it. Therefore the \"best\" version to do string concatenation is to use + or +=. And if that turns out to be slow for you, which is pretty unlikely, then do something else. So why do I use a lot of append/join in my code? Because sometimes it's actually clearer. Especially when whatever you should concatenate together should be separated by spaces or commas or newlines.", "id": 12171382, "owner_tier": 0.9, "score": 0.9999999999796748}, {"content": "If the strings you are concatenating are literals, use String literal concatenation This is useful if you want to comment on part of a string (as above) or if you want to use raw strings or triple quotes for part of a literal but not all. Since this happens at the syntax layer it uses zero concatenation operators.", "id": 38806886, "owner_tier": 0.3, "score": 0.010162601605691057}, {"content": "You can use this(more efficient) too. (https://softwareengineering.stackexchange.com/questions/304445/why-is-s-better-than-for-concatenation)", "id": 38008202, "owner_tier": 0.9, "score": -2.032520312850669e-11}, {"content": "If you are concatenating a lot of values, then neither. Appending a list is expensive. You can use StringIO for that. Especially if you are building it up over a lot of operations. If you already have a complete list returned to you from some other operation, then just use the ''.join(aList) From the python FAQ: What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many\n  strings together is inefficient as each concatenation creates a new\n  object. In the general case, the total runtime cost is quadratic in\n  the total string length. To accumulate many str objects, the recommended idiom is to place them\n  into a list and call str.join() at the end: (another reasonably efficient idiom is to use io.StringIO) To accumulate many bytes objects, the recommended idiom is to extend a\n  bytearray object using in-place concatenation (the += operator): Edit: I was silly and had the results pasted backwards, making it look like appending to a list was faster than cStringIO. I have also added tests for bytearray/str concat, as well as a second round of tests using a larger list with larger strings. (python 2.7.3) ipython test example for large lists of strings", "id": 12169859, "owner_tier": 0.9, "score": 0.10975609754065041}, {"content": "While somewhat dated, Code Like a Pythonista: Idiomatic Python recommends join() over + in this section. As does PythonSpeedPerformanceTips in its section on string concatenation, with the following disclaimer: The accuracy of this section is disputed with respect to later\n  versions of Python. In CPython 2.5, string concatenation is fairly\n  fast, although this may not apply likewise to other Python\n  implementations. See ConcatenationTestCode for a discussion.", "id": 12169922, "owner_tier": 0.9, "score": 0.004065040630081301}, {"content": "The recommended method is still to use append and join.", "id": 12169856, "owner_tier": 0.7, "score": 0.008130081280487806}], "link": "https://stackoverflow.com/questions/12169839/which-is-the-preferred-way-to-concatenate-a-string-in-python", "question": {"content": "Since Python's string can't be changed, I was wondering how to concatenate a string more efficiently? I can write like it: or like this: While writing this question, I found a good article talking about the topic. http://www.skymind.com/~ocrow/python_string/ But it's in Python 2.x., so the question would be did something change in Python 3?", "id": 12169839, "title": "Which is the preferred way to concatenate a string in Python?", "traffic_rate": 210}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "python-3.x", "string", "concatenation"]}, {"answers": [{"content": "Of course it's join. How do I know?  Let's do it in a really stupid way:\nIf the problem was only adding 2 strings, you'd most likely use str1 + str2. What does it take to get that to the next level? Instinctively, for most (I think), will be to use sum. Let's see how that goes: Wow! Python simply told me what to use! :)", "id": 2134393, "owner_tier": 0.9, "score": 0.20588235279411762}, {"content": "There is a great answer from SilentGhost, but just a few words about the presented reduce \"alternative\": Unless you've got a very very very good reason to concatenate strings using + or operator.add (the most frequent one, that you've got few, fixed number of strings), you should use always join. Just because each + generates a new string which is the concatenation of two strings, unlike join that only generates one final string. So, imagine you've got three strings: Ok, it doesn't seems not much, but you've got to reserve memory for D. Also, due Python's use of strings, generating a new, intermediate, string, it's somehow expensive... Now, with five strings, Assuming the best scenario (if we do (A+B) + (C+D) + E, we'll end having three intermediate strings at the same time on memory), and that's generating three intermediate strings... You've got to generate a new Python object, reserve memory space, and release the memory a few times... Also there is the overhead of calling a Python function (that is not small). Now think of it with 200 strings. We'll end up with a ridiculous big number of intermediate strings, each of which is consuming combining quite a lot of time on being a complete list over Python , and calling a lot of operator.add functions, each with its overhead... Even if you use reduce functions, it won't help. It's a problem that has to be managed with a different approach: join, which only generates one complete Python string, the final one and calls one Python function. (Of course, join, or other similar, specialized function for arrays.)", "id": 2134386, "owner_tier": 0.5, "score": -1.4705882263566603e-10}, {"content": "I myself use the \"join\" way, but from Python\u00a02.6 there is a base type that is little used: bytearray. Bytearrays can be incredible useful -- for string containing texts, since the best thing is to have then in Unicode, the \"join\" way is the way to go -- but if you are dealing with binary data instead, bytearrays can be both more Pythonic and more efficient: It is a built-in data type: no imports needed - just use then -- and you can use a bytearray instead of a list to start with - so they should be more efficient than the \"join\", since there isn\u2019t any data copying to get the string representation for a bytearray.", "id": 2133872, "owner_tier": 0.9, "score": 0.02941176455882353}, {"content": "Have a look at Guido's essay on Python optimization. It covers converting lists of numbers to strings. Unless you have a good reason to do otherwise, use the join example.", "id": 2133605, "owner_tier": 0.5, "score": 0.5294117645588235}, {"content": "The only Pythonic way:", "id": 2133580, "owner_tier": 0.9, "score": 0.9999999998529413}, {"content": "Here's the least Pythonic way:", "id": 2133625, "owner_tier": 0.5, "score": 0.07352941161764706}], "link": "https://stackoverflow.com/questions/2133571/most-pythonic-way-to-concatenate-strings", "question": {"content": "Given this harmless little list: My goal is to Pythonically concatenate the little devils using one of the following ways: A. A plain old string function to get the job done, short, no imports B. Lambda, lambda, lambda C. Globalization (do nothing, import everything) What are other Pythonic ways to achieve this magnanimous task? Please rank (Pythonic level) and rate solutions giving concise explanations. In this case, is the most pythonic solution the best coding solution?", "id": 2133571, "title": "Most Pythonic way to concatenate strings", "traffic_rate": 9}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "concatenation"]}, {"answers": [{"content": "If the number of string is small and strings are known in advance, I would go : Using f-strings. However, this is valid only since python 3.6.", "id": 67470215, "owner_tier": 0.1, "score": -9.433962206816312e-11}, {"content": "It's reasonable to assume that it isn't bad practice for this example because: Concatenation of strings have the disadvantage of needing to create a new string and allocate new memory for every concatenation! This is time consuming, but isn't that big of a deal with few and small strings. When you know the number of strings to concatenate and don't need more than maybe 2-4 concatenations I'd go for it. When joining strings Python only has to allocate new memory for the final string, which is much more efficient, but could take longer to compute. Also, because strings are immutable it's often more practical to use a list of strings to dynamically mutate, and only convert it to a string when needed. It's often convenient to create strings with str.join() since it takes an iterable. For example: In most cases it makes more sense to use str.join() but there are times when concatenation is just as viable. Using any form of string concatenation for huge or many strings would be bad practice just as using str.join() would be bad practice for short and few strings, in my own opinion. I believe that the author was just trying to create a rule of thumb to easier identify when to use what without going in too much detail or make it complicated.", "id": 39680089, "owner_tier": 0.5, "score": 0.9999999999056605}], "link": "https://stackoverflow.com/questions/39675898/is-python-string-concatenation-bad-practice", "question": {"content": "I am reading The Hitchhiker\u2019s Guide to Python and there is a short code snippet  The author pointed out that ''.join() is not always faster than +, so he is not against using + for string concatenation.  But why is foo += 'ooo' bad practice whereas foobar=foo+bar is considered good?  Before this code snippet, the author wrote: One final thing to mention about strings is that using join() is not always best. In the instances where you are creating a new string from a pre-determined number of strings, using the addition operator is actually faster, but in cases like above or in cases where you are adding to an existing string, using join() should be your preferred method.", "id": 39675898, "title": "Is python += string concatenation bad practice?", "traffic_rate": 68}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "string", "string-concatenation"]}, {"answers": [{"content": "Method 1: a += b Method 2: a + b Method 3: ''.join((a, b)) Method 4: '{0}{1}'.format(a, b) Method 5: f'{a}{b}' Method 6: '%s%s' % (a, b) We can utilize the timeit library to test each method. With this example code, we run each method 10000 times and return the average time it takes. As you can see, Method 2, a + b is the fastest concatenation method.", "id": 64980767, "owner_tier": 0.3, "score": 0.999999995}], "link": "https://stackoverflow.com/questions/64980766/fastest-way-to-concatenate-two-strings-in-python", "question": {"content": "Given two arbitrary strings: When concatenated they produce 'start end' What is the fastest way to concatenate the two strings?", "id": 64980766, "title": "Fastest Way to Concatenate Two Strings in Python", "traffic_rate": 2843}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "python-3.x", "string", "performance"]}, {"answers": [{"content": "I use the following with python 3.8", "id": 61291323, "owner_tier": 0.5, "score": 0.015267175496183207}, {"content": "According to Python docs, using str.join() will give you performance consistence across various implementations of Python. Although CPython optimizes away the quadratic behavior of s = s + t, other Python implementations may not. CPython implementation detail: If s and t are both strings, some\n  Python implementations such as CPython can usually perform an in-place\n  optimization for assignments of the form s = s + t or s += t. When\n  applicable, this optimization makes quadratic run-time much less\n  likely. This optimization is both version and implementation\n  dependent. For performance sensitive code, it is preferable to use the\n  str.join() method which assures consistent linear concatenation\n  performance across versions and implementations. Sequence Types in Python docs (see the foot note [6])", "id": 41464254, "owner_tier": 0.5, "score": 0.022900763282442747}, {"content": "''.join([a, b]) is better solution than +. Because Code should be written in a way that does not disadvantage other implementations of Python (PyPy, Jython, IronPython, Cython, Psyco, and such) form a += b or a = a + b is fragile even in CPython and isn't present at all in implementations that don't use refcounting (reference counting is a technique of storing the number of references, pointers, or handles to a resource such as an object, block of memory, disk space or other resource) https://www.python.org/dev/peps/pep-0008/#programming-recommendations", "id": 36938478, "owner_tier": 0.3, "score": -7.633587739866634e-11}, {"content": "There is nothing wrong in concatenating two strings with +. Indeed it's easier to read than ''.join([a, b]). You are right though that concatenating more than 2 strings with + is an O(n^2) operation (compared to O(n) for join) and thus becomes inefficient. However this has not to do with using a loop. Even a + b + c + ... is O(n^2), the reason being that each concatenation produces a new string. CPython2.4 and above try to mitigate that, but it's still advisable to use join when concatenating more than 2 strings.", "id": 10043957, "owner_tier": 0.5, "score": 0.9999999999236641}, {"content": "Plus operator is perfectly fine solution to concatenate two Python strings. But if you keep adding more than two strings (n > 25) , you might want to think something else. ''.join([a, b, c]) trick is a performance optimization. ", "id": 10043677, "owner_tier": 0.9, "score": 0.38167938923664124}, {"content": "When working with multiple people, it's sometimes difficult to know exactly what's happening.  Using a format string instead of concatenation can avoid one particular annoyance that's happened a whole ton of times to us: Say, a function requires an argument, and you write it expecting to get a string: So, this function may be used pretty often throughout the code.  Your coworkers may know exactly what it does, but not necessarily be fully up-to-speed on the internals, and may not know that the function expects a string.  And so they may end up with this: There would be no problem if you just used a format string: The same is true for all types of objects that define __str__, which may be passed in as well: So yes:  If you can use a format string do it and take advantage of what Python has to offer.", "id": 10044897, "owner_tier": 0.5, "score": 0.05343511442748092}, {"content": "I have done a quick test: and timed it: There is apparently an optimisation for the a = a + b case.  It does not exhibit O(n^2) time as one might suspect. So at least in terms of performance, using + is fine.", "id": 10044139, "owner_tier": 0.5, "score": 0.015267175496183207}, {"content": "The assumption that one should never, ever use + for string concatenation, but instead always use ''.join may be a myth. It is true that using + creates unnecessary temporary copies of immutable string object but the other not oft quoted fact is that calling join in a loop would generally add the overhead of function call. Lets take your example. Create two lists, one from the linked SO question and another a bigger fabricated Lets create two functions, UseJoin and UsePlus to use the respective join and + functionality. Lets run timeit with the first list They have almost the same runtime. Lets use cProfile And it looks that using Join, results in unnecessary function calls which could add to the overhead. Now coming back to the question. Should one discourage the use of + over join in all cases? I believe no, things should be taken into consideration And off-course in a development pre-mature optimization is evil. ", "id": 10044103, "owner_tier": 0.9, "score": 0.06106870221374046}], "link": "https://stackoverflow.com/questions/10043636/any-reason-not-to-use-to-concatenate-two-strings", "question": {"content": "A common antipattern in Python is to concatenate a sequence of strings using + in a loop. This is bad because the Python interpreter has to create a new string object for each iteration, and it ends up taking quadratic time. (Recent versions of CPython can apparently optimize this in some cases, but other implementations can't, so programmers are discouraged from relying on this.) ''.join is the right way to do this. However, I've heard it said (including here on Stack Overflow) that you should never, ever use + for string concatenation, but instead always use ''.join or a format string. I don't understand why this is the case if you're only concatenating two strings. If my understanding is correct, it shouldn't take quadratic time, and I think a + b is cleaner and more readable than either ''.join((a, b)) or '%s%s' % (a, b). Is it good practice to use + to concatenate two strings? Or is there a problem I'm not aware of?", "id": 10043636, "title": "Any reason not to use &#39;+&#39; to concatenate two strings?", "traffic_rate": 70}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "string-concatenation", "anti-patterns"]}, {"answers": [{"content": "When you use the triple quote string you do not have to indent: You can also join strings automatically by using parenthesis: because python will concatenate consecutive strings in one expression together automatically (see String literal concatenation). You are still free to use + signs to concatenate the strings explicitly, but do use parenthesis to make it one expression: The alternative would be to use a backslash before the end of the line: but I find using parentheses and string literal concatenation to be more readable.", "id": 14588930, "owner_tier": 0.9, "score": 0.9999999995238095}, {"content": "Several ways to do this, when you have multiple strings with nothing but whitespace between them, the compiler creates a single string from them, as already said.  You can also use \\ to escape the end of line, like so. or The downside to this is you must remember the \\ on every line.  As a general rule, using + to join many strings together is a bad idea, because it makes a copy of the string for every + it finds, because strings are immutable, which makes it take a long time.  Instead consider using str.join, like this. Note that this has the added advantage that you can replace the \" \" with some other separator depending on what you are doing (newline or no character).", "id": 14589116, "owner_tier": 0.5, "score": -4.761904761904762e-10}, {"content": "textwrap.dedent will clean up those leading spaces, without messing up your source indentation.", "id": 14591923, "owner_tier": 0.9, "score": -4.761904761904762e-10}], "link": "https://stackoverflow.com/questions/14588851/string-concatenation-putting-large-chuck-of-text-in-python-code", "question": {"content": "Suppose I have a large chunk of text, say  The third and final rotation of Himalayan Pilgrimage explores the\n  theme of Sacred Space with a pair of magnificent large mandala\n  paintings, two-dimensional representations of a three-dimensional\n  architectural space where a specific deity resides. Dating to the\n  fourteenth and sixteenth centuries, these paintings represent, in\n  vivid colors, a cosmology of the deity Hevajra. Several other\n  paintings on view depict historic teachers of various Tibetan orders. In Java I can write it as In Python, however, if I do the same, I get complaints about the plus signs +. If instead I use ''' I get a bunch of leading white spaces due to indentation (indentation so the code is easy to read). Does anyone know the solution to this problem: how to paste a big chuck of text into Python code without incurring white spaces? The answer I am looking for is not: put the whole text on one line Again, I need to add text that span more than one line without incurring additional white space.", "id": 14588851, "title": "String Concatenation: Putting large chuck of text in Python code", "traffic_rate": 11}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "string", "python-2.7"]}, {"answers": [{"content": "For a while now, CPython has had an optimization that tries to perform string concatenation in place where possible. The details vary between Python versions, sometimes a lot - for example, it doesn't work for globals on Python 3.11, and it used to be specific to bytestrings on Python 2, but it's specific to Unicode strings on Python 3. On Python 3.10, the optimization starts in unicode_concatenate, and it eventually hits a PyObject_Realloc inside resize_compact or resize_inplace, attempting to resize the left-hand operand in place. One fairly consistent thing about the optimization across Python versions is that it only works if the left-hand side of the concatenation has no other references, or if the only reference is a variable that the result of the concatenation will be assigned to. In your slow case: the LHS of initial_string + 'x' is initial_string, and you're not going to assign the result back to initial_string - you're going to concatenate 'y' to the result first. Thus, the optimization can't kick in for initial_string + 'x'. (It kicks in for the + 'y' part, though.) For your other cases, the optimization works. For example, in instead of concatenating initial_string and 'x' and then appending 'y', you concatenate 'x' and 'y' and then concatenate initial_string and the result. The changed order of operations means that you're assigning the result of the initial_string concatenation back to initial_string, so the optimization applies. (Also the 'x' + 'y' gets constant-folded away, which helps a little but isn't the primary cause of the performance difference.)", "id": 75774779, "owner_tier": 0.9, "score": 0.9999999983333333}, {"content": "Using the dis module, you can see what happens: (Note that this is on CPython 3.9. On 3.11 the bytecode is different, although the speed on my machine is similar.) In the case of code_2, the x and y constants are folded, and one INPLACE_ADD is used instead of two BINARY_ADD opcodes. So basically, four bytecodes are replaced by two. In your second block of code, the dis output is almost identical, except for one BINARY_ADD/INPLACE_ADD.", "id": 75774555, "owner_tier": 0.9, "score": -1.6666666666666667e-09}], "link": "https://stackoverflow.com/questions/75774350/special-case-when-for-string-concatenation-is-more-efficient-than", "question": {"content": "I have this code using python 3.11: Why += is more efficient in this case?\nAs far as I know, there is the same number of concatenation, and the order of execution doesn't change the result. Since strings are immutable, it's not because of inplace shinanigans, and the only thing I found about string concat is about .join efficiency, but I don't want the most efficient, just understand why += seems more efficient than =. With this code, performances between forms almost equals: I noticed a difference using different Python version ('x' + 'y' form): Python 3.7 to 3.9: Python 3.10: Python 3.11 for comparison: Similar but not answering the question: How is the s=s+c string concat optimization decided? If s is a string, then s = s + 'c' might modify the string in place, while t = s + 'c' can't. But how does the operation s + 'c' know which scenario it's in? In a nutshell: Optimization occur when s = s + 'c', not when t = s + 'c' because python need to keep a ref to the first string and can't concatenate in-place. Here, we are always assigning using simple assignment or augmented assignment to the original string, so in-place concatenation should apply in both cases.", "id": 75774350, "title": "Special case when += for string concatenation is more efficient than =", "traffic_rate": 301}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python", "string", "concatenation", "string-concatenation", "python-3.11"]}, {"answers": [{"content": "join() has a definition str.join(iterable) where iterable is a generator or a list or a set and so on. So it is helpful if you already have a list of strings read from the files and you are concatenating them using join.\n For example You can get all lines in a file using join like ''.join(readlines(f)) Now you can accomplish your task using join as follows using fileinput module Refer to this answer to know the most efficient way to concat files into a string. Suggestion: As you mentioned there would be millions of lines, did you consider the memory it is going to consume to store it in a variable? So it is better you do what you are planning to do on the fly while reading the lines instead of storing it in a variable.", "id": 53236869, "owner_tier": 0.1, "score": 0.0}], "link": "https://stackoverflow.com/questions/53236784/efficient-string-concatenation-in-python-3", "question": {"content": "I am writing a Python 3 code where the task is to open about 550 files in a directory, read their contents and append it to a string variable 'all_text' which will be say around millions of line long as a single line. The inefficient code I was using till now is as follows- But then I read that using 'join()' method is efficient, so I tried the following code- The problem with this code is that this is removing the previously held contents of 'all_text' variable and writing the current file's content only! How do I get around this problem? Thanks for your help!", "id": 53236784, "title": "Efficient string concatenation in Python 3", "traffic_rate": 5719}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "stackoverflow", "tags": ["python"]}, {"answers": [{"content": "Use an array of strings, push to append and then use join to get the final result. Effectively the same as a string builder\n\nIt's often faster just to do the string concatenation yourself instead of iterating thru everything calling array appends and then using join. Join just iterates over all the strings to do the string concatenation that could have been done the first pass. Unless you're doing some advanced logic that necessitates using an array, you're really just doing more work for no reason\n\nMight not be noticable for small inputs, but it will definitely add up. I thought using an array->join in a parser I was working on recently might speed things up, but the performance hit was shocking\n\nif you use concatenation you will create intermediate strings for each concatenation step, if you use join only 1 string will be allocated for the concatenation process although the number of strings has to be quite large for the difference to even be measurable. I found that the difference gets up to 4x faster for join vs += after 100 million concatenations\n\nCare to point out what's wrong with the benchmark I created a few months ago then?\n\n[https://jsperf.app/cisila/1/preview](https://jsperf.app/cisila/1/preview)\n\nWith 1000 tokens with length between 5-30 (and 25% of them being 1 char), it shows concatenation being 284% faster than array.join(''). 276,059 ops/sec vs  96,964 ops/sec\n\nEdit: OP, there are really only a few different ways to do this. Just write a benchmark geared towards your specific usecase and make your own determination.  It's likely that performance isn't even something you should consider unless the throughput is high enough.\n\nThat's interesting because it directly contradicts my own benchmark [https://jsperf.app/sagopa](https://jsperf.app/sagopa) although to be fair yours is closer to a real world scenario. Javascript performance is really confusing at times.\n\nI got 56% slower on the += method compared to join('')\n\nWith your benchmark on my device, it seems join becomes faster somewhere in the 100k-1 million token range. Before that (and especially around the 1000 token mark where my benchmark tests), concatenation is faster.\n\nNo real idea why tho, just wild guesses. Goes to show these things are very complicated, especially in a dynamic/gc'd language like JavaScript.\n\nSo, OP. My take away is that any of these methods are probably fast enough for handling the response chunks from your LLM without human perceptible delay. If you really need to optimize, write a benchmark as comparable to your use case as possible.\n\nHowever, most of the time, I write for ease of understanding and maintenance first, performance second. It's rarely worth it to write code that runs as quickly as possible if it makes it harder for me or someone else to work with in the future.", "id": "k3uc0d7", "owner_tier": 0.3, "score": 0.999999999090909}, {"content": "Unless you operate with thousands of string a second, you won't get any performance improvement for string manipulation in JavaScript. Given that you're using ChatGPT API, that means that the performance issue of the string manipulation is not significant and I'm certain that it's not an issue for your use-case.\n\nAnswering your question, JS doesn't offer a mechanism like Java does but that's because it doesn't need it. JS is one of the fastest languages to manipulate strings.\n\nKeep using the += and leave your code clean.", "id": "k3yq18r", "owner_tier": 0.7, "score": -9.090909035659355e-10}], "link": "https://www.reddit.com/r/node/comments/1724gci/what_is_the_most_efficient_way_to_concatenate_a/", "question": {"content": "I have a server that uses the chat gpt api with stream (SSE) and I have to concatenate all the chucks it sends.\n\nI wanted to know if there is something more efficient than `+=`, in other languages they recommend using a String Buffer, in js/ts I don't know what is best.\n\nThank you so much.\n\n\n```ts\nasync function main() {\n  const stream = await openai.chat.completions.create({\n    model: 'gpt-4',\n    messages: [{ role: 'user', content: 'Say this is a test' }],\n    stream: true,\n  });\n  for await (const part of stream) {\n    process.stdout.write(part.choices[0]?.delta?.content || '');\n  }\n}\n```", "id": "1724gci", "title": "What is the most efficient way to concatenate a string? (For example chat GPT stream responses)", "traffic_rate": 51.20747277506572}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "join if you already have an iterable of strings.\n\nfstrings if you are trying to format some variables.\n\n    f'{a} {b}'\n\n\\+ if you're being lazy or _really_ just need a + b with no other formatting.\n\n> is this a blanket statement to avoid using += and + for concatenation in all cases? If so, why even have the feature as part of the language?\n\nLiterally doesn't matter. If you are building a string go nuts with `+=`. It's not something you'd be farting around with if that level of optimization actually mattered.", "id": "ily4bpm", "owner_tier": 0.9, "score": 0.9999999975}, {"content": "Hello, I'm a Reddit bot who's here to help people nicely format their coding questions. This makes it as easy as possible for people to read your post and help you.\n\nI think I have detected some formatting issues with your submission:\n\n1. Inline formatting (`` `my code` ``) used across multiple lines of code. This can mess with indentation.\n\nIf I am correct, please edit the text in your post and try to follow [these instructions](https://www.reddit.com/r/learnpython/wiki/faq#wiki_how_do_i_format_code.3F) to fix up your post's formatting.\n\n___\n\n^(Am I misbehaving? Have a comment or suggestion? Reply to this comment or raise an issue )^[here](https://github.com/0Hughman0/pyredditformatbot/issues).", "id": "ily06re", "owner_tier": 0.1, "score": -2.4999999848063226e-09}, {"content": "I don't really care about line length, after all, the first \"law\" of PEP8 is: ``` \"A Foolish Consistency is the Hobgoblin of Little Minds\"```.\n\nWith that said the **fastest** way to concatenate strings in Python is to use f-string, as in:\n\n```result = f\"{a}{b}\"```", "id": "ilykbsz", "owner_tier": 0.5, "score": -2.4999999848063226e-09}, {"content": "I try to keep my lines under 120 characters so don't really care if I go over the old 80 character limit.\n\nI tend to forget that both of those options exist - I use f-strings for almost everything.", "id": "ilzob7b", "owner_tier": 0.3, "score": -2.4999999848063226e-09}], "link": "https://www.reddit.com/r/learnpython/comments/wyp9wh/join_or_for_string_concatenation/", "question": {"content": "I know there are several ways to concatenate strings. For the most basic cases, such as joining *a* and *b* here..\n\n    a = \"ABCD\"\n    b = \"EFGH\"\n\n.. which is recommended? \n\n`a + b`\n\n`''.join([a, b])`\n\nI find many examples of people using join(), but I don't see how this is an advantage in the simplest of cases. One disadvantage is it consumes 10 additional characters on the line of code, which is significant if you're trying to keep lines at 79 characters or less.\n\nAs a follow-up question, can anyone elaborate on this statement from PEP8 ?\n\n>...do not rely on CPython\u2019s efficient implementation of in-place string concatenation for statements in the form **a += b** or **a = a + b**. This optimization is fragile even in CPython (it only works for some  types) and isn\u2019t present at all in implementations that don\u2019t use  refcounting.\n\n.. is this a blanket statement to avoid using += and + for concatenation *in all cases*? If so, why even have the feature as part of the language?", "id": "wyp9wh", "title": "join() or '+' for string concatenation", "traffic_rate": 153.12462962962962}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "On July 1st, a [change to Reddit's API pricing](https://www.reddit.com/r/reddit/comments/12qwagm/an_update_regarding_reddits_api/) will come into effect. [Several developers](https://www.reddit.com/r/redditisfun/comments/144gmfq/rif_will_shut_down_on_june_30_2023_in_response_to/) of commercial third-party apps have announced that this change will compel them to shut down their apps. At least [one accessibility-focused non-commercial third party app](https://www.reddit.com/r/DystopiaForReddit/comments/145e9sk/update_dystopia_will_continue_operating_for_free/) will continue to be available free of charge.\n\nIf you want to express your strong disagreement with the API pricing change or with Reddit's response to the backlash, you may want to consider the following options:\n\n1. Limiting your involvement with Reddit, or\n2. Temporarily refraining from using Reddit\n3. Cancelling your subscription of Reddit Premium\n\nas a way to voice your protest.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/learnprogramming) if you have any questions or concerns.*", "id": "jyc33nk", "owner_tier": 0.1, "score": -9.090909035659355e-10}, {"content": "No, that's pretty much it. Another example would be if you're drawing a box out of characters, in which case you might want to do something like `\"*\" * 50` to draw a horizontal line.\n\nI would say the main reason Python has a string replication operator at all is for symmetry with the `+` string concatenation operator. That is, `s*3` gives you the same result as `s+s+s`. It doesn't let you do anything you couldn't do otherwise, it's just for convenience.\n\nOk. I wanted to make sure I wasn't about to dive into a meaningless rabbit hole.", "id": "jyc5d5y", "owner_tier": 0.7, "score": 0.999999999090909}, {"content": "What you might not realise is that strings are kinda like lists, and this trick works with those too. If I need a list that has four 0s in it, I can write `[0]*4` and that gives me `[0, 0, 0, 0]`. I'm sure you can see that has more use cases than the string case. \n\nBut yeah, your example of padding strings or the other commenters example of drawing boxes or being symmetrical with concatenation is where its usefulness for strings ends.\n\nShould be noted though, you may encounter an unexpected behavior if you try to multiply a mutable object, like a list: \\[\\[0\\] \\* 4\\] \\* 3.\n\n[https://docs.python.org/3/faq/programming.html#how-do-i-create-a-multidimensional-list](https://docs.python.org/3/faq/programming.html#how-do-i-create-a-multidimensional-list)\n\nu/butt--Fumble\n\nThat is very true. For u/butt-Fumble this means that each element in the outer list is the same object in memory. So changing one will change them all. In these cases use a list comprehension. \n\n```\n[[0] for i in range(4)] for j in range(3)]\n```", "id": "jyc8l5b", "owner_tier": 0.7, "score": 0.4545454536363636}, {"content": "Your question seems to be answered; if not early, you should note this as well:\n\n[https://docs.python.org/3/faq/programming.html#what-is-the-most-efficient-way-to-concatenate-many-strings-together](https://docs.python.org/3/faq/programming.html#what-is-the-most-efficient-way-to-concatenate-many-strings-together)", "id": "jycbb86", "owner_tier": 0.5, "score": 0.09090909000000001}], "link": "https://www.reddit.com/r/learnprogramming/comments/1655b8j/why_string_replication_is_useful/", "question": {"content": "Title should say: Why is string replication useful?\n\nI'm reading Automate the Boring Stuff from the website and there's a section about simple uses for strings and operators. I'm in the 2nd chapter in the String Concatenation and Replication section. The text is:\n\n*>>> 'Alice' \\* 5*\n\n*'AliceAliceAliceAliceAlice'*\n\n*The expression evaluates down to a single string value that repeats the original string a number of times equal to the integer value. String replication is a useful trick, but it\u2019s not used as often as string concatenation.*\n\nI substantively understand what is happening with string replication, but I'm not sure I get why it could be useful. I guess you could replicate an empty string in a terminal to help your eyes parse the text. Like, maybe if you were playing a text-based RPG it could be helpful for reading a character sheet like:\n\n`charOne = \"Billy\"`\n\n`charOneWisdom = 24`\n\n`charOneSTR = 34`\n\n`charOneLUK = 9`\n\n`print(\"Character Name: \" + charOne)`\n\n`print(\" \" * 2 + \"Character Stats:\")`\n\n`print(\" \" * 6 + \"INT: \" + str(charOneWisdom))`\n\n`print(\" \" * 6 + \"STR: \" + str(charOneSTR))`\n\n`print(\" \" * 6 + \"LUK: \" + str(charOneLUK))`\n\nThe output has small spaces from the left so it's easier to read.\n\n`Character Name: Billy`\n\n  `Character Stats:`\n\n`INT: 24`\n\n`STR: 34`\n\n`LUK: 9`\n\nIs there a specific use case for string replication that I'm not aware of because I'm too new to programming?", "id": "1655b8j", "title": "Why string replication is useful?", "traffic_rate": 759.4064349112426}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "Use `std::string`. Given the number of users of the standard library it's necessarily sufficiently efficient for most scenarios. `std::string` guarantees O(n) complexity for concatenation, which means that when the buffer needs to upsized the new size is some factor (typically 2) times the old size.\n\n\n---\n\n> \u275e Is std::stringstream any better for this purpose?\n\nNo, iostreams are notoriously slow (in spite of theoretical possible high speed): you can be reasonably sure that it will be slower than most any alternative, due to flawed locale support.\n\nBut **measure** if you're really interested.\n\n---\n\n> \u275e Why isnt there a type that just takes the pointer to the const char* components of the string and only does a final allocation when all the components are fed in?\n\nWhat do you mean?\n\n`std::string` supports C strings.\n\nThey probably mean something like StringBuilder in Java. You give it strings and they store them in a small list (std::vector for us) and then there is one function that scans the length of all strings, reserves the space and concats them\n\nUnlinked STL entries: [std::string](https://en.cppreference.com/w/cpp/string/basic_string)\n\n---\n\n^(Last update: 14.09.21. Last Change: Can now link headers like '<bitset>')[Repo](https://github.com/Narase33/std_bot_cpp)", "id": "ilr6d3n", "owner_tier": 0.5, "score": 0.749999999375}, {"content": "Add up the total length of all strings, reserve that length, then start concatenating.  Of course.. where is the data going? If its a large string why bother concatenating it anyway?  just stream the bytes to its destination.\n\nWhat do you mean by stream the data. Can you provide an example? I have been bothered by this issue at different occasions. I was able to solve some by std::string::reserve but since I stumble upon this often, I want to get to the root of this and slay it for good.\n\nSay you have a std::vector<std::string> data;\n\nWhat are you going to do with it?  Send it to a server over a socket?  write it to disk?  search it?  Write it to the console?  You don't need to concatenate it to one string to do those things.\n\nExample, you are writing a web app, you are returning a giant string, maybe its json, maybe its txt, maybe its xml.  You can start writing that data through the socket before you even get all of it (maybe you are doing sql queries, or reading files, or doing rpc's to other services).\n\nFeeding in to a database as query string\n\nUse a prepared statement instead of concatenating the args, its faster and safer.  Some data bases even jit compile part of the query now a days.", "id": "ilr6hd1", "owner_tier": 0.9, "score": 0.999999999375}, {"content": "> fragmentation \n\nThere isnt going to be any fragmentation. The result will be a single allocation of a contigous char array.\n\n> Is std::stringstream any better for this purpose?\n\nNot really. Under the hood, stringstream has to do the exact same resizing of its buffer as a `std::string` would do.\n\n> Why isnt there a type that just takes the pointer to the const char* \n\nIf that is possible, it would be equivalent to simply calling `resize`.\n\n---\n\nMaybe something like:\n\n    template<typename ... Ts>\n    std::string concat( Ts&& ... ts )\n    {\n       const auto size = ( std::string_view{ ts }.size() + ... );\n       std::string res;\n       res.reserve( size );\n       ( res.append( ts ), .... );\n       return res;\n    }\n\nThank you. I came up with a non template similar solution but now I see this I like how simple it is. I need to get myself familiar with variadic templates. Thank you.", "id": "ilr6vqf", "owner_tier": 0.7, "score": 0.249999999375}, {"content": "It begs the question, is efficiency really a concern? Have you profiled your code? Why do you want to concatenate strings in the first place?\n\nIf it were me, I'd go all the way back to basics and question how you got a scattered set of strings that need concatenation in the first place. The best solution to your problem is prevention.\n\nIf you need a continuous view over a bunch of strings, then the best solution might not be to concatenate the data. Memory operations are expensive. You're talking about a sequence of allocations, reallocations, and deallocations, all of which is going to fragment your memory. You could do a pass and sum the size of all your strings and allocate once, but you're still going to free up a whole bunch of smaller strings which had contributed to fragmentation in the first place. And then you have to do all the data copying!\n\nInstead, you might just want to provide a contiguous view. There is `std::ranges::join_view`. Likely, it's more efficient for you to leave all the data where it is and abstract away that they are all separate. The join_view gives you a \"flattened\" range, as this is typically called \"flattening\", and then you can give that to a string_view to make it read-only and string-like.\n\nThe reason for concatenation is to form database query string from C++ client code. Memory team has profiled this operation to fragment memory.\n\nI think join_view is what I am looking for. Thank you. I just want a concatenated view of the string not necessarily own them into continuous memory.\n\nIf you're using standard streams to communicate with the SQL server over TCP, then this is not an issue - you've got string bits all going down the pipe, there's no point is concatenating the strings before the stream, because the stream would also inherently concatenate the strings. This alludes to what I suggested earlier, that if your memory team is telling you string memory fragmentation is the next lowest hanging fruit, then you have to look at how all these small strings are getting made in the first place. I would consider using a single string and a heuristic to reserve a size based on the client's usage patterns.", "id": "ilvcnl5", "owner_tier": 0.7, "score": 0.187499999375}, {"content": "My advice would be to make sure not use `a = a + b;` to concatenate, but rather use `a += b;` or `a.append(b);`. This is a simple, valuable optimization.", "id": "iluz6e0", "owner_tier": 0.5, "score": -6.249999962015806e-10}, {"content": "Why wouldn't you know the final size? How would the thing you are asking for be able to get the size any better than you could?", "id": "ilvcg03", "owner_tier": 0.3, "score": -6.249999962015806e-10}], "link": "https://www.reddit.com/r/cpp_questions/comments/wxiyg1/most_efficient_way_to_concatenate_strings/", "question": {"content": "Whats the most effective way to concatenate strings to avoid fragmentation and alloc/dealloc during resizing?\n\nI know, I can use reserve but I wouldn\u2019t know the worst case scenario of the total length of this concatenation.\n\nIs std::stringstream any better for this purpose? Why isnt there a type that just takes the pointer to the const char* components of the string and only does a final allocation when all the components are fed in?", "id": "wxiyg1", "title": "Most efficient way to concatenate strings", "traffic_rate": 17.10646221248631}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "Because it's not the wild west of Javascript. There is absolutely no reason why strings and ints should be able to be concatenated without any special considerations. \n\nThe question you should ask is \"Why are there languages that allow this sacrilege?\"\n\nPlus, the answer is in your question:\n> I know that f-strings are less uglier and error-prone\n\nSo JavaScript still allows for this?\n\nYes javascript \"allows\" lots of things.\n\nFor example \"5\" + 5 is \"55\"\n\nWhile \"5\" * 5 is 25...\n\nfun fun fun...\n\nMany languages allow this. One of those is java, where anything can be concatenated to a string and it handles the toString() call automatically.\n\nLua on the other hand has a special string concatenation operator which is lot `+` but `..`\n\nYou can't say `\"hey\"+5` but you can say `\"hey\"..5` and Lua also does the conversion automatically.\n\nPython allows to write `\"5\"*5` though, so most explanations that why `\"5\"+5` should not work are simply opinions.\n\nThe first one works like that in most languages I am* familiar with so it's not that strange unless you only know python. *(not sure which is the more common behavior). Though python throwing an error is not a bad solution, but it's seems even a bit unusual.\n\nAbout the second, most languages would give an error, javascript does a type conversion and multiplies, and python produces a rather strange 55555. Each solution has its pros.\n\n>and python produces a rather strange 55555.\n\nThis makes more sense to me, you are multiplying a string several times.\n\nIf adding \"5\" to \"5\" one time results in \"55\"... Then adding that 5 times results in \"55555\".\n\nThat's what multiplication means, do the add operation X times...", "id": "iaarm8b", "owner_tier": 0.7, "score": 0.9999999996969696}, {"content": "Because integers aren't strings.\n\n    print(name + ' is ' + age + ' years old')\n\nWould you expect \"John is 000020 years old\", or \"John is 20 years old\" or \"John is 2e+2 years old\"?\n\nEach is valid, if you could concatenate ints to strings.\n\nIf you use the function str(age), then the str() function decides how to represent an integer as a string.\n\nedit: 2e+1\n\nI know it doesn't matter to your point but 2e+2 is 200.\n\nYeah, I wondered if I'd fucked that up... Ta.", "id": "iaawmw4", "owner_tier": 0.3, "score": 0.5757575754545454}, {"content": "The literal answer to your question is \"because it's not part of the language\".\n\nTo answer the spirit of your question, which I think is, \"why did the creators of Python not automatically cast numeric type to strings when the plus operator is used?\" I'll ask my own question:\n\nWhy would casting numeric types to strings be preferred over casting strings to numeric types?\n\nThat is, why wouldn't \"20\" + 5 be 25?\n\nThe answer is that there is no clear \"right\" operation when numeric types and string types use the same operator for different things. What about a string plus a list? Lists can be appended using the plus operator, so in this case, does a list get cast to a string and then a string produced, or does a string get cast to a list and then a list produced?\n\nGenerally, operators only work between the same or very, very similar types because it's impossible to determine precedence otherwise.", "id": "iabvhlj", "owner_tier": 0.7, "score": -3.030303011886452e-10}, {"content": "my guess has always been that strings ahre treated like charactor arrays in python but without you actually haveing to give a size or type. so name is just treated as a \\['j','o','h', 'n'\\] and intigers are their own type(like in most lower level langauges). you can split name into it individual letters or charactors and get things like name\\[0\\] = 'j' but age\\[0\\] wont give you 2. so the program in my mind does this name\\[ :\\] .append( ' ') and just does recursion until it hit the end of the print statement.\n\n&#x200B;\n\nI am sure this is not how it actually works but that my limited guess. I am sure someone who actually knows computers and python better will have a better answer.", "id": "iabz3h3", "owner_tier": 0.3, "score": -3.030303011886452e-10}, {"content": "Because what happens when you have 0/\"1\" or  0 + \"2\"?  Python is a strict typing language.  Trust me as someone who has coded Perl, it's really hard to fix things when say addition doesn't follow math.", "id": "iadb4hd", "owner_tier": 0.7, "score": -3.030303011886452e-10}, {"content": "I prefer `f string` formatting. \n\n```\nname = John\nage = 20\nprint(f\"{name} is {age} years old\")\n```\nLooks a lot neater.", "id": "iadbrus", "owner_tier": 0.3, "score": -3.030303011886452e-10}, {"content": "That's how it should work. Integers are not String. Therefore the interpreter should not assume if you want to compose an string or an int. \n\nFor example: '1'+1 may be '11' or 2.\n\nF strings are different because you're telling the interpreter to build a string. Therefore the interpreter can safely assume that everything should be converted into a string.", "id": "iage1zc", "owner_tier": 0.5, "score": -3.030303011886452e-10}], "link": "https://www.reddit.com/r/learnpython/comments/uzkkgf/why_does_python_only_concatenate_string_to_string/", "question": {"content": "If I will input\n\n    name = John\n    age = 20\n    print(name + ' is ' + age + ' years old')\n\nThen I will receive \n\n    TypeError: can only concatenate str (not \"int\") to str\n\nI know that f-strings are less uglier and error-prone but it's interesting.  \nThank you", "id": "uzkkgf", "title": "Why does Python only concatenate string to string and not string to integer?", "traffic_rate": 153.1248148148148}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "There is a StrCat function in Abseil libraries. According to google it's one of the most used utility functions there. Google tried to propose it into standard but it didn't get anywhere. Then there is another proposal P1228 which also seems stalled.\n\nP1228 wasn't stalled, so much as the whole world was temporarily stalled due to Covid.  The C++ committee held its first in-person meeting in 2 and a half years... just last week.  (And yes, the did a lot of meetings remotely... but the author of P1228 has 3 kids and during Covid, parents in California temporarily became home-schoolers...", "id": "gvir68d", "owner_tier": 0.3, "score": 0.34920634904761905}, {"content": "Strings don\u2019t seem to interest those involved in the standardization process. Look how long it took to get starts_with/ends_with and contains, and those are considerably simpler.\n\nHeck, after coming out with string_view seemingly obvious overloads for them are still nowhere to be found: regexes, sto[idl].\n\nI can assure you that SG16, the Unicode and text formatting study group, is absurdly obsessed with strings. Unfortunately for the last year or so we've been focusing on stuff that's more fundamental \u2014 and more broken \u2014 than the existing string library in C++.", "id": "gvj4ex9", "owner_tier": 0.5, "score": 0.34920634904761905}, {"content": "Rather than just that, I feel implementing the Python str.join function would be interesting.\n\n    std::join(\", \", \"1\", \"2\", \"3\");\n\nor something\nhttps://docs.python.org/3/library/stdtypes.html#str.join\n\nThere is actually one is [std::ranges](https://en.cppreference.com/w/cpp/ranges/join_view)\n\nranges::join is not useful for string concatenation. Stackoverflow is already full of questions how to join transformed strings.  Perhaps we need another paper for supperior string join :)\n\nCould you elaborate? I've been using range-v3 for quite a while and when it comes to joining string it does the job pretty well: [https://godbolt.org/z/c1csYEEbE](https://godbolt.org/z/c1csYEEbE)\n\nI know that things like `ranges::to` and `ranges::view::concat` are yet missing from the STL, but from what I've read they'll evetually make it there.", "id": "gvjuqfq", "owner_tier": 0.5, "score": 0.1428571426984127}, {"content": "See [https://www.reddit.com/r/cpp/comments/mt7h68/optimizing\\_stringappend\\_is\\_harder\\_than\\_it\\_looks/?utm\\_source=share&utm\\_medium=web2x&context=3](https://www.reddit.com/r/cpp/comments/mt7h68/optimizing_stringappend_is_harder_than_it_looks/?utm_source=share&utm_medium=web2x&context=3)", "id": "gvig3eq", "owner_tier": 0.5, "score": 0.03174603158730159}, {"content": "Wouldn't a solution that takes the length of all strings, and then reserves that on the destination string, be pretty much overhead-free? It only does one memory allocation, no reallocations, and it traverses the source strings only once (assuming for a moment it doesn't have to call strlen - and why should it in an age of string\\_view?). I'm not sure what other overhead you could cut from it, really.\n\nYou could do it with zero allocations by returning an std::array instead of an std::string. In the usual case where the result is no more than a few hundred characters there should be no stack overflow issues.\n\nIf your string class allows you to give it a buffer to own, which mine do, then you could easily have a concatenator function that adds up the string lengths, allocates the buffer,  copies over the source strings, then gives that buffer to a temp string object that gets RVO'd back to the caller.\n\nThat solves a different problem though. The question was for a general purpose concat() function that returns an std::string.\n\n>You could do it with zero allocations by returning an std::array instead of an std::string\n\nPeople usually don't concatenate strings and then sit back and relax, enjoy the beauty of the result. That result is usually passed somewhere. And every function that expects a string/string\\_view would decay that array into const char\\*, calculate its length via strlen, dropping everything after the fist \\\\0, and eventually allocate anyway if it needs a string.\n\nIn fact I just implemented that, replacing my previous mechanism. There are a number of variations for strings and strings with separator characters.", "id": "gvjln2p", "owner_tier": 0.5, "score": 0.12698412682539684}, {"content": "I see utility to it. Though, when I was concatenating strings (text editor and formatting library), it was almost always `wchar_t`/`std::wstring`, and so a `concat` function that favored only `std::string` wouldn't help me much. Also, the past few years I've actually found myself concatenating `vector`'s of integers and floats more often than strings (such as machine learning tensors and dimensions), and so an `std::join/concat` that concatenated multiple vectors would be more generic and more convenient for me (instead of the verbose `myContainer.insert(myContainer.end(), myOtherContainer.begin(), myOtherContainer.end())` \ud83d\ude14. Though alternately if `vector` just had an `.append(foo)` method, that would be bliss.\n\n>`char16_t`/`std::wstring`\n\nI hope you mean `wchar_t`/`std::wstring` or `char16_t`/`std::u16string`, since `char16_t`/`std::wstring` doesn't belong together.\n\nKuhluh: \ud83d\udc4d Fixed (I meant to say `wchar_t` treated as UTF-16).", "id": "gvj8ez7", "owner_tier": 0.3, "score": 0.11111111095238096}, {"content": ">std::format is, as currently specified by the standard, unfit for the purpose of efficient concatenation. Runtime analysis of formatting string is one of the problems - constexpr std::format is still far on the horizon and I don't see it landing in C++23.\n\nThis is not the case. `std::format` with format string compilation is actually pretty easy to add because parsing is already `constexpr` in the underlying formatters, the only thing that is missing is top-level overloads.\n\nIn principle there is no reason for `std::format` to be slower than a dedicated concatenation function as results in [https://github.com/fmtlib/fmt/issues/1685#issuecomment-643555407](https://github.com/fmtlib/fmt/issues/1685#issuecomment-643555407) show:\n\n    ------------------------------------------------------------ \n    Benchmark                  Time             CPU   Iterations \n    ------------------------------------------------------------ \n    naive                    139 ns          139 ns      4840941 \n    append                   113 ns          113 ns      6207325 \n    appendWithReserve        116 ns          116 ns      6029597 \n    format_compile           108 ns          107 ns      6392344 \n    format_runtime           129 ns          129 ns      5341350 \n    format_to               67.7 ns         67.6 ns     10185967 \n    nullop                 0.233 ns        0.232 ns   1000000000\n\nNote that even runtime format string processing has a lot of opportunities for optimization. The current implementation is fairly basic but still performs quite well.\n\nSo the argument for a separate  concatenation API is usability, not performance.\n\nI don't believe your benchmark results are accurate in any way. You're showing appendWithReserve as being *slower* than appendWithoutReserve, and hardly any faster than the naive implementation.\n\nMy own benchmark results, using your own godot.com link, showed substantially different outcomes than yours.\n\nNotably, I measured format_compile at about half the speed of appendWithoutReserve, and appendWithReserve at about twice the speed of appendWithoutReserve. Showing that format_compile is roughly 4x slower than appendWithReserve.\n\na string concatenation that uses `std::string::resize` and `std::copy` directly into the resulting pointer, is even faster still than appendWithReserve, as it skips an incredibly large amount of unnecessary logic in `std::string::append`\n\nI have no idea what \"format_to\" represents, as it is not explained in the linked github page, so i could not do any comparisons of that.\n\nSee this comment thread for details.\n\nhttps://old.reddit.com/r/cpp/comments/mwb8i1/would_stdconcat_for_strings_be_a_good_addition_to/gvn5n9t/\n\nThis is not my benchmark and it is indeed rubbish (it is sort of a pathological case for format (!) and there is a lot of variability) but it doesn't change the conclusion, just slightly affects the relative differences. Counterintuitively,  reserve was indeed slower in those runs.\n\nHere's even better example: [https://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html](https://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html). If you look at `fmt::format[c]`, `fmt::to_string` and `std::to_string`, you'll notice that there is almost no difference in libstdc++ which has a decent implementation of `to_string`.\n\nMore generally, any optimization that applies to concatenation can be applied to the format API and vice versa. The only difference is API: format is more flexible while concat is slightly more convenient if you only need to stringify a few arguments and don't need any control over presentation.\n\nI simply do not believe that appendWithReserve can be slower than the same code sans the reserve call. My own benchmarking, even with the extreme volatility of the godbolt.com environment, showed that it is consistently 2x the speed. Not slower.\n\nFurther, the benchmark results provided for {fmt} are *substantially different* than the results I got using the same code. {fmt} was slower than even the naive implementation when not using FMT_COMPILE. Adding FMT_COMPILE brings it down to about the same speed as appendsWithoutReserve \n\nUnless more details are published about the methodology used for the benchmark, and independent confirmation of the results can be obtained, you should not reference that github link as some sort of evidence that {fmt} has compatible performance to even \"appendsWithoutReserve\". The published benchmark results *don't* match reality, and its clear to anyone who runs the benchmark code themselves that {fmt} is substantially slower than the conventional wisdom of using `std::string::reserve` and `std::string::append`.\n\nNote that benchmarking on godbolt doesn't make any sense: you are basically comparing debug and release code:\n\n    ***WARNING*** Library was built as DEBUG. Timings may be affected.\n\n`reserve` being slow is indeed surprising but it's irrelevant here. My guess is that the difference is implementation specific. I ran benchmarks on libc++ which has larger SSO capacity compared to libstdc++, so it needs fewer reallocations and reserve just adds unnecessary overhead. In any case, it doesn't really matter because as I wrote the same optimizations can be applied in both cases. This silly benchmark only demonstrates that there is no difference on one specific implementation.\n\nthe debug warning comes from the Google benchmark lib being compiled as debug. It should have no meaningful impact on the actual measurements. I verified the assembly code for the code under test was appropriately optimized.\n\n\n> reserve being slow is indeed surprising but it's irrelevant\n\nIts entirely relevant. Your benchmark measurements are *clearly* invalid. Both by itself because of the reserve call being measured as slower without detailed justification, as well as the lack of documented methodology.\n\nThat the results published are completely different than my own measurements, are another point against it.\n\nPlease disavow that benchmark result / github issue as being invalid, and don't use it in discussions in the future. Using it as evidence that {fmt} is performant is dishonest.\n\nI've just rerun the benchmark and can confirm that the results are indeed correct on clang/libc++/macos:\n\n    % ./concat-benchmark\n    2021-04-26 08:10:05\n    Running ./concat-benchmark\n    Run on (8 X 2800 MHz CPU s)\n    CPU Caches:\n      L1 Data 32K (x4)\n      L1 Instruction 32K (x4)\n      L2 Unified 262K (x4)\n      L3 Unified 8388K (x1)\n    Load Average: 2.37, 2.25, 1.98\n    ------------------------------------------------------------\n    Benchmark                  Time             CPU   Iterations\n    ------------------------------------------------------------\n    naive                    142 ns          142 ns      4687385\n    append                   114 ns          114 ns      5881760\n    appendWithReserve        121 ns          121 ns      5640112\n    format_compile           117 ns          117 ns      5682279\n    format_runtime           155 ns          155 ns      4539265\n    format_to                102 ns          102 ns      6672386\n    nullop                 0.232 ns        0.232 ns   1000000000\n\n\\> the debug warning comes from the Google benchmark lib being compiled as debug.  \n\n\nAll libraries including {fmt} are built with optimizations disabled on godbolt: [https://github.com/compiler-explorer/compiler-explorer/issues/2449#issuecomment-786301639](https://github.com/compiler-explorer/compiler-explorer/issues/2449#issuecomment-786301639)\n\nMay I have this complete source code for  concat-benchmark?\n\nI was very interested in your benchmark.  In our own tests (GCC 9.3, linux box), `format_compile` is slightly slower than `appendWithReserve` and `format_to` is significantly slower than `appendWithReserve`.  We use `FMT_HEADER_ONLY`.  Would it being a static library help with performance at all?\n\nI'm also curious what the best solution is for appending raw strings that are constants?  In my solution I often do:\n\n    const std::string my_static_string = \"MYSTATIC_STRING\";\n    fmt::format::(FMT_COMPILE(\"{}{}\", my_static_string, some_other_string));\n\nBut wasn't sure if that was the better solution.  It didn't seem like making the string itself `constexpr` would provide any benefit?\n\nIt's here:  https://github.com/fmtlib/format-benchmark/blob/master/src/concat-benchmark.cc\n\n>Would it being a static library help with performance at all?\n\nI don't think static library will make any difference but make sure to compile with assertions disabled (-DNDEBUG). Feel free to open an issue in {fmt} with repro details and I'll take a look. Format string compilation was added recently and there are some opportunities for optimization.\n\n>I'm also curious what the best solution is for appending raw strings that are constants?\n\nPut them in a format string if you can, otherwise you can pass them as string\\_views and avoid string allocation.", "id": "gvvsxmn", "owner_tier": 0.3, "score": 0.19047619031746033}, {"content": "How often are you doing something that looks precisely like `format(\"{}{}{}\", a, b, c)` that you need a special facility for it?\n\nIt's pretty straightforward to implement `concat(a, b, c)` to mean that expression. Could just do it and see how popular it is.\n\nMy codebase uses a version of string concat very similar to the OP in what appears to be approaching a thousand or more places locations across our entire codebase (millions of lines of code). I find new places where people concatenated >2 strings with operator+ every week or two.\n\nI would say that a standardized string concatenation function is sorely needed.\n\nThis is such a bad argument. Yes, I can implement concat. I can also implement a vector, a map, a lock_guard, and an optional. The std isn't just for things that you literally cannot implement yourself without it.\n\nSo... add a PR to fmt? Or provide it as a separate 3rd party library that depends on fmt?\n\n> This is such a bad argument.\n\nI have no idea what it is you think I'm arguing, but I said nothing that resembles what you're saying. I did not say that this facility does not belong in the standard library. \n\nWhat I have said, repeatedly now, is that if this is actually something really useful (that may belong in the standard library), that somebody should actually implement it and provide it for people to use. And then, if a lot of people use it, that's (a) already providing a lot of value to those people without having to go through standardization and then (b) providing clear motivation for standardization.\n\nI posted in the original post a link to how performant fmt::format is for concatenating small strings. As for now, std::format will be just slow until we can parse format string at compile time. It's not the solution here.\n\nNo that's an absolutely terrible suggestion. I'm not formatting a string. I'm concatenating a collection of strings. I want exactly 1 allocation, and exactly one copy per character.  Support for automatically converting non-string data types would be nice, but ultimately unnessary.\n\nMy implementation gets me exactly this, minus the optional conversion capabilities.\n\nThe post that shows that `fmt::format` is [faster](https://github.com/fmtlib/fmt/issues/1685#issuecomment-643555407)?\n\n> No that's an absolutely terrible suggestion. \n\nDon't be a dick. \n\n> I'm not formatting a string. I'm concatenating a collection of strings. I want exactly 1 allocation, and exactly one copy per character. Support for automatically converting non-string data types would be nice, but ultimately unnessary.\n\nThat's... absolutely formatting a string. Tomato, tomato.\n\nSupporting for non-strings might not be important to *you specifically* but in the broader context of potentially standardizing a facility, it seems pretty necessary (plus `StrCat` already supports this, and there was already [no consensus](https://github.com/cplusplus/papers/issues/151#issuecomment-471829461) to remove that support). \n\nIt's completely free to support, since we already have the facility, so I don't know why you just wouldn't.\n\nMoreover, and getting back to your delightful comment about this being an \"absolutely terrible suggestion\"... you could, for instance, implement `concat(xs...)` in a way that special cases the scenario where all the `xs` are `string`, `string_view`, `char const*`, or `char` (and possibly just any random-access sized range of `char`). That approach is not hard to do and does what you want, while also not limiting functionality.\n\nHere's my money where my mouth is \n\nWhile this isn't 100% the same as what I use at work, its nearly so.\n\n4, 4-line, functions and 99% of my string concatenation needs are met.\n\nhttps://github.com/splinter-build/splinter/blob/10-string_concat/src/string_concat.h\n\nWhat you need to compare to is format_runtime. This is the version that got into the std::.\n\nHow the bloody hell is this possible?\n\nappend with reserve should end up as, essentially, a single allocation, and then a series of memcpys. Nothing should be able to beat that.\n\n> appendWithReserve        116 ns          116 ns      6029597\n>\n> format_compile           108 ns          107 ns      6392344\n\nEdit:\n\nAhh, well, they're creating a string with characters already in it, for one, instead of appending the initial string after reserving space. That at least explains a tiny part of it.\n\nAnother edit:\n\nWell, it turns out it's because the benchmark is not reproducible with the information provided.\n\nhttps://godbolt.org/z/EZE7Dn (From the linked github post) produces *wildly* different results than the github post, showing fmt to be slower by an order of magnitute, as well as the original post claiming that appendWithReserve is slower than appendWithoutReserve (which is not what I would expect, and not what the linked godbolt page shows). This is especially egregious since appendWithReserve is coming out at about half the time as appendWithoutReserve hen I run it.\n\nTo even run that benchmark requires adding -pthread to the compiler args (https://godbolt.org/z/5z8xz9shh),\n\nthen, adding FMT_COMPILE to the string for the fmt function takes the runtime cost for fmt down to the same as appendWithoutReserve, which still makes appendWithReserve twice as fast.\n\nFrustratingly, my string_concat function does quite a bit worse than appendWithReserve, https://godbolt.org/z/rhr4T59h5 .  However, *so far* after refreshing the page a few dozen times, i've only seen string_concat do worse than fmt once. Every other result, i've beaten fmt, sometimes by as much as 20-30ns.\n\n\nEdit again:\n\nhttps://godbolt.org/z/esK43e69f\n\nNow string_concat consistantly beats appendWithReserve by about half, and beats fmt by about 100ns every time.\n\nI would say that I could *probably* get it down even further if I had the ability to ask the string to resize itself without also overwriting the newly resized data, but looking at the generated assembly it's clear that the compiler is deliberately omitting the zero initialization of the character data, so i guess it doesn't matter in this specific usage.\n\n> Don't be a dick.\n\nDon't tell people to submit pull requests to projects that aren't the standard library, without explaining why?\n\n> That's... absolutely formatting a string. Tomato, tomato.\n\nOne involves parsing the format specification string (std::format(\"{}{}{}\")) and the other doesn't do any kind of positional decision making, but is more akin to copying multiple buffers of unspecified types into a contiguous buffer. For the many thousands of callsites that my work code-base has for `string_concat`, there's no need to have any kind of positional decision making like what std::format offers. Why pay for overhead that isn't needed?\n\n> It's completely free to support, since we already have the facility, so I don't know why you just wouldn't.\n\nAre you referring to `std::to_chars` ? while that can be used for conversion of *some* types to string, there are two problems.\n\n1. there is no `std::to_chars_length` which can be used to determine the amount of space needed to store the result of a call to `std::to_chars`. This mean an intermediate buffer for the result of `std::to_chars`, either on the stack, or the heap. The stack is, of course, problematic for the generic case, as stack space is limited and when you start adding user specified types via argument dependent lookup, you could trivially blow out the stack.\n2. I don't know about other codebases, but my codebase already has `to_chars` functions that have signatures that aren't going to work with the `std::to_chars` signature. So doing ADL on a function named `to_chars` means I have to potentially go and fix several dozen thousand call sites. Not super fun, but I guess not the end of the world.\n\nAnd, of course, lets not even get into what an `E\u0302\u0303\u0363\u0342\u036b\u0312\u0341\u032b\u0323\u0323\u0333\u032fl\u031c\u0331\u0349\u0331\u0318\u034dd\u0329\u0348\u0320r\u0363\u0303\u0301\u0350\u0330\u0355\u0359\u0316\u0333i\u0306\u0367\u036e\u030b\u035b\u0335\u0323\u0323\u0326t\u0366\u0335\u0319\u0320\u032f\u0359\u0316c\u0367\u036a\u033d\u0362\u0349h\u0358\u0331\u0339\u0326\u0319\u0347\u0347\u0332` terror of an interface `std::to_chars` has... Apparently C++ can't decide whether std::error_code should be an output-reference-argument (e.g. std::filesystem) or a return value.\n\n> Moreover, and getting back to your delightful comment about this being an \"absolutely terrible suggestion\"... you could, for instance, implement concat(xs...) in a way that special cases the scenario where all the xs are string, string_view, char const*, or char (and possibly just any random-access sized range of char). That approach is not hard to do and does what you want, while also not limiting functionality.\n\nI was not saying that the idea of writing the function was terrible. I was saying the suggestion to submit a PR to fmt, or make a third party library that depends on fmt, was a terrible idea, as that does nothing about furthering p1228, it just implements yet-another-clone of p1228.\n\nFurther, like I alluded to in my original comment, as well as in a followup reply to myself, my job has had something very similar to p1228 for something on the order of 15 years, approximately. The original version was a C++98 \"hand written variadic\" template with 20 copy-pasta's of itself that accepted up to 20 string-like types to concatenate into a single buffer, with a \"one allocation only\" guarantee. C++11 made it possible to turn it into a single variadic template, but with lots of boiler plate and several helper functions. C++17 finally let me shrink it down to just a handful of lines, which was wonderful. But there's zero need for leveraging fmt / std::format for p1228. Adding a relationship there would be needlessly overcomplicated.\n\nTo repeat from my reply to myself, here's an implementation that's fairly similar to p1228 that only support string-like types. This isn't exactly what my work uses, but it's similar\n\nhttps://github.com/splinter-build/splinter/blob/10-string_concat/src/string_concat.h\n\n> What you need to compare to is format_runtime. \n\nNo, you don't. Certainly not for what you're talking about.\n\n> This is the version that got into the std::\n\n[Not anymore](https://wg21.link/p2216).\n\nAhhh, found out why string_concat was performing so much worse than appendWithReserve.\n\nMy call to std::strlen was doing a full string length search on the static constexpr string literals at the top of the file. Which is, of course, the *exact opposite* of what it's supposed to be doing when given constexpr.\n\nReplacing that with std::string_view and std::size() and my code gets comparable, sometimes better, sometimes worse, results to appendWithReserve\n\n> Now stringConcat consistantly beats appendWithReserve by about half, and beats fmt by about 100ns every time.\n\nNice.\n\nFor comparison purposes, here's an implementation of P1228 running in your benchmark: https://godbolt.org/z/G3xP4bqGb\n\n> I would say that I could probably get it down even further if I had the ability to ask the string to resize itself without also overwriting the newly resized data\n\nNote that when you write to memory that's not already in the processor's cache, the processor often responds by reading the cache line from RAM, because it doesn't necessarily know that you're about to write over everything.  But when something like string::resize is pre-allocating space and zeroing it out, it's often doing the zero'ing 32 bytes at a time using XMM registers, which means the processor often *does* know that the memory will be overwritten, and thus it doesn't have to read the data in.  In other words: sometimes it *is* faster to resize first, even if it means writing the data twice.\n\nAnd separately, note that some CPUs are actually faster at writing data if it's entirely zero - see https://travisdowns.github.io/blog/2020/05/13/intel-zero-opt.html\n\nIt is still not voted in, unfortunately, right?... I hope it does land, and gets applied back to C++20. Even if it does, and is just as fast as what p1228 proposes, I would still be happy with having std::concat. Something less general, simple, and part of standard string library. It just feels like it should be there, but it isn't (same as with many other things, like string-based to_lower and to_upper, case-ignoring find and comparison, simple join/split on strings). I know, that ranges fill a few of these gaps (let's hope http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2210r2.html lands). But it still feels a bit awkward and I believe people would prefer having these things additionally as additions to string library, with simple, high-level, not very customizable interface.\n\n> Replacing that with std::string_view and std::size()\n\nMaybe try string literals and `std::character_traits<char>::length()`?\n\nThanks for the followup on this. Since last year, I've been using a slightly improved version of the stringConcat function in the linked gotbolt, as well as having the use of `std::string::resize_and_overwrite()` gated around `#if defined(__cpp_lib_string_resize_and_overwrite)`\n\nAt one point I had a \"final\" godbolt link, but i can't find it. Sorry. \n\n> Note that when you write to memory that's not already in the processor's cache, the processor often responds by reading the cache line from RAM, because it doesn't necessarily know that you're about to write over everything. But when something like string::resize is pre-allocating space and zeroing it out, it's often doing the zero'ing 32 bytes at a time using XMM registers, which means the processor often does know that the memory will be overwritten, and thus it doesn't have to read the data in. In other words: sometimes it is faster to resize first, even if it means writing the data twice.\n\nThese are interesting considerations, and I'm very curious to see how this plays out with `std::string::resize_and_overwrite()`\n\nAs a consumer of `std::string::resize_and_overwrite()`, and not someone who's more than begrudgingly willing to mess around with benchmarking and trying to get the \"perfect\" implementation, i'm very hopeful that the standard library is emitting whatever instruction the CPU needs in order to understand \"don't bother prefetching, it'll just be overwritten immediately anyway\". Otherwise, it sounds like `std::string::resize_and_overwrite()` is potentially a pessimization -- which would rather defeat the point.\n\n> P1228\n\nYes, I'm aware of this paper, and am strongly in favor of seeing it added to the C++ standard. This is the kind of functionality that's *very hard* to implement yourself, but everyone can benefit from it.\n\nFor my stringConcat function that I use in my work codebase, i keep toying with the idea of implementing the proxy objects ( I think you call them concat_views ? ) and basically the rest of the paper, but never get around to it.\n\nFor your paper itself, one thing to be aware of is that it would be very helpful, at least to me, if there was a built-in way for me to make use of the concat_views and other machinery on a raw char* that i provide. I have several specialized string classes in my codebase that would be able to use this machinery, but only if i can control everything about the buffer being written to.\n\nanother consideration: \"std::concat\" makes me think i can concatinate more than just into std::string. The first thing some of my co-workers will try to do with this is `std::concat<std::list<thing>>()`. I know this because the first version of my `stringConcat` was just `blah::concat`, and several people complained that they couldn't use it with std::list. And yes, it was clearly documented in the documentation that it was only for strings.\n\n??? I don't even understand what we're talking about anymore.\n\nIf you think concat is useful, then implement it so that people can use it. That's really all I'm saying.\n\nWell, forgive my lack of clarity, but that's actually what I was using, i merely said \"std::strlen\" as shorthand for casual readers.\n\nI believe that /u/KaznovX was trying to communicate that having something like p1228 added to the standard would be better than something based on std::format (even if something based on std::format also existed) because \n\n1. Why standardize anything, anyway? That's been hashed hundreds of times, no need to reviit.\n2. Sometimes simple, but task-optimized, tools are better than complex but versatile. E.g. I reach for a regular screwdriver over my multitool even though my multitool has 3 different screwdriver-like things in it.\n\nIf I can editorialize a bit, it also appears that /u/KaznovX is opining on the standard library having a tendency to grow new capabilities that are hyper generalized to the point where the rest of us plebs either can't figure out how to use it effectively, or can't ever use it because it takes 3+ standard releases before we get even the rudimentary/limited version of it. I mean... have you seen `std::from_chars` ? That's a lot of rough edges to cut yourself on.\n\nReferencing his comment on http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2210r2.html, instead of basic dead-simple `std::string::split`being available in the language, er.. ever, we get controversial functionality like modules and co_routines, which have been much maligned and much applauded by various people. Other languages manage to achieve basic, if not super generalized, functionality like string splitting in their first major release. But here we are still carting around the ghost of C-language past with nul terminated string functions like strtok being the only standard-library function for doing some operations. And lets not forget that std::cstring_view was rejected https://github.com/cplusplus/papers/issues/189, continuing the pain-point that is needing c-standard library functions, but being unable to use them ergonomically or in a type safe way, because C++'s standard library provides few replacements.\n\nYou're in the EWG, so you have influence over this. Less new components, more \"flesh things out\" please. p1228 and p2210 would help. std::cstring_view would be great. std::filesystem::path_view would be sweet. Just in general some spit and polish over existing functionality would be much better than additions like std::format. The rest of the world has to live with the language that was published 1-3 releases ago. New shiny shit doesn't do us any good. A release that just focuses on rounding out the crufty edges would be *amazing*, and would be a hell of a lot easier to justify to my boss than \"Hey, I want a new compiler cause I want this fancy std::format library\". He doesn't care about std::format, we already have our own formatting library that we wrote 15 years ago. (Not that it's great or anything, but it' already there). But we *dont* have a string split function, or a std::cstring_view, and we want those.\n\nHuh? But char traits length is constexpr. Surely you can make it work. Did the string literal decay to a pointer?\n\nYou're welcome to take a look for yourself.\n\nhttps://godbolt.org/z/x79T8Ef57\n\nWhy C++ prefers decaying to a pointer over staying as a const-ref-to-array is beyond me.\n\nCrazy enough, the code gen for using `std::string::resize` and `std::copy` is *wayyyyy* less insane than using `std::string:reserve` and `std::string:append`.\n\nIt's a real shame that we can't have some kind of `std::string::resize_but_dont_initialize` function to skip the initialization of the string data, since we know we'll be overwriting it anyway.\n\nresize: https://godbolt.org/z/GTr9Mah5v\n\nreserve: https://godbolt.org/z/KjWfK5oM4\n\n> `static constexpr auto str1 = \"label\";`\n\n`str1` is already a pointer. `auto` is `const char*`.\n\n> It's a real shame that we can't have some kind of std::string::resize_but_dont_initialize function to skip the initialization of the string data, since we know we'll be overwriting it anyway.\n\nIt's been proposed for C++23. The problem with `resize_default_init()` (to use the standardese for \"try not to init\") is that the string after the call is in a partially initialized state and the Library Evolution didn't like that idea. Instead we're getting something like `resize_with_init(size_t, Callable)`.\n\nwhich is a mistake of the language. That should be a char[5]; Shame.\n\nThat's.... not better? The provided function can fail to initialize the data as well. Why make it more complicated for no actual improvement?\n\nTo quote Megadeath\n\n> Hindsight is always 20/20, but looking back it's still a bit fuzzy.\n\nBack when `constexpr` and `auto` were standardized, not many expected `constexpr` to become a thing it is today. Jason Turner has once said that, at the time, `constexpr` was kind of a joke. Without `constexpr`, you'd have run time initialization of those arrays, copying the string literal from `.rodata` segment. That's not fun to hide behind `auto` if the string is long. At least that's my attempt at rationalization, but I do agree that it would have been nicer if `constexpr auto foo = \"asd\";` were an array.\n\nEven so, my string_size() function is detecting them as arrays, so if you remove the \"is it an array?\" if-constexpr block, and default to std::size(), it removes the calls to strlen in the resulting assembly.\n\nSo the compiler clearly decided to do something more useful than what the standard wanted it to.\n\nThere are two solutions to that...\n\n```\nconstexpr auto&& foo = \"asd\";\n```\nThe `&&` is very good at preserving type, so if you pass foo to something, you'll find that foo refers to a `char const[4]`.\n\n```\nconstexpr decltype(auto) foo = \"asd\";\n```\nI despise the `decltype(auto)` terminology, but this is one of the cases it's designed for: `decltype(auto)` doesn't decay the thing that's assigned to it... so foo is a `char const[4]` here.\n\nI've had less than enough sleep last night to read assembly today.\n\nHere's the proposal for `resize_and_overwrite`: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p1072r7.html#R1\n\nIn case of string literals, just use `constexpr string_view`.\n\nMuch appreciated\n\nI mostly agree with you, but do remember that a \\`string\\_view\\` is 16 bytes and a \\`char const\\[4\\]\\` is only 4 bytes.", "id": "gvimupf", "owner_tier": 0.5, "score": 0.99999999984127}, {"content": "I use [std::ostringstream](https://en.cppreference.com/w/cpp/io/basic_ostringstream).\n\nIt is incredibly inefficient compared to even += the string.\n\nA sequence of += operations is generally what I do these days to concatenate multiple strings to a target string. Annoying but better than creating expensive temporaries I\u2019d have to throw away doing a + b + c to concatenate.\n\ndepends on the implementation", "id": "gvho1gf", "owner_tier": 0.1, "score": 0.23809523793650794}, {"content": "First: if this makes it to the standard it should be applicable to all containers.  I suppose `std::set` already has it with `std::set_union`\n\nIt really doesn't have to be applicable to all of them. All the containers have already a different API, and only std::string, std::vector and std::vector model a sequence, that can be grown. Out of them, concatenation is done most often on strings. I don't see how often would you need to concatenate more than 2 vectors or deques - and you can do that with .insert very quickly. For deque having this algorithm makes not much sense in the first place, since the memory is allocated in fixed-size blocks anyway.\n\nThe point is to have a good interface of concatenating multiple things convertible to string_view - char*, strings etc. To make sure that strlen is called as few times as possible. To take use of char_traits (in string_view constructor), that can be computed at compile time, contrary to strlen. You don't have to consider these things with concatenating spans into a vector.\n\nWouldn't set_union remove duplicates?\n\nYou are the one who brought up the standard library, not I.  The standard already has a lot of identifiers and functionality; if something is to be added it typically should be as general as possible, not special casing a single use case.\n\nSo first of all: you mention efficiency: you'd want it to be variadic to be as efficient as possible: `concat(a, concat(b, c))` can never be as efficient as `concat(a, b, c)` which among other things can do a single allocation for the result.\n\nSecond: if you are thinking of this issue, most (you're right, not every) container could use fast, efficient concatenation even if *you* only need one case.  However coming up with the right semantics for each case can be tricky.\n\nIt may be done for std::deque, std::list and std::forward_list too. With the specific case of rvalue parameters that may splice lists if allocators allow it. \n\nActually, concatenation between heterogenous containers may be really interesting too. \n\n> I don't see how often would you need to concatenate more than 2 vectors or deques - and you can do that with .insert very quickly.\n\nI got your point, but it would be very frustrating to have such algorithm only for strings where there is no real difference and it would just require a SequenceContainer.\n\nwell yes, but that's what you want with a set.\n\nI suppose `concat(set1, set2, set3)` should return the union of the three sets. as another way of doing `set_union` in this case.\n\nLooking at its signature, it looks like `std::set_union` can compute the union of two different kinds of containers, even returning a third type.  I suppose this new `concat` function would be the same, with  specializations for certain types.", "id": "gvhzkmr", "owner_tier": 0.3, "score": -1.587301577654808e-10}, {"content": "> `for (auto sub_view : views)`\n       `result.append(sub_view);`\n\nwhy do this, instead of \n\n> `for (auto &&sub_view : views)`\n       `std::copy(sub_view.begin(), sub_view.end(), result.end());`\n\n1) To avoid unnecessary <algorithm> dependency\n2) Because copying like that, without resizing is Undefined Behavior, right?\n\noh yeah, 2) is good point. I was forgetting that there is no way to resize string without overwriting memory.", "id": "gvk2t2n", "owner_tier": 0.7, "score": 0.06349206333333335}, {"content": "Regarding your implementation, you're using reserve, but you could be using resize; with resize you don't have to check on every append to see if you have enough space and possibly grow the buffer: you know you have enough buffer, so you can just copy the data directly.\nAnd yes, `std::format` can format numbers... but now that the standard library has a very efficient to_chars routine, support for concatenating numbers comes almost for free.  See https://gcc.godbolt.org/z/KT8s3bGec for an example implementation - and take a look at the difference in generated code!\n\nRegarding supporting other types, your second alternative is better than your first, but I'd prefer to write\n```\nauto s = std::concat(\"The answer = \", 42);\n```\nrather than\n```\nauto s = std::basic_string_concat<std::string>(\"The answer = \", 42);\n```\nBesides, `auto s = std::format(\"The answer = {}\", 42);` is already nice and terse, so I'd prefer to follow its lead.", "id": "iwk31wu", "owner_tier": 0.1, "score": -1.587301577654808e-10}], "link": "https://www.reddit.com/r/cpp/comments/mwb8i1/would_stdconcat_for_strings_be_a_good_addition_to/", "question": {"content": "Concatenating strings is one of the basic operations. However, there is still no functionality in the language, that allows to concatenate a few strings in the most performant way.\n\nOne of the simplest ways, that I managed to think of (that remains performant) is:\n\n    template <typename... T>\n    std::string concat(T&& ...args) {\n        std::string result;\n        std::string_view views[] { args... };\n        std::string::size_type full_size = 0;\n        for (auto sub_view : views)\n            full_size += sub_view.size();\n        result.reserve(full_size);\n        for (auto sub_view : views)\n            result.append(sub_view);\n        return result;\n    }\n\nIt still suffers from a few things: `string_view`s introduce a bit of redundancy, while we need just the lengths of the concatenated strings. Appends always append a null terminator and check capacity unnecessarily. Additionally, compilers fail to unroll the loops or propagate the constants through `string_views`s. It could be slightly improved with a lot of template-based unrolling, but we still won't be able to avoid overhead.\n\nMy point here is: there is no way to do it overhead-free from user code. Even if the code with little overhead is relatively simple - still, it is a basic operation on strings, provided in the standard library of many (if not the most) developed programming languages.\n\nThere is existing proposal for something like that, p1228. http://open-std.org/JTC1/SC22/WG21/docs/papers/2019/p1228r1.html\nIt is based an absl::StrCat(), but there are a few things I really don't like about it. Imho formatting is something completely independent from concatenating. We have now std::format, that can take care of formatting numbers, and it is efficient.\n\nHowever, std::format is, as currently specified by the standard, unfit for the purpose of efficient concatenation. Runtime analysis of formatting string is one of the problems - constexpr std::format is still far on the horizon and I don't see it landing in C++23. Without it, https://github.com/fmtlib/fmt/issues/1685 performance is worse than to simply += all the elements. `std::format(\"{}{}{}\", str1, str2, str3);` is a bit ugly, too. Meanwhile, std::concat would be a simple library addition. It is not dependent on constexpr arguments.\n\nAnother thing problematic with p1228 is, that it defines operations only on std::strings. With dropping number formatting support, it seems easy now to extend support for other string types. The interesting question is the API.\n\n    template<\n        class CharT,\n        class Traits,\n        class Allocator,\n        class... T>\n    basic_string<CharT, Traits, Allocator> basic_string_concat(T ...args);\n\nIs one way, but it seems unnecessarily verbose. I find:\n\n    template<\n        class String,\n        class... T>\n    String basic_string_concat(T... args);\n\na bit better, cause at the call point user knows, what type it wants to get.\n\nAnother way is a static method for std::basic_string. I can't find this kind of solution anywhere(?) else in the standard library, so I assume there is something wrong with it, but I'm not sure what exactly.\n\nI'd love to hear your thoughts on this. Am I missing something crucial here? Do you know if P1228 is still worked on? (I'm not on the mailing lists, so I could miss something there).\n\n(Repost, the original post have been removed by a spam bot)", "id": "mwb8i1", "title": "Would std::concat for strings be a good addition to the Standard Library?", "traffic_rate": 48.45232439769257}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "I prefer the functional language convention of `++` as a generic concatenation operator that applies to strings, arrays, lists, etc. Haskell, Erlang, and Scala (among others) all do this, although Scala still uses `+` for strings and `++` for collections. It seems like the closest thing to a cross-language consensus on a concatenation operator that isn't `+`.\n\nI'm also fond of C's use of juxtaposition for concatenation: `\"foo\" \"bar\" \"baz\"`\n\nIt feels like Haskell programmers came to regret this choice of operator since concatenation is not specific to a list of chars. Nowadays, the operator `<>` is increasingly used, which works for any semigroup, e.g., abritrary lists, vectors, `Text`, etc.\n\nI'm actually *not* a fan of C/C++'s automatic concatenation.  It's an easy way to introduce bugs when you're passing, say, an initialization list of tokens to a function, and you accidentally forget a comma.  I actually ended up changing my library's API partly because I got bit by this myself.  It's surprisingly hard to spot a missing comma when you're not looking for it.\n\nHonestly, I find that I've been so indoctrinated by C++ that I often copy it's language features without really considering alternatives.  I guess I don't mind Lua's approach of using ```..``` as an operator.  A lot of the other operators suggested don't really say \"concatenate\" to me, but I guess that's partially due to the heavy influence of C and C-like languages on general programming conventions.  Still, I don't think it's wise to push too heavily against established conventions if you're hoping for any sort of actual adoption.  It's important to balance idealism and pragmatism.\n\nNow I have to decide if I'm going to change Jinx's string concatenation operator from ```+``` to something else.  It's still in beta, and not too many people are using it yet besides me.\n\nThe concatenation in C is particularly useful when combined with macros, and when you consider the fact that there's no other way to concatenate strings, besides function that copy memory around. \n\nPython copied this feature, for no real reason, unfortunately.\n\nI'd say it really depends on if you want type coercion to happen with string concatenation or not. If not, using `+` is totally fine, and won't surprise anyone.", "id": "e8im4g6", "owner_tier": 0.3, "score": 0.8723404253191489}, {"content": "D also uses `~`, afaik.\n\nAll in all, I believe you shouldn't use operators at all for such a task, as an operator should be clear in it's task. Everyone knows `+` returns a sum of it's operands, but nobody would realize that `.`, `..` or `~` concatenates.\n\nInstead, I would use methods for such a thing, such as `a.append(b)` (Of course, that example assumes mutable strings).\n\nEven method names can be unclear. Sometimes moreso.\n\nThere isn't a lot of consensus on the meaning of `append` vs. `concat` across languages. The one consistent thing is that, if a `concat` method *does* exist, it usually means \"create a new collection that is the concatenation of these collections\". But I've seen `a.append(b)` used to mean any of four possible things:\n\n* Create a new list by concatenating the list `a` to the list `b` (same meaning as `concat`)\n* Create a new list by adding the element `b` to the end of the list `a` (a reverse `cons`)\n* Mutate `a` by adding all of the elements of the list `b` to the end\n* Mutate `a` by adding the single element `b` to the end (JS's `push`, Ruby's `<<`)\n\nIn dynamically-typed languages, this is especially bad: will `[1, 2, 3].append([4, 5, 6])` be `[1, 2, 3, 4, 5, 6]` or `[1, 2, 3, [4, 5, 6]]`?\n\nI agree that it shouldn't be an operator, but sure there is no reason that `a.append(b)` needs mutable strings. You can simply return a new string, which I would argue is the better approach anyway. There are very few cases where the correct approach is to modify a value.\n\nAnd everybody knows that \"+\" is a commutative operator, too. Therefore \"+\" and by extension any symbol that is used for a commutative operation is a poor choice IMO.\n\nA good symbol choice is a symbol whose graphics is not symmetric. \"/\" is not commutative and not symmetric; but it's usual meaning both in math and text, doesn't fit.\n\nD's choice is an ok one, it's an asymmetric symbol and reminds of the dash/hyphen which is used to join two words. However, in some fonts, it is displayed as if it were above an absent letter (because it's originally an accent - it also can cause trouble with some test editors for the same reason). Another good choice IMO is \"&\".\n\n\"a.append(b)\" and interpolation are probably too verbose for a language in which one manipulates strings often.\n\nYes that's kind of my point. `+` is universally accepted as addition. But there's no such standard for concatenation, even though it's very convenient to have a concatenation operator. So each language basically uses whatever is leftover for concatenation.\n\nEDIT: I think `~` is not great just because of how hard it is to reach on my keyboard.\n\nEDIT 2: I'd much rather have any 1 random symbol on my keyboard mean concatenation than not have a dedicated operator.\n\nThen in some languages there are different types of lists, what type would `concat(new LinkedList<>(), new ArrayList<>())`? There isn't a clear and clean solution.\n\nMy point was that `append` is a bad name for an immutable concatenation method.\n\n> A good symbol choice is a symbol whose graphics is not symmetric. \"/\" is not commutative and not symmetric; but it's usual meaning both in math and text, doesn't fit.\n\nIt is sometimes used for concatenating filesystem paths, which are effectively strings.  So it's not unprecedented to see something like `\"/etc\" / \"cron.d\" / \"foo\"`, but the resulting path includes the slashes when appending elements rather than working exactly like a string concatenation.\n\nJulia uses \"*\" instead of \"+\" for string concatination I presume because strings form a [monoid](https://en.m.wikipedia.org/wiki/Monoid?wprov=sfla1) over concatination. This unfortunately means that string concatination and list concatination are done differently.\n\n> concatenating filesystem paths, which are effectively strings. \n\nPlease don't say that :P. Even if the path is represented as a string internally, as a type, it is very much distinct from a string. It does not make sense to concatenate two absolute paths.", "id": "e8iidde", "owner_tier": 0.7, "score": 0.999999999787234}, {"content": "In languages like Erlang there is ++ for string concatenation.  \nThis operator also works with arrays or vectors. With vectors you can add the values together, or concatenate them.  \n[0,2,4]+[3,5,2] gives: [3,7,6]  \n[0,2,4]++[3,5,2] gives: [0,2,4,3,5,2]  \n\n\n\n", "id": "e8ijgmi", "owner_tier": 0.5, "score": 0.2340425529787234}, {"content": "P6 is a Perl. Some built in operations are strongly typed. Others weakly typed. It uses weak typing for its default string concatenation operator for the reasons you state.\n\nDevs can override this if they want strong typing typing instead:\n\n    sub infix:<~> (Str $l, Str $r) { &CORE::infix:<~>($l, $r) }\n    say 42 ~ 'bar' # compile-time error\n\nOr something more nuanced that's neither strong typing (compile time fail if not exactly the correct type) nor the default weak typing (coerce to string, warn if an argument is `Nil`, undefined etc.):\n\n    sub infix:<~> (Str(Int) $l, Cool $r) { &CORE::infix:<~>($l, $r) }\n    say 42 ~ 'bar'; # works\n    say 'bar' ~ 42; # run-time error\n\nFor string concatenation P6 uses `~`. (P6 uses `.` for method calls (including optional public lvalue accessors for attributes) instead of `->`; this was largely driven by the clear industry consensus, already evident by 2001, for adopting `.` for method calls.)\n\nThere were two primary reasons for choosing `~` as the symbol for an infix string concatenation op:\n\n* Availability on most keyboards globally;\n\n* Acceptance of use of shift on many keyboards because P6 supports string interpolation (`\"$foo $bar\"` is same as `$foo ~ ' ' ~ $bar`), including interpolation of code (`\"$foo: {$age+1}\"` is same as `$foo ~ ': ' ~ $age+1`), so idiomatic code tends to use the string concatenation operator less often than would otherwise be necessary;\n\n* Excellent mnemonic that's understood globally by all (it looks like a short piece of string for tying things together). I've never encountered a P6 dev or newbie finding it anything other than delightfully obvious and memorable.\n\nIn recent years several proglang designers that want a distinct string concatenation operator in their language have followed suit. This growing acceptance adds corresponding growing familiarity, a third reason to consider choosing it.\n\nP6 also supports a prefix `~` for coercion to a string. These all mean the same thing:\n\n    some-expression .Str\n    Str(some-expression)\n    ~some-expression\n\n(Aesthetically speaking, each has its place.)\n\nMy reason for mentioning this prefix op is that if you're going to have one in a language it makes sense to think about using the same symbol because of the added value in reusing its nice mnemonic simplicity for both functions. In contrast something like:\n\n    ++some-expression\n\nreads very oddly as a string coercion imo.\n\n\n\n\n\nI'm actually using `~` right now, but find it's in a bit of a hard place to type LOL. I might just stick with it though, since it's otherwise a good symbol and I don't have many alternatives (just due to the other symbols I've used up).\n\nEDIT: when I say Perl I mean Perl5, since no-one I know ever ever talks about Perl6, there's no confusion.\n\nRight. It's awkward for me too. Fortunately P6 has interpolation so Damian gets to say [\"you'll never use the concatenation operator again\"](https://www.youtube.com/watch?v=Nq2HkAYbG5o&index=92&t=11m&list=PLRuESFRW2Fa77XObvk7-BYVFwobZHdXdK) and get applause from a Perl crowd. :)\n\nI hear you about no one talking about P6. That'll change but it might take a decade.", "id": "e8ispch", "owner_tier": 0.3, "score": 0.2553191487234042}, {"content": "My language has no string concatenation operator\u2013you just use string interpolation. For example, instead of `%a + %b`, you do: `\"\\%a\\%b\"` (variables have a `%` prefix). It mostly works pretty well, except that `%foo += %baz` is less concise: `%foo = \"\\%foo\\%baz\"`. However, with languages that have immutable strings (like my language), it's more performant to build up a list of strings and concatenate them with a single function call instead of doing `+=` a bunch of times (which creates a lot of intermediate values). Because of that, I'm okay with the fact that the \"build a big string through incremental concatenations\" anti-pattern is verbose/awkward in my language.", "id": "e8iwtl9", "owner_tier": 0.3, "score": 0.17021276574468086}, {"content": "I generally prefer `*` for string concatenation, because the set of strings is just a free monoid with string concatenation as the monoid operation. Since monoid operations (as a generalization from group operations) are usually denoted with `*`, it makes sense to use `*` for string concatenation. I don't think we need different operators for string concatenation and scalar multiplication any more than we need different operators for e.g. scalar multiplication and matrix multiplication. The actual function called should be determined by the type as Python does it.\n\n(Of course, this reasoning is only valid if you expect your language to be used by people who have some understanding of abstract algebra.)\n\n>I generally prefer `*` for string concatenation, because the set of strings is just a free monoid with string concatenation as the monoid operation.\n\nHello? Julia? Is that you?\n\nI've never really been swayed by that argument. By that logic we should use `*` for concatenation in regexes and `+` for alternation, since these two operations over string patterns form a ring, but I've never seen anyone make that argument. Plus most people do not think of strings as a monoid under concatenation, even though they are.\n\nBesides the fact that I find the whole argument for `*` a little weak overall, it runs into the exact same problem as `+` where you have to explicitly convert the arguments to strings.\n\n\n\nProgramming is too serious to be left to retired math teachers.\n\nYou guys still insist on the fact that it's just \"executable math notation\" (this dates back to APL), mas[censored] with monoids and diffeomorphisms all day, and then screw the whole thing up with poor notation choices that completely ignore the basics of acceptable coding style (point-free or single letter variable names FTW, right?) AND are inconsistent -- well it's actually consistent with the long tradition of notation abuse both in math and physics (\"\u2200x\u220aA p(x) is not grammatically correct, but you know what I mean\"; see also [notation for integrals](https://math.stackexchange.com/questions/2038245/intuition-about-dx-in-integral-notation#2146635)).\n\n\"*\" is almost universally used as the multiplication operator, which is commutative and distributive. I know that the standard ASCII set of characters is quite limited, but why oh why use that one when &, #, ~, \\ or even % are free?\n\n\n\nI would say that the fact that people don't think about strings as a monoid under concatenation is no reason not to use `*`. Perhaps if we did, then more people would think about them that way. I think in general it would be good if people were more familiar with abstractions like that.\n\nAlso, having to explicitly convert arguments into strings seems to be an advantage, rather than a disadvantage, to me.\n\n>By that logic we should use * for concatenation in regexes and + for alternation, since these two operations over string patterns form a ring, but I've never seen anyone make that argument.\n\nWe don't use `*` for concatenation in regexes, but we do use a completely valid alternate notation for a ring. We use _juxtaposition_ for concatenation and `|` (the notation for logical disjunction, which is the additive operator of the ring of boolean algebra). Mostly, we do this to keep `*` and `+` free for the Kleene star and the Kleene plus, respectively, which seems perfectly reasonable to me. For strings, using juxtaposition for concatenation is undesirable, so it's better to go with the `*` notation. But I would also be perfectly happy with using `&` (logical conjunction, the multiplicative operator of the ring of boolean algebra) for string concatenation for the same reason that `|` works for alternation in regexes.\n\nYou're right that `*` is almost universally used as the multiplication operator, but multiplication is _not_ almost universally commutative. Multiplication is almost universally _associative_. For example, matrix multiplication, tensor multiplication, and quaternions multiplication are all not commutative. The use of `*` for string concatenation is appropriate precisely because string concatenation is _associative_ but not _commutatitve_, as is often the case for `*` (and this is particularly appropriate in numerical languages like Julia that already make heavy use of matrix multiplication and other non-associative uses of the `*` operator).\n\n>\"*\" is almost universally used as the multiplication operator, which is commutative and distributive. I know that the standard ASCII set of characters is quite limited, but why oh why use that one when &, #, ~, \\ or even % are free?\n\n* `&` is the least objectionable of all of these, since it's basically another form of `*` but for boolean algebras. Some languages do use `&`.\n\n* `\\` is not appropriate because it denotes division, which is almost _never_ associative, unlike string concatenation.\n\n* `%` is not appropriate because it denotes modular division, which is also almost _never_ associative.\n\n* `~` is (usually) not appropriate because it denotes logical negation, which is not a binary operator. Even if it doesn't denote logical negation in a particular language, it has no standard algebraic properties a programmer might be familiar with. Nothing about this operator choice helps a programmer understand string concatenation, unlike `*`.\n\n* `#` also has no standard algebraic properties, apart from being generally associated with numbers. Nothing about this operator choice helps a programmer understand string concatenation.\n\n\n\n`\\` is integer division, '%' is modulo ....\n\n\nI'm not saying it's a reason _not_ to use it, just that I think the arguments _for_ using it are a little weak. I'd be totally fine with C++ using `*` for string concatenation. It's better than `+` in my eyes (in a vacuum). \n\nOf course, I guess you could argue that `&` is decent as well, since it pairs nicely with `|` and that's already used to mean \"alternation\" in regexes and EBNFs, and `&` / `|` kind of form a \"multiplication / addition\" pair in my eyes. (Because of the fact that `&` is basically multiplication over booleans and `|` is kinda addition, plus the alternate notation for them in the boolean context is `*` and `+`.)\n\nIt's only really an advantage if your string concatenation operator is overloaded to mean something else as well. If you have an operator that means \"string concatenation, and nothing else\", all you gain by forcing people to explicitly convert into strings is extra boiler-plate and useless type errors when they forget this boiler-plate. What disadvantages do you see with implicit coercion when the language has a dedicated string concatenation operator?\n\nAs I mentioned in one of my other comments, I personally would prefer `&` to `*` because we've already gone down the `|` road with regexes and EBNFs. However, I don't think there's really gonna be a consensus any time soon. If you look at the comments there's lots of people arguing for many, many different choices.\n\n> The use of * for string concatenation is appropriate precisely because string concatenation is associative but not commutatitve, as is often the case for * \n\nDefine \"often\". * is commutative for naturals, rationals, reals, booleans and complex numbers. Those number you see and use *often*. \n\nThe standard notation for matrix multiplication is juxtaposition. I can understand that a PL uses \"*\" in the case of matrix mult because it makes the language more resilient to mistakes (especially if a statement/expression separator is not mandatory), but the choice of \"*\" goes against all sanity: your math-side arguments also apply to \"+\", and this symbol is commonly used by PLs as string concatenation.\n\nAs the other symbols I've mentioned, it's difficult to answer to your observations because they mix math notation and usual PL notations considerations. No sane conclusions can come out of that, one has to choose a main focus (either \"like math because our users like math\" or \"like the language our users used to use\") first.\n\nI would say that '|' and '&' are better thought of as union and intersection, the latter being a valid operation on regular expressions which is *not* concatenation and is perhaps more appropriate as a dual to alternation.", "id": "e8ij7vv", "owner_tier": 0.3, "score": 0.5319148934042554}, {"content": "Interpolation FTW.", "id": "e8ivusq", "owner_tier": 0.3, "score": 0.08510638276595744}, {"content": "I think in separate math ops from combinators, like this\n\n    ++ = append\n    -- = remove\n    ** = replace\n\n", "id": "e8iju5j", "owner_tier": 0.5, "score": 0.04255319127659574}, {"content": "[Fortress](https://en.wikipedia.org/wiki/Fortress_(programming_language)) had whitespace as an operator they called `juxtapose` and by allowing it to be overloaded, they implemented string concatenation without special symbolic operators:\n\n    \"there are \" itemCount \" items at the \" n+1 \" index\"\n\n&#x200B;", "id": "e8jc6mw", "owner_tier": 0.5, "score": 0.06382978702127659}, {"content": "I thought about this a fair amount recently, as well as discussing it with some people I know. Our goal is to make a beginner friendly language, so the conclusion we came to may be a little different than the general consensus. \n\nThat being said, it seems that the best choice is **not** to use an operator at all, but to use something like `a join b` or `append a to b`. This is much clearer to novice programmers, who find the concept of \"adding\" to strings quite strange, and will have similar feelings regarding `*`. Similarly, using operators like `.` and `..` is also confusing. I should note that these observations about beginner programmers are not just based on my intuition but also on a small survey I conducted (very small, n = 5).\n\nSomeone else suggested using a function with a name consisting of words, but also suggested that writing `a.append(b)` would require mutable strings. This is certainly not the case (e.g., in Python: `def append(self, b): return self + b`). \n\nFinally, I don't see why not having to add another operator is even a consideration when designing a language. It takes minimal effort to simply give an operator a name, and it can provide much benefit to give it a different name. As for languages with coercion, I firmly hold the stance that coercion is always wrong and should never be performed.\n\nHow is `a join b` not an operator? Unless your syntax is very, very bizarre, it looks exactly like an infix operator to me.\n\nWhen I asked all my friends, they said \"`+` for string concatenation is good\". I mentioned the issues above, they thought for a second then said \"still `+`\". Granted they're all programmers.\n\nI generally don't like coercion, since it can easily cause confusion, but I think in some cases it's the right choice. With Perl or PHP, `$a . $b` means \"concatenate `$a` and `$b`\", always. There's 0 reason to use `.` if you don't mean concatenate, so having the operator coerce both its arguments to strings feels like the right behavior to me in this particular case.\n\nThe distinction between function and operator is really arbitrary at best. Operators are functions that you can write in an infix manner, but you can also write functions in an infix manner in many many languages. In Haskell you can use any function as an infix operator, and in basically every OOP language you can do `a.f(b)`, which is hardly much different from using a function as an infix operator. Also, not that it's particularly important for this discussion, but the syntax for the language is quite non-standard (but hopefully intuitive).\n\nMy point is just that `+` for concatenation is not an intuitive thing. Considering your audience, I'm hardly surprised by the answers you got.\n\nIt's fine to have it convert the arguments to strings, but I don't see why you need coercion for this. You could just as easily define a function `concat :: (Show a, Show b) => a -> b -> String` which would always be able to convert it's arguments to strings and yet doesn't need coercion.\n\nI know that an operator is really just a function with a special name and way of calling it. I'll just let the question about `join` lie since I'm not familiar enough with your syntax to judge.\n\nI'm also opposed to `+` for concatenation, although for completely different reasons than you it seems.\n\nI mean, how is that different from coercion, to a user of the language?\n\n> The distinction between function and operator is really arbitrary at best\n\nI think technically, operators are supposed to return an element of the same set/type as the arguments. For example, string concatenation is an operator because the result is a string. Addition of two integers is an operator because the result is an integer.\n\nYou can easily find counterexamples in programming, I guess, like == which is called equality operator even though the result is a boolean regardless of the operands.\n\nFor what it's worth, there really isn't much different between `a join b` and `join a b` in the language. The point was really more that non-symbol named functions seem to be a better choice to me (even though they're a little longer), though clearly there are different situations which can affect which one is the better choice.\n\nI think the benefit to the user is that, if the language doesn't have type coercion, then they never have to worry about the type coercion working incorrectly. If your language has type coercion, but you're just not using it in this case, I'd agree that it provides little benefit (but like I said, I'm always opposed to actual type coercion). It also has the benefit of specifying in the type that it's going to convert the arguments to strings for you, and that you need to provide some mechanism for converting your values into strings.\n\nAn even better solution though would be to do something like the following so it's more extensible (but with a default so there's less work required; you could override the instance if you wanted):\n\n```\nclass Convert a b where\n    convert :: a -> b\n\nclass Concatable s where\n    concat :: (Convert a s, Convert b s) => a -> b -> s\n\ninstance Semigroup m => Concatable m where\n    a `concat` b = convert a <> convert b\n```\n\nI don't think I like this definition. It sounds like it would make basically every polymoprhic function an \"operator\". If I have `id :: a -> a`, it's return type is the same as it's arguments, but is the identity function an operator? And like you point out, there's things that typically are considered operators which don't follow this rule (like `==`). But also I find the distinction to be basically basically meaningless. Every operator, such as `+`, which I think it is safe to say is universally regarding as an \"operator\" (whatever exactly that means), may easily be expressed as a function.\n\nYou're gonna remake COBOL if you're not careful lol.\n\nI mean that only really works if you have a statically typed language. Otherwise, you don't really specify a type either way. When I say \"type coercion\" I'm talking about only the concatenation operator doing coercion, not having it as a language feature in general. Which I guess lands me in basically the same place as you.\n\nThis is where it comes from:\n\nhttps://en.wikipedia.org/wiki/Operator_(mathematics)\n\n\"In mathematics, an operator is generally a mapping that acts on elements of a space to produce other elements of the same space\"\n\nI guess that's just not true for programming, just like our functions are usually not really true functions.\n\nYeah hopefully not lol. At the very least, the semantics/paradigm are definitely quite different from COBOL's.\n\nIf it's a dynamic language, you can simply check type and dispatch at run time. Though it may not surprise you to learn I'm also overwhelmingly in favor of statically typed languages.", "id": "e8ikb9g", "owner_tier": 0.3, "score": 0.34042553170212764}, {"content": "I like `,` (comma) for string concatenation.  It has precedent in English written language (concatenate items in a clause using a comma) as well as arrays or lists in many programming languages (`[foo, bar, baz]` or `[1, 2, 3]`) and fits well with languages that treat strings as arrays-of-characters.\n\nHere's how it looks in J (which uses single-quote for strings):\n\n    'the value is: ', a_string_in_a_variable, ' more strings'\n\nContrast with the Python version of the same string, using the `+` operator:\n\n    'the value is: '+ a_string_in_a_variable+ ' more strings'\n\n\n[sidebar] J is dynamically typed, but does not implicitly coerce values to strings.  So if you have `foo` which is a string and `bar` which is not, then both `bar,foo` and `foo,bar` are errors.\n\nHow do you differentiate between concatenation and an enumeration of expressions?\n\ni.e. is [\"Hello\", \"World\"] an array with the two strings Hello and World or a single element array with the string HelloWorld?\n\nFunction calls are also interesting: foo(\"bar\", \"baz\"), does this call foo(String) or foo(String, String)?\n\nSmalltalk uses comma.\n\nSmalltalk does not use commas to separate items in arrays and Smalltalk method sends do not rely on commas either.\n\nArray\n    \n    #( 1 2 'three')\n\nMethod send\n\n    aDictionary at: aKey put: anObject\n\nI really like Smalltalk's syntax and find the cliche'd foo(x,y) to be really ugly.", "id": "e8isnbn", "owner_tier": 0.3, "score": 0.08510638276595744}, {"content": "How about a variadic function for concatenation?\n\n    var longString = concat(\"Welcome back \", userName, \", you last logged in \", daysSinceLastLogin, \" days ago.\")", "id": "e8jrn5d", "owner_tier": 0.5, "score": 0.04255319127659574}, {"content": "I'm inclined to like Haskell's `++` operator.  However, what's important is that the syntax is visibly different from the arithmetic operator, not the exact punctuation.  This makes sense even in a statically-typed language, so it's kind of a no-brainer for a dynamically typed language.\n\nIn my project, the native string interface starts out as \"list of codepoints\", so (as in Haskell) the concatenation operator is shared with lists, which act as a universal iterator interface.", "id": "e8j31f3", "owner_tier": 0.3, "score": 0.021276595531914896}, {"content": "Mathematica uses \"string1\" <> \"string2\". I kind of like it, if ~ isn't available. \n\nIt's not bad except the in place version isn't the prettiest (`<>=`).", "id": "e8izd28", "owner_tier": 0.3, "score": 0.021276595531914896}, {"content": "[My language](https://easylang.online/ide/) does it like BASIC:\n\n    print \"3 + 4 = \" & 3 + 4", "id": "e8jb6pm", "owner_tier": 0.1, "score": -2.1276595615372958e-10}, {"content": "To offer a different perspective: According to wolfram mathworld, concatenation is often written as `a||b`, and in mathematica it's `a<>b`. I kind of like those because the same operator would be usable on numbers, lists and what have you.\n\nYes, that's exactly why i support having a distinct concatenation operator, whatever notation you may choose.", "id": "e8jfp5s", "owner_tier": 0.3, "score": 0.021276595531914896}, {"content": "I don't like the use of  `+` as a string concatenation operator. `+` is often an associative and commutative operator and is no longer that when using it to concatenate string together. Since C# (the language I use the most at work) has support for string interpolation, I found myself using string concatenation less and less. And this post make me realize that I am OK to write `$\"{a}{b}{c}\"` to concatenate a,b and c (even if there are string and no conversion happen there).\n\nTo be fair, `+` floating point addition isn't associative but we still use `+` to denote it.\n\nIn practice, it doesn't matter much for floating point as they are weird beasts to begin with. On the other hand, mixing string concatenation with `+` and implicit conversion start to get weird.\nFor instance this code is not really obvious:\n```\nvar x = 5;\nvar y = 6;\nvar str = \"x+y=\" + x + y;\n```\nShould it print `x+y=11` or `x+y=56`?\n\nYes, I'm just being pedantic by mentioning floating points.\n\nI think I mentioned that exact issue with weak typing and reusing an operator for string concatenation in my post.\n\nJS will give you the second option because `+` is left associative, which is kind of counter intuitive.", "id": "e8jioi5", "owner_tier": 0.3, "score": 0.06382978702127659}, {"content": "My 2c, but `+` is probably better suited to things that behave specifically as rings (i.e, integers, floats, complex numbers, polynomials, matrices, and things that can be \"multiplied\" and \"subtracted\"). `+` implies the operation is commutative (i.e `a + b = b + a`) which is not true for concatenation. The generic \"combine\" operator is often denoted as `<>`, and we don't assume that the operation is commutative. You could use whatever you like I suppose, perhaps a vertical bar (`|`)?\n\nTo be fair, `+` is also associative normally, but that doesn't hold true for floating point numbers and I've never seen anyone complain.", "id": "e8jvv8i", "owner_tier": 0.7, "score": 0.021276595531914896}, {"content": "Ada uses &", "id": "e8kstst", "owner_tier": 0.5, "score": -2.1276595615372958e-10}, {"content": "In ruby you can use + but you can also use <<. Acutually in ruby there is a third way which is quite cool. Simply put two strings together without an operator but this only works for string literals not variables.\n\n", "id": "e8kz3vf", "owner_tier": 0.7, "score": -2.1276595615372958e-10}], "link": "https://www.reddit.com/r/ProgrammingLanguages/comments/9ropwa/string_concatenation_syntax/", "question": {"content": "A lot of languages use `+` for string concatenation. This is a fine choice for statically-typed languages (actually I'd say good choice because you don't have to add an extra operator), but not so good for dynamically-typed languages.  \n\n\nIf your language is dynamically-typed, weakly-typed, and uses `+` for concatenation, you run into the JS issue of not always knowing whether `a + b` is going to add or concatenate, which can lead to subtle bugs when it does the wrong thing.  \n\n\nIf your language is dynamically-typed, strongly-typed, and uses `+` for concatenation, you run into the Python issue of having to always convert everything to strings when you're concatenating, which feels like unneeded extra typing. (Although I much prefer this to the JS issue.)  \n\n\nIn something like Perl or PHP, you have a separate operator for string concatenation (`.`). So `$a + $b` always means add, `$a . $b` always means concatenate (coercing `$a` and `$b` to strings if needed). To me, this feels like the best of both worlds.\n\nHowever, there doesn't seem to be much consensus on which operator to use (as shown by all the options below):\nhttps://en.wikipedia.org/wiki/Comparison_of_programming_languages_(strings)#Concatenation\nhttps://www.rosettacode.org/wiki/String_concatenation\nhttp://rigaux.org/language-study/syntax-across-languages.html#StrngStrnCnct\n\nWhat did you guys do for string concatenation? What influenced your choice of operator (if you gave it much thought)? Anything I overlooked in my (short) analysis above?", "id": "9ropwa", "title": "String Concatenation Syntax?", "traffic_rate": 16.86659877800407}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "Asking for the \"most efficient\" way of doing something like this in this sub is a dangerous game.\n\nParticularly since most posters are writing about what they think, not about what they measure.", "id": "l7vvpcc", "owner_tier": 0.7, "score": 0.9999999999280575}, {"content": "fmt doesn't have to know the number of pieces at compile time if you use join", "id": "l7w56n0", "owner_tier": 0.3, "score": 0.1294964028057554}, {"content": "Maybe `std::format_to` if you are not stuck in the past, although it might still be a bit verbose and I'm not sure how well it performs.", "id": "l7wgsr9", "owner_tier": 0.3, "score": 0.12230215820143885}, {"content": "Verbosity is not a problem here because you should only write this function once and call this function every time you need to build a string. If you look at the StringBuilder source code, it will also be verbose but you don\u2019t care about that.", "id": "l7wuhwa", "owner_tier": 0.5, "score": 0.10791366899280574}, {"content": "You can use auto & obj to avoid copying the obj. \u00a0\n\nYou can do str += \u2018!\u2019; as that\u2019s one char but \u201c!\u201d is 2 chars and char const * is unknown length.\n\nCalculating the string length to start will save re-allocations.\n\nnote that manually reserving space for the stuff you add to the string is likely only more efficient than not doing so if you can calculate the length of the *ENTIRE* string.  \nmanually reserving the size needed every iteration of the loop is probably less efficient than the natural exponential growth of the string.  \nalso note that since the part you are adding to the final string is also \"dynamic\", reserving memory manually specifically for it might be a good idea.", "id": "l7vwols", "owner_tier": 0.5, "score": 0.1798561150359712}, {"content": ">I could perform a first iteration to count the total size,\n\nYou don't have to calculate the *exact* size. If you just know the *approximate* size, you can reserve that amount. For example, a simple guess at `str.reserve(1000)` might reduce the reallocations to 1 or 2.\n\n\"Good enough\" often beats \"perfect\".\n\nIn particular, it's important to remember than _anyway_ strings to have excess capacity beyond their length -- to offer amortized O(1) push.\n\nThis is important because computing the exact length can be complicated: computing how many bytes it'll take to represent a float may require as much work as formatting it...\n\nThus, in the case you can't get the _exact_ size, you shouldn't instead to _slightly_ overestimate instead. You'll still get a single allocation, and most of the time it'll be just as much memory as if you had estimated exactly anyway.\n\nAnd of course, if it's a hot-loop, reuse the allocation. Over and over.\n\n>computing how many bytes it'll take to represent a float may require as much work as formatting it...\n\nThis is why I think bound-checked interface for `std::to_chars` is pretty stupid. If your buffer is large enough to hold any output, then there is no need to check for the bound, but it's incurred anyway. If not, the only way to use `std::to_chars` safely is to use double-buffering, i.e., prepare a large enough temporary buffer, do the formatting there with completely pointless bound-checking added for free (and no, compiler doesn't elide it even with deep inlining), and then copy it to the primary buffer. Even funnier is that common implementations of floating-point `std::to_chars` already does this exact double-buffering internally (for the \"general precision form\") because otherwise conforming to the bound-checked interface specification becomes very complicated. So if the user does this double-buffering on top, then now it's actually triple-buffering with two successive copies under the hood. This is not good for a function that is supposed to be very fast.\n\nI know people these days are hyper-allergic to UB (especially the Dreaded Buffer Overflow\ud83e\udd2a), but still... I honestly think s`td::to_chars `should have been specified with no bound-check, of course with UB for too small buffers. Or if UB is too scary, they could have been much more lenient with the buffer bound validation, like, allowing implementations to reject any buffer that is not large enough to hold any possible outputs even if it is large enough to hold the output of the specific input, or something like that. Or, they could provide two versions of s`td::to_chars,` one with UB (but also with a scary name), another returning a constant-sized string (so both cannot fail).\n\n> This is why I think bound-checked interface for `std::to_chars` is pretty stupid. If your buffer is large enough to hold any output, then there is no need to check for the bound, but it's incurred anyway.\n\nWhat's the cost of this check?\n\nFor integers, the fastest integer formatting routines require pre-computing the number of digits ahead of time to avoid double-buffering. This is because formatting occurs right-to-left, so you need to know how many digits the integer will span to be able to place the rightmost digit in its exact spot from the get go.\n\nAnd if you know, before starting formatting, exactly how many digits the integer will span, then you can bounds-check for nearly free: it's not the computationally intensive part.\n\nGiven how computationally intensive formatting _floats_ is, I'd guess that any bounds-check is just noise.\n\n>For integers, the fastest integer formatting routines require pre-computing the number of digits ahead of time to avoid double-buffering. This is because formatting occurs right-to-left, so you need to know how many digits the integer will span to be able to place the rightmost digit in its exact spot from the get go.\n\nI'm not aware of anything faster than the one by [James Edward Anhalt III](https://github.com/jeaiii/itoa), and this one doesn't compute the length upfront. Rather it builds a giant if-else branches based on the length of the input and follows completely separate code paths for each branch. So if you want to bake bound-checking there, you need to modify all branches. I don't know how much cost it will incur, but it's not a single if-block.\n\nFor floating-point numbers, it's definitely not just noise, it has measurable impact. It's somehow lost at this point but I did have benchmark data containing both of the MS STL `std::to_chars` implementation and the upstream Ryu, and they did show a clear gap in between. `std::to_chars` does more than just bound-checking on top of Ryu though, like branching on the format/precision parameters and etc.. (I actually also consider that interface kinda weird... but that's a separate topic.)\n\n*(EDIT: Actually, now I guess, maybe the gap was mainly due to finding the shortest format between fixed vs scientific and I have to do the experiment again with the scientific format specified. I think it's possible that the gap will be shortened a lot to indeed render it as just noise.)*\n\nAlso, note that the above comment is just entirely about the shortest-roundtripping case. For the user-specified precision case, this bound-checking gets more hairy, and I'm quite sure the cost in that case is much higher. Which may sound contradictory, as in some sense the user already provides how long the output would be with the precision argument. But that's indeed the case *only* if the user requests the scientific format. For the fixed-point and the general formats, especially the general one (in particular with the enforcement of no trailing zero), there are near infinite amount of little details that make the strict bound-checking spec quite challenging to conform. I had to modify my [floff](https://github.com/jk-jeon/floff) implementation quite a lot because of this when I contributed to Boost.CharConv. Also as I said this is why `std::to_chars` (and `boost::charconv::to_chars` as well) writes to a temporary buffer and then copy it back to the user-provided one, for the general precision form.\n\nNow, if you ask me, fine but still, is the cost of bound-checking that really high to an extent that actually can cause some trouble, then well, I don't know, I guess not. I'm probably quite biased because maybe I have been obsessed with writing the fastest possible implementation, just for the sake of its own, rather than because of any real applications I had in mind. Nevertheless, my point is that the benefit of this incurred cost is very questionable, because as I pointed out, in general there is *no way* to successfully use `std::to_chars` without preparing a large enough buffer from the very first place. And it's doubly silly to require the users to do so *given* that the bound-checking spec more or less *requires* the implementations to internally prepare such a buffer already. They could have just returned this internal buffer directly to the user. (To be precise, it is possible to avoid this internal buffer, but that will probably incur even more performance cost.)\n\n> I'm not aware of anything faster than the one by James Edward Anhalt III, and this one doesn't compute the length upfront. Rather it builds a giant if-else branches based on the length of the input and follows completely separate code paths for each branch. So if you want to bake bound-checking there, you need to modify all branches. I don't know how much cost it will incur, but it's not a single if-block. \n\nI was not aware of this implementation.\n\nThe implementation I had in mind is roughly the countlut implementation -- though I do tend to prefer a loop by 10K, to minimize the code footprint -- whose performance seems roughly in line with `{fmt}` on the benchmarks.\n\nI tweaked the benchmark code a bit at https://godbolt.org/z/7fv4qq81P to have a better look at things:\n\n - Using DoNotOptimize on the statically generated input, so the compiler cannot optimize for the input.\n - Using DoNotOptimize on the generated output, so the compiler cannot optimize away the writes.\n - Hoisting the functions into `noinline` wrappers to be better isolate their code, making it clearer in the assembly output.\n\nThis quite drastically changed the output that godbolt gives me, compared to the README: the difference between jeaii and fmt is much less stark after the changes, though jeaii does retain a slight advantage in CPU (though not in Time).\n\n    -----------------------------------------------------\n    Benchmark           Time             CPU   Iterations\n    -----------------------------------------------------\n    BM_fmt           14.8 ns         8.53 ns     79802313\n    BM_jea           15.6 ns         8.05 ns     89378571\n\nI also peeked at the assembly. I was pleasantly surprised that despite the massive amount of branches in the (inscrutable) code, the compiler seems to have ripped through them, and only 4 conditional jumps remain. That's quite impressive.\n\nThe code is a bit less tight than fmt, though:\n\n - jeaii: ~140 lines of assembly and 200 bytes table.\n - fmt: ~70 lines of assembly and 128 bytes table.\n\nThis means jeaii will bloat the cache a wee bit more, an effect not demonstrated in micro-benchmarks.\n\nIt's an impressive feat, regardless, and I thank you for making me aware of it. I was still \"stuck\" at countlut variants -- whose performance matches that of fmt in the benchmarks, it seems.\n\nI'll keep the link, as I'd like to explore its performance more on specific integer sizes... I just have to think how to get that without training the branch predictor...\n\n> Also, note that the above comment is just entirely about the shortest-roundtripping case. For the user-specified precision case, this bound-checking gets more hairy, and I'm quite sure the cost in that case is much higher\n\nI expect shortest-roundtripping may have the highest latency, indeed, though even with user-specified precision getting the rounding correct properly makes things complicated.\n\n> in particular with the enforcement of no trailing zero\n\nI have some fixed-point formatting rountines that remove trailing zeroes, and I haven't really optimized the removal.\n\nOn the other hand, in terms of buffer management, I use a simple branch:\n\n 1. Ideal case (hinted as \"likely\"): the buffer is large enough for the worst-case => I format directly in the user-provided buffer with the core (non-checking) routine.\n 2. Short case: I call a never-inlined function which prepares a large enough side-buffer, calls the core routine, then check if the user-provided is actually large enough and if so copies from side-buffer to user-provided buffer.\n\n(Note that the never-inlined function can still get const-propped when the routine is called with a constant, at the compiler's whim, it's never-inlined, not cold)\n\n(And yes, this is ruthlessly optimizing for users passing large enough buffers at the expense of others taking a 5ns hit due to the function call; other approaches which keep a flag, etc... slow down the ideal path a bit)\n\n>  Nevertheless, my point is that the benefit of this incurred cost is very questionable, because as I pointed out, in general there is no way to successfully use `std::to_chars` without preparing a large enough buffer from the very first place.\n\nWould you happen to know if `std::to_chars` uses the same approach as I highlighted above?\n\nIn my experience, this single \"check for worse case\" bounds-check is invisible performance wise. It's a `cmp` against a constant, followed by a well-predicted jump as long as the user keeps providing large enough buffers.\n\n>This quite drastically changed the output that godbolt gives me, compared to the README: the difference between jeaii and fmt is much less stark after the changes, though jeaii does retain a slight advantage in CPU (though not in Time).\n\nBenchmarking on godbolt is very unreliable. I tried to run [https://github.com/jeaiii/itoa-benchmark](https://github.com/jeaiii/itoa-benchmark) and got the following results:\n\n[https://jumpshare.com/s/vO6ltUPm5EZZJZV8mQUz](https://jumpshare.com/s/vO6ltUPm5EZZJZV8mQUz) (32-bit unsigned) [https://jumpshare.com/s/p3oxkgULShHviwlvZTkZ](https://jumpshare.com/s/p3oxkgULShHviwlvZTkZ) (64-bit unsigned)\n\n(The benchmark was buggy and I had to fix it... it relied on the expectation that signed overflow should behave \"as usual\", and somehow the compiler leveraged this UB in a weird way to make the program falls into an infinite loop. Quite funny urghhhh! And if you ever want to try it yourself, please be aware that there was another bug trying to substitute `0` to `void*` in SFINAE constant evaluation context, resulting in substitution failure that is not intended. Also, the whole project is very Windows-y and probably it's impossible to build it on other platforms. James Anhalt is a game programmer and it seems he doesn't care very much about anything other than MSVC. I ran the benchmark with clang-cl though.)\n\nIn case it is not clear, URND\\_LEN means samples are of uniformly random length, which supposedly most harshly penalize the giant branch approach.\n\nAlso, AFAIK the table size for jeaiii is like 400 bytes, and that for fmt is like 200 bytes IIRC (maybe [this](https://github.com/fmtlib/fmt/blob/c4ea903250e20c3ffa9b70695c33207dc9b9a0e2/include/fmt/format.h#L1113)?).\n\nBy the way, the giant branch is not the \"main idea\" of jeaiii, rather it's on the trick of converting the input into a \"fixed-point fraction form\", as I explained in my [blog](https://jk-jeon.github.io/posts/2022/02/jeaiii-algorithm/). I can imagine another implementation that uses the same fixed-point fraction trick but with the length computed upfront instead of giant branches. I'm not sure how well that will turn out to, though.\n\n  \n(Reddit doesn't allow me to post a lengthy comment)\n\n>I expect shortest-roundtripping may have the highest latency, indeed, though even with user-specified precision getting the rounding correct properly makes things complicated.\n\nIn my experience, shortest-roundtripping case was actually way easier than the rounding mess that I had to juggle with for the given precision case. Of course the given precision case can perform better if the specified precision is small enough (while the corresponding shortest-roundtripping output has much more digits), but I think maybe the given precision case would be slower if the length is comparable. Didn't try to benchmark though.\n\n(To give some more (aka too much, sorry) context, Ryu-printf, the algorithm used for all existing `std::to_chars` implementations atm for the given precision case, performs wider-width integer multiplications than Ryu/Dragonbox/whatever shortest-roundtripping algorithms do. Since this wide-int math is the main bottleneck of this business, it's quite possible that even for the short length case Ryu-printf may perform worse than shortest-roundtripping algorithms. And this shortcoming was one of the main motivation behind [floff](https://jk-jeon.github.io/posts/2022/12/fixed-precision-formatting/). Since floff basically fixed this issue, I guess it would probably perform better than shortest-roundtripping algorithms if the precision is small enough. But I don't have any data point to backup any of my claims.)\n\n>On the other hand, in terms of buffer management, I use a simple branch: Would you happen to know if `std::to_chars` uses the same approach as I highlighted above?\n\nI think when I looked at Stephan T. Lavavej's implementation, it seemed to me that it tried to avoid using a tempoary buffer as much as possible. He \"gave up\" on the given-precision, general format case though. Maybe let's ask him directly: u/STL!\n\nAnother thing I want to say is that, while your approach does make a lot of sense for the shortest-roundtripping case, however, for the given precision case with either fixed-point or scientific formats, the required length can grow indefinitely if the user requests too large precision. For the general format case (with trailing zero removal) the length is bounded, but the maximum length is way above what users usually would ever want to see. So for the given precision case I think this painful bound-check fiddling is basically unavoidable, and it does incur meaningful overhead.\n\nYeah, for the zero-trimming, it was either use a temporary buffer, or implement a complicated (and probably slow) finite state machine to avoid emitting digits. It took me forever to realize that I could put a reasonable upper bound on how big the output could possibly be, and that this could be placed on the stack (since I had a hard constraint of no dynamic memory allocations): https://github.com/microsoft/STL/blob/e36ee6c2b9bc6f5b1f70776c18cf5d3a93a69798/stl/inc/charconv#L2400-L2405\n\nI was able to cleverly avoid having to convert twice (an improvement over what the UCRT does for classic `printf`). See: https://github.com/microsoft/STL/blob/e36ee6c2b9bc6f5b1f70776c18cf5d3a93a69798/stl/inc/xcharconv_tables.h#L24-L76\n\n>I was able to cleverly avoid having to convert twice (an improvement over what the UCRT does for classic printf). See:\n\nI didn't really understand what this is supposed to do when I first read it some months ago, and now I get it: to determine fixed vs scientific. This is interesting!\n\nI just gave up deciding it upfront and ended up doing a \"post prettification\", after all digits are generated and possible rounding adjustments has been done: https://github.com/boostorg/charconv/blob/8e46c8869f45494677487cfbdf0c164b7a5bdfea/include/boost/charconv/detail/dragonbox/floff.hpp#L3819\n\nOf course I had to perform an additional `std::memmove` to move the printed digits around, but I feel like this cost can be avoided because we are printing on the temporary buffer anyway.", "id": "l7xk02o", "owner_tier": 0.5, "score": 0.19424460424460432}, {"content": "Use Google\u2019s [absl::StrCat](https://abseil.io/docs/cpp/guides/strings#abslstrcat-and-abslstrappend-for-string-concatenation). I have no regrets depending on Abseil. It is well maintained and the maintainers are responsive.", "id": "l7wz8mx", "owner_tier": 0.3, "score": 0.057553956762589925}, {"content": "Use `std::stringstream`. Using `operator+` on strings is rarely a good idea, especially for accumulating strings, because it reallocates on every operation.\n\nstd::string has the same allocation behaviour as std::vector, AFAIK. So you can either reserve() if you know the size in advance, or let exponential growth take the sharp edges of growing the string.\n\nUsing streams is absolutely atrocious and that class should likely not be used under any circumstances.\n\nAs far as performance goes, naively stringing (pun intended) together a bunch of ```operator +``` is 4x faster than using streams, and if you're able to preallocate some memory in advance it can be upwards of 30x faster:\n\nhttps://lemire.me/blog/2023/10/19/for-processing-strings-streams-in-c-can-be-slow/\n\nIt's not the case that every operation has to result in an allocation; move semantics allow one side of the ```+``` operation to allocate an exponentially increasing amount of memory so that the number of allocations is logarithmic in the size of the string. This means that if you chain together ```a + b + c + d + ...```, the initial ```a + b``` will produce a temporary ```std::string```, but that object can be reused as an rvalue reference in every successive append operation thereafter with its memory increasing exponentially.\n\nIn this case each + is making a temporary string, that's a lot of allocations/deal locations. I am not aware of any compiler successfully eliminating these superfluous objects\n\nNonetheless, a sequence of appends into the output string, without temporaries, is generally going to outperform `a + b + c + d + ...`\n\nPre-allocated as in following should work using placement new?\n\n`void* pre_allocated_memory = malloc(SIZE);`  \n`std::string* str = new (pre_allocated_memory) std::string;`\n\n>I am not aware of any compiler successfully eliminating these superfluous objects.\n\nEveryone of them does. That's why ```operator +``` is overloaded to work with rvalue references:\n\nhttps://en.cppreference.com/w/cpp/string/basic_string/operator%2B\n\nBecause of those overloads, the sequence ```a + b + c + d + ...``` works similar to the following expression:\n\n    [&] () {\n      std::string t1 = a + b;\n      t1.append(c);\n      t1.append(d);\n      t1.append(...);\n      return t1;\n    }()\n\n```t1.append``` can allocate exponentially more memory similar to how ```std::vector``` grows, meaning amortized constant time.\n\nAFAIK operator+ is not always generating a temporary string.\n\nNote that `+` on temporaries (`&&`) reuses the temporary instead of allocating, so actually `a + b + c + d + ...` is as efficient as manually calling `+=` for each.\n\nNo, preallocated using ```std::string::reserve```:\n\nhttps://en.cppreference.com/w/cpp/string/basic_string/reserve\n\nYou're 100% right! Thanks for correcting me!\n\nIt even issues a reserve for good measure. Still it seems to generate a very significant bunch of extra stuff that I don't have a great explanation for, and it even issues a few deletes, could you please point out if I'm doing anything wrong? (Last time I checked this I must have seen those deletes and immediately assumed they were the temporaries being deleted, I hope you'll understand my misunderstanding):\n[godbolt.org/z/PM51sjzM4](http://godbolt.org/z/PM51sjzM4) \nFeel free to change the code to be equivalent, I'm sure that I've missed something. I've tried with both append and +=", "id": "l7vqfur", "owner_tier": 0.3, "score": 0.6906474819424461}, {"content": "So if I follow, you want `\"First \"` then `\": {}!\"` for every item, where `{}` is number and then optionally `-obj.get_extra()`.\n\nPerf aside, I think I'd write this as something like this, because it's explicitly stating how one item is formatted, then formatting a view of those joined together.\n\n    auto fmtOneItem = [](const auto& obj) {\n        return obj.has_extra() ?\n            fmt::format(\": {} - {}!\", obj.number(), obj.get_extra()) :\n            fmt::format(\": {}!\", obj.number());\n    };\n    auto str = fmt::format(\n        \"First {}\",\n        fmt::join(list | std::views::transform(fmtOneItem), \"\")\n    );", "id": "l7w1ktv", "owner_tier": 0.3, "score": 0.04316546755395684}, {"content": "I ran some more benchmarks with some of the suggestions in this discussion, using Visual Studio 2022 (v143), Release Build, C++ 20, /O2.\n\n    #include <iostream>\n    #include <string>\n    #include <vector>\n    #include <charconv>\n    #include <chrono>\n    #include <format>\n    #include <cassert>\n    \n    class Foo \n    {\n        std::string word_;\n        std::size_t number_;\n        bool has_extra_;\n        std::string extra_;\n    public:\n        Foo(std::string word, std::size_t number, bool has_extra, std::string extra)\n            : word_(word), number_(number), has_extra_(has_extra), extra_(extra)\n        {\n        }\n    \n        const std::string& get_word() const\n        {\n            return word_;\n        }\n    \n        std::size_t number() const\n        {\n            return number_;\n        }\n    \n        bool has_extra() const\n        {\n            return has_extra_;\n        }\n    \n        std::string get_extra() const\n        {\n            return extra_;\n        }\n    };\n    \n    std::size_t estimate_length(const std::string& first, const std::vector<Foo>& list)\n    {\n        std::size_t length = first.size();\n    \n        for (const auto& obj : list)\n        {\n            length += obj.get_word().size()\n                + 2\n                + 10 // number estimate\n                + (obj.has_extra() ? (3 + obj.get_extra().size()) : 0)\n                + 1;\n        }\n        return length;\n    }\n    \n    std::string test1(const std::string& first, const std::vector<Foo>& list)\n    {\n    \n        std::string str = first;\n        for (const auto& obj : list) {\n            str += obj.get_word() + \": \" + std::to_string(obj.number());\n            if (obj.has_extra()) {\n                str += \" - \" + obj.get_extra();\n            }\n            str += \"!\";\n        }\n    \n        return str;\n    }\n    \n    \n    std::string test2(const std::string& first, const std::vector<Foo>& list)\n    {\n    \n        std::string str;\n        str.reserve(estimate_length(first, list)+1);\n        str.append(first);\n        for (const auto& obj : list) {\n            str += obj.get_word() + \": \" + std::to_string(obj.number());\n            if (obj.has_extra()) {\n                str += \" - \" + obj.get_extra();\n            }\n            str += \"!\";\n        }\n        return str;\n    }\n    \n    std::string test3(const std::string& first, const std::vector<Foo>& list)\n    {\n    \n        std::string str = first;\n        char buffer[255];\n        for (const auto& obj : list) {\n            str.append(obj.get_word());\n            str.append(\": \");\n            auto result = std::to_chars(buffer, buffer + 255, obj.number()); // assumes C++17\n            if (result.ec == std::errc{})\n            {\n                str.append(buffer, result.ptr - buffer);\n            }\n            else\n            {\n                // error\n            }\n            if (obj.has_extra()) {\n                str.append(\" - \");\n                str.append(obj.get_extra());\n            }\n            str.push_back('!');\n        }\n    \n        return str;\n    }\n    \n    std::string test4(const std::string& first, const std::vector<Foo>& list)\n    {\n        std::string str = first;\n        for (auto obj : list)\n        {\n            if (obj.has_extra())\n            {\n                str += std::format(\"{}: {} - {}!\",\n                    obj.get_word(), obj.number(), obj.get_extra());\n            }\n            else\n            {\n                str += std::format(\"{}: {}!\",\n                    obj.get_word(), obj.number());\n            }\n        }\n        return str;\n    }\n    \n    int main()\n    {\n        std::vector<Foo> list;\n    \n        for (std::size_t i = 0; i < 1000000; ++i)\n            list.push_back(Foo{ \"String to long for small string optimization\", i, true, \"String to long for small string optimization\" });\n    \n        auto time1 = std::chrono::high_resolution_clock::now();\n        auto s1 = test1(\"First \", list);\n        auto time2 = std::chrono::high_resolution_clock::now();\n        auto s2 = test2(\"First \", list);\n        auto time3 = std::chrono::high_resolution_clock::now();\n        auto s3 = test3(\"First \", list);\n        auto time4 = std::chrono::high_resolution_clock::now();\n        auto s4 = test4(\"First \", list);\n        auto time5 = std::chrono::high_resolution_clock::now();\n    \n        assert(s1.size() == s2.size() == s3.size() == s4.size());\n    \n        auto elapsed1 = std::chrono::duration_cast<std::chrono::microseconds>(time2 - time1).count();\n        auto elapsed2 = std::chrono::duration_cast<std::chrono::microseconds>(time3 - time2).count();\n        auto elapsed3 = std::chrono::duration_cast<std::chrono::microseconds>(time4 - time3).count();\n        auto elapsed4 = std::chrono::duration_cast<std::chrono::microseconds>(time5 - time4).count();\n    \n        std::cout << \"Estimated length: \" << estimate_length(\"First \", list) << \", actual: \" << s1.size() << \"\\n\\n\";\n    \n        std::cout << \"OP: \" << elapsed1 << \"\\n\";\n        std::cout << \"OP + estimate length: \" << elapsed2 << \"\\n\";\n        std::cout << \"using append, avoiding temporaries: \" << elapsed3 << \"\\n\";\n        std::cout << \"using std::format (cristi1990an): \" << elapsed4 << \"\\n\";\n    }\n\nResults:\n\nEstimated length: 104000006, actual: 99888896  \n\n\nmicrosoft compiler:\n\n    OP: 485136\n    OP + estimate length: 518773\n    using append, avoid temporaries: 325610\n    using std::format (cristi1990an): 1063464\n\nclang compiler:\n\n    OP: 497363\n    OP + estimate length: 515913\n    using append, avoid temporaries: 269436\n    using std::format (cristi1990an): 874970\n\nConclusions:\n\n- Pre-calculating the length of the entire output string doesn't help, even using an heuristic for number length. It's better in general to rely on the exponential growth of the string.\n\n- If you think `std::format` performs some magic to achieve optimal performance, you're probably wrong. \n\n- \u00a0A sequence of appends into the output string, avoiding temporaries, is hard to beat\n\nShouldn't `get_extra` return a const reference, instead of a copy? You may cause extra allocations there.\n\n_(do consider `std::optional<std::string> extra_` instead of mimicking optional yourself)_\n\nYep, good observation. I fixed that (also the for loop in test 4) and reran the benchmarks. This time I got\n\nMicrosoft compiler:\n\n    OP: 493979\n    OP + estimate length: 445592\n    using append, avoid temporaries: 267014\n    using std::format (cristi1990an): 767798 \n\nclang:\n\n    OP: 457314\n    OP + estimate length: 384340\n    using append, avoid temporaries: 164566\n    using std::format (cristi1990an): 570564\n\nIt changed the results, looping through all of the items to pre-calculate the length of the string is now showing as beneficial.\n\nI also added a benchmark for saknussemm's suggestion using `fmt::format` and `fmt::join`\n\n    std::string format_as(const Foo& obj)\n    {\n        auto result = fmt::format(\"{}: {}\", obj.get_word(), obj.number());\n        if (obj.has_extra()) {\n            std::format_to(std::back_inserter(result), \" - {}\", obj.get_extra());\n        }\n        return result;\n    }\n    \n    std::string formatObj(const std::vector<Foo>& list)\n    {\n        return fmt::format(\"First {}!\", fmt::join(list, \"!\"));\n    \n    }\n    \n    std::string test5(const std::string& first, const std::vector<Foo>& list)\n    {\n        return formatObj(list);\n    }\n\nwith the results\n\n  \nclang\n\n    OP: 461589\n    OP + estimate length: 375672\n    using append, avoid temporaries: 182119\n    using std::format (cristi1990an): 590501\n    using fmt::format and fmt::join (saknussemm): 763901\n\nAppend avoiding temporaries still wins! I think I'm done.", "id": "l7ype4o", "owner_tier": 0.3, "score": 0.06474820136690647}, {"content": "The most efficient way in your scenario can be selected by a benchmark.\n\nThe rules should be:\n\n  - Don't reallocate the output string (it should have enough capacity to hold the final string from the beginning)\n  - Don't allocate the parts (such as creating one std::string for each part)\n  - Don't endlessly copy bytes from one temporary to another\n\nI would try libfmt first as it has been optimized decently, and if that doesn't work out I would try to benchmark alternative solutions.", "id": "l7xfxzg", "owner_tier": 0.1, "score": 0.02877697834532374}, {"content": "If your profiler complaining about the allocation, or something else?", "id": "l7wmuhw", "owner_tier": 0.9, "score": 0.014388489136690647}, {"content": "You can use std::string as an StringBuilder:\n1. Call reserve() to define the starting buffer size to cover the most common cases.\n2. Append using += or append().\n3. Whenever possible use functions that append into a string instead creating temporal strings.\n4. Finally call shrink_to_fit() when you are concerned more about wasting some memory than having to allocate and copy. That call is not binding so the compiler can omit such operation when there is nothing to gain from that. I.E. No memory gets saved because heap allocation is done in multiples of 8 or 16, so most of the time a few bytes will remain unused.", "id": "l80bz1m", "owner_tier": 0.1, "score": 0.014388489136690647}, {"content": "Maybe with fmt, I think that it has strategies to minimize new allocations in the formatting part\n\n\\`\\`\\`\n\n    std::string format_as(Obj obj)\n    {\n        auto result = fmt::format(\"{}: {}\", obj.get_word(), obj.number());\n        if (obj.has_extra()){\n            std::format_to(std::back_inserter(result), \" - {}\", obj.get_extra());\n        }\n        return result;\n    }\n    \n    std::string formatObj(std::vector<Obj>& list)\n    {\n        return fmt::format(\"First {}!\", fmt::join(list, \"!\"));\n    \n    }\n\nI wouldn't recommend std::back\\_inserter if performance is a factor\n\nIt depends. In this case Fmt tries to get the container of a back\\_inserter and do a reserve. Also, it has a local buffer and appends the partial result in chunks to the final destination. In the end, a benchmark and counting allocations would be ideal", "id": "l7x7pe5", "owner_tier": 0.1, "score": 0.03597122294964029}, {"content": "> I could perform a first iteration to count the total size, allocate memory and perform a second iteration to concatenate everything manually. The problem is that it is too verbose.\n\nWhy I may ask? what stops you from writing a function that iterates over the values with signature\n\n`void iterate_string_chunks(std::predicate<std::string_view> auto cb)`\n\nand then invoke it twice like this:\n\n    std::size_t req {};\n    iterate_string_chunks([&req](const auto str) {\n        req += size(str);\n    });\n\n    std::string s {};\n    s.reserve(req);\n\n    iterate_string_chunks([&s](const auto str) {\n        s += size(str);\n    });\n\nIf you need to \"precompute\" things use a struct to hold the temporaries and make `iterate_string_chunks` its member function (or reuse a buffer, or whatever).\n\nSure you're iterating the list twice, but O(n*2) is still O(n) in the end.\n\nAre you formatting integers & floats every time, even when just counting their length?\n\nYou may be spending more time formatting than the time saved by avoiding allocating then.", "id": "l7xjflm", "owner_tier": 0.5, "score": 0.021582733741007196}, {"content": "I wonder if you could do something like, stick the relevant args (not converted to string temps) into a tuple while appending format specifiers to a string, then use \\`std::apply()\\` to call \\`std::format()\\`. Done right, you can avoid stringization of anything until the end, and the length of the overall format string can be upper-bound reserved in O(1) time in advance based on the number of items.\n\ni\u2019ve done something similar for interop between c++ and python.\nthe primary goal was to eliminate an insane amount of boilerplate code, not necessarily to improve\u00a0performance, so i didn\u2019t do any benchmarking.\nin any case, it\u2019s an idea worth trying.", "id": "l7yvhw2", "owner_tier": 0.3, "score": 0.014388489136690647}, {"content": "Memory assessment can be done.  Let's say most of the lines are 5 characters long.  Let's allocate memory for these lines.  Some will be smaller, some will be larger and, for sure, additional memory will not be required when adding.  The main point is to remove memory allocations; this is the most expensive operation.", "id": "l7zd4mu", "owner_tier": 0.1, "score": -7.194244560593734e-11}, {"content": "std::string already has vector-like semantics on capacity, so every necessaary reallocation reduces the chances that the next concatenation will require the same.\n\nMost of the time we're not doing string concatenation on a strict deadline, so that state of things is fine for most programs.\n\nbut to answer your question; if you know all of the strings to be concatenated upfront, you can reserve the capacity before concatenation. Otherwise you can do lazy concatenation (eg by building up a vector of string_view) in order to make that same optimization where the final concatenated string is actually needed, or just at more opportune time.\n\nfor concatenating non-string values, you can use resize_and_overwrite and std::to_chars in newer standards, or alternatively just use resize followed by to_chars in the 0-initialized region.", "id": "l82v7yf", "owner_tier": 0.5, "score": -7.194244560593734e-11}, {"content": "I typically use a stringstream for this sort of thing.  Probably not the most efficient in terms of memory or CPU cycles, but it's straightforward:\n\n    #include <sstream>  \n    ...\n    \n    std::stringstream s;\n    s << \"First \";\n    \n    for ( auto obj : list )\n    {\n      s << obj.get_word << \": \" << obj.get_number();\n      if ( obj.has_extra() )\n        s << \" - \" << obj.get_extra();\n      s << \"!\";\n    }\n    \n    std::string result = s.str();", "id": "l84ug7r", "owner_tier": 0.1, "score": -7.194244560593734e-11}, {"content": "I once wrote a benchmark between operator+ operator+= and std::ostringstream. The winner was ostringstream, but today C++20 std::format  is faster. Make your own benchmark with your specifics", "id": "l8hkzs9", "owner_tier": 0.1, "score": -7.194244560593734e-11}], "link": "https://www.reddit.com/r/cpp/comments/1dc65b0/what_is_the_most_efficient_way_to_build_a_string/", "question": {"content": "In this example, there are many intermediate copies and memory allocation for intermediate strings.\n\n```\n    std::string str = \"First \";\n    for (auto obj : list){\n        str += obj.get_word() + \": \" + std::to_string(obj.number());\n        if (obj.has_extra()){\n            str += \" - \" + obj.get_extra();\n        }\n        str += \"!\";\n    }\n```\n\nI could perform a first iteration to count the total size, allocate memory and perform a second iteration to concatenate everything manually. The problem is that it is too verbose.\n\nI know about std::fmt, but the number of fragments has to be known at compile-time.\n\nJava has the StringBuilder class. It collects each fragment and build the full string in the end. Maybe C++ has some third-party library with this feature.\n", "id": "1dc65b0", "title": "What is the most efficient way to build a string with many parts?", "traffic_rate": 48.45334238208348}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "The second is called \"interpolation\"\n\nAah I see thanks.\n\nI'm just a beginner so for me, since they were doing the same thing, I thought it was the same command with just two different techniques\n\nisnt interpolation a + (b - a) \\* t? what does that have to do with strings and concatenation? not doubting you just wondering where it come from\n\nInterpolation: The cooler concatenation\n\nAnd it is really useful in saving memory when you're trying to concatenate more than 2 strings, or if you need to put other data type values in between strings.\n\nInterpolation is far better to use when dealing with strings ultimately you will find it more flexible and you only need two double quotes as opposed to multiples with + in between.\n\nThe main difference is in implementation details.  When you use + to concatenate, the code is actually allocating a new string for the result of the +.  So if you have more than 2 strings you want to combine, each + results in an extra string getting allocated. Interpolation does some shenanigans on the backend to just pull from all the strings when it allocates the result.  \n\n\nIn other words, interpolation is just better at getting to the same result and scales better.\n\nThere are many interpolations. String interpolation is similar to the approximation you mentioned because it *inter* (puts in the middle) of two *poles* (marks). So, it's about putting a thing between two (or more) other things. When it comes to strings it puts the variable's value between two constant parts.\n\nNo, you are talking about the linear interpolation. Interpolation is a much wider term. 'Interpolate' means 'alter', 'insert' or 'interject.' In math, it means estimating new discrete datapoints between already existing ones.\n\naccording to the dictionary, interpolation basically just means inserting something into something else lol.\n\nin math/statistics, it refers to estimating/calculating unknown data points between two or more known data points (and probably some other stuff too).  in programming, it has to do with inserting literals (and again, probably some other stuff).\n\n_cries in rust_", "id": "idymxag", "owner_tier": 0.9, "score": 0.9999999999763033}, {"content": "(\u201cHello %s\u201d, username)\n\nYou are one hell of a crazy person lmao\n\nExactly! So much easier and cleaner than concatenation\n\nclassic \ud83d\ude0c\n\nThat person Javas.\n\nNot really cleaner imo once you have multiple variables\n\nOr printf\n\nI disagree. I like this:\n\nprintf(\n\u201cHi %s, you have %d new message%s.\u201d,\nname,\nnoOfMessages,\nnoOfMessages !== 1 ? \u201cs\u201d : \u201c\u201d\n)\n\nIt\u2019s so much easier to get an idea of what the complete string will look like.\n\nSystem.out.printf\n\nI\u2019d \u201ccalculate\u201d the variables beforehand. To each their own.\n\nLike `const msgStr = amtMessages !== 1 ? \u201cmessages\u201d : \u201cmessage\u201d` etc\n\nNo bs with needing to specify the variable type either", "id": "idyn2y7", "owner_tier": 0.9, "score": 0.341232227464455}, {"content": "#\u2019\u2019Hello \u2018\u2019\n\nThat's why I hate MS Word as IDE", "id": "idysh3q", "owner_tier": 0.9, "score": 0.06161137438388625}, {"content": "I thought it was `Hello ${username}`\n\nFor JavaScript, yea. But this is C#.\n\n```\n// js\nconsole.log(`Foo ${bar}`);\n\n// C#\nSystem.WriteLine($\"Foo {bar}\");\n```\n\nI thought this was php\n\nJs way feels weird, the fact that you need to tell the language that you're going to use interpolation directly before you use it instead of before opening the quotes doesn't feel right\n\nPhp concatenation would be \n\n    \u201cHello \u201c . $username\n\nf\"Python does {it} too\"\n\nYou mean C#, right? It's because there are two different kinds of string special characters in C#, `$` and `@`. The latter is called [verbatim identifier](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/tokens/verbatim) and I have no clue about the use cases.\n\nDear god\n\nAnd interpolation `\"Hello {$username}\"`\n\nWorks with comma as well when echo\u2019ing\n\nAllows carriage returns and tabs and stuff directly in a string.  We use it for inline SQL (with params, of course) to be able to format it in code so it is readable.", "id": "idyzkyv", "owner_tier": 0.7, "score": 0.2322274881279621}, {"content": "You ever seen these before Java users?\n\nJava users saw this in Kotlin.\n\n(The closest thing in Java is `format()` and `formatted()`.)\n\nHave had this forever:  System.out.printf(\"Hello %s!\", userName);\n\nThis is `printf`, which originates from C. Java has no syntax for string interpolation. The closest thing in Java is `format()` or `formatted()`.\n\nNot forever. That was added later, I remember changing all the code to use it.\n\nThen I remember fixing all the places where people put %d in there without specifying the locale.", "id": "idz8h84", "owner_tier": 0.3, "score": 0.06398104263033175}, {"content": "Meanwhile C++ users are still waiting for gcc to support `std::format(\"Hello {}\", username)` so that can interpolate in a typesafe way.\n\n%L\n\nWow, I\u2019m surprised libstdc++ still doesn\u2019t support for it. What could be the delay? They literally have a working reference implementation given to them.\n\nBut our ```std::cout``` is superior", "id": "idzbqrt", "owner_tier": 0.5, "score": 0.0189573459478673}, {"content": "mmm I really love the cool one coz it leaves me with enough memory to compute for other things than create new strings", "id": "idyq2ce", "owner_tier": 0.3, "score": 0.007109004715639811}, {"content": "The second one is much more efficient and easier to read. The first one is an abomination .p", "id": "idz2lbn", "owner_tier": 0.1, "score": 0.004739336469194313}, {"content": "If you would\u2019ve used f\u201dHello {username}\u201d then I would\u2019ve laughed.\n\nThey are the same shit bruh\n\nSure, but I\u2019m not smart enough to get the original", "id": "ie0em6k", "owner_tier": 0.7, "score": 0.011848341208530806}, {"content": "`f\"Hello {username}\"`", "id": "ie26dcl", "owner_tier": 0.5, "score": 0.007109004715639811}, {"content": "Stringbuilder for everything\n\nI hope not... At least in c# string builders have a high upfront cost to initialize them. If you are doing something like Console.WriteLine($\"logged in at {DateTime.Now}\"); you are making your code hard to read and slower to execute. For the most part I don't start using a sting builder until I'm at 5+ concatenations, or I have a loop that concatenates.\n\nAlso I get that you were probably being a little hyperbolic, just wanted to make sure other people don't take you totally seriously.", "id": "idzcz2d", "owner_tier": 0.1, "score": 0.011848341208530806}, {"content": "It's actually not cooler. If you compare the one the \"cooler\" one has more instructions, takes more time, which generates more CPU heat.\n\nNot necessarily. In python, f strings are [typically more efficient](https://stackoverflow.com/questions/59180574/string-concatenation-with-vs-f-string) when more than two variables are being concatenated, due to optimizations of the runtime. Simple reason might be you can avoid intermediate results of each operator+ that needs to malloc and free. Or at least that is my basic understanding.", "id": "idzhlok", "owner_tier": 0.5, "score": 0.009478672962085308}, {"content": "Nothing is better than ES5.\n\n`[ 'Hello', userName ].join(' ')`", "id": "idztg8u", "owner_tier": 0.5, "score": 0.002369668222748815}, {"content": "Right one is more elegant, but if I wanted to see a bunch of \"$\", I would just work with PHP.", "id": "idzupwq", "owner_tier": 0.5, "score": 0.002369668222748815}, {"content": "Are people still concatenating? I use printf all the time. Much more clean and easy to read imo.", "id": "idz60l8", "owner_tier": 0.3, "score": -2.3696682464454977e-11}, {"content": "Have to say I do love it", "id": "idzha3s", "owner_tier": 0.7, "score": 0.002369668222748815}], "link": "https://www.reddit.com/r/ProgrammerHumor/comments/vm2jlj/concatenation/", "question": {"content": "", "id": "vm2jlj", "title": "Concatenation", "traffic_rate": 826.8396226415094}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "Readable results for people who don't use the new layout:\n\n    0 ns/iter (+/- 0)        from_bytes\n    10 ns/iter (+/- 0)       concat_string_macro\n    10 ns/iter (+/- 0)       concat_strs_macro\n    10 ns/iter (+/- 0)       mut_string_with_capacity_push_str_char\n    10 ns/iter (+/- 0)       string_concat_macro\n    10 ns/iter (+/- 1)       mut_string_with_capacity_push_str\n    14 ns/iter (+/- 0)       concat_in_place_macro\n    19 ns/iter (+/- 10)      mut_string_with_too_much_capacity_push_str\n    22 ns/iter (+/- 0)       array_join\n    24 ns/iter (+/- 0)       array_concat\n    24 ns/iter (+/- 0)       array_join_long\n    24 ns/iter (+/- 0)       mut_string_push_str\n    27 ns/iter (+/- 0)       string_from_plus_op\n    27 ns/iter (+/- 0)       to_string_plus_op\n    29 ns/iter (+/- 0)       to_owned_plus_op    \n    30 ns/iter (+/- 0)       collect_from_array_to_string    \n    34 ns/iter (+/- 0)       collect_from_vec_to_string    \n    39 ns/iter (+/- 0)       mut_string_with_too_little_capacity_push_str    \n    43 ns/iter (+/- 1)       string_from_all    \n    52 ns/iter (+/- 0)       format_macro    \n    53 ns/iter (+/- 0)       format_macro_implicit_args    \n    68 ns/iter (+/- 1)       mut_string_push_string", "id": "hy8d89h", "owner_tier": 0.9, "score": 0.9999999999065421}, {"content": "I feel like some code examples are missing from the readme. For example, it says `concat_string_macro` is the second-fastest way to concatenate strings, but the readme doesn't show what the code for that benchmark looks like in the \"Examples explained\" section.\n\nSorry, that's just me being lazy. I updated the ReadMe [https://github.com/rimutaka/concatenation\\_benchmarks-rs/commit/218f1be779c9a86a3d1c3588601449fc2c008f06](https://github.com/rimutaka/concatenation_benchmarks-rs/commit/218f1be779c9a86a3d1c3588601449fc2c008f06). Thanks for pointing it out!", "id": "hy84ugl", "owner_tier": 0.3, "score": 0.27102803728971964}, {"content": "I think that from bytes implementation might be undefined behavior. It looks like it relies on DATE, T, and TIME all being next to each other in memory, in that order. I'd be shocked if that was guaranteed.\n\nYeah I think it is... I wonder if there is any way to make it non-UB without sacrificing performance (it'd still be horribly unsafe but at least it would always work).\n\nI doubt it. It's not a very useful algorithm to begin with. It requires the strings already be next to each other. It compiles to a no-op.\n\nI ran it through MIRI and confirmed that it is undefined behavior.\n\n`[repr(C)]` would guarantee the field order at least.\n\nYeah I took a second look at it and it makes an OsStr and not a String so it's just changing the type. Why is it even on this list...", "id": "hy8i179", "owner_tier": 0.5, "score": 0.5046728971028037}, {"content": "Out of curiousity, is there a good reason why format!() is so much slower than the other methods?\nSeeing as it's a macro, shouldn't it just be compiling down to the same thing as the other methods, assuming it's implemented optimally?\n\n`format_args!` makes a `fmt::Arguments` struct which takes the parts between `\u201c{}\u201d`s and stores them as `&\u2019static strs`, and the arguments which would go in between `{` and `}` as `ArgumentV1<'a>`.  The `ArgumentV1` dynamically calls the proper formatter on the arguments, so even though they are `&str`s the underlying `format!` code is using dynamic dispatch if I\u2019ve understood how it works correctly.\n\nThat's a good question. I was about to say that maybe it's doing some extra checks since it allows various types, then I remembered this is rust and you really just need the right traits on a type to convert it to a string. \n\n\nMaybe someone else will check it out and tell us lol", "id": "hy91q0e", "owner_tier": 0.5, "score": 0.18691588775700935}, {"content": "Well done!", "id": "hy82mg1", "owner_tier": 0.9, "score": 0.03738317747663551}, {"content": "`concat_in_place` is only for concatenating to an existing string, and it explicitly takes care to check the string's capacity to ensure it doesn't overallocate. I figured `[&str, &str].concat()` was already optimal for creating a new string. The only gap is when you need lots of conditional additions to a string. `AsRef<str>` is also avoided for sake of improving compile times and generating less monomorphed code.", "id": "hy90ik6", "owner_tier": 0.7, "score": 0.03738317747663551}, {"content": "This is very interesting!", "id": "hy9bldl", "owner_tier": 0.3, "score": -9.34579433572457e-11}, {"content": "I can\u2019t find the concat_string_macro and concat_str_macro on GitHub. Any reason why?\n\nI found them all via crates.io\n\n* https://github.com/FaultyRAM/concat-string\n* https://github.com/9999years/concat_strs\n* https://github.com/richardanaya/string_concat\n* https://codeberg.org/mmstick/concat-in-place\n\n[deleted]\n\nThanks, I looked over them in the post. I\u2019ll definitely check those out\n\nAh, my bad \ud83d\ude05", "id": "hy9dkbd", "owner_tier": 0.3, "score": 0.05607476626168224}, {"content": "I've updated `concat_in_place` to also perform efficient new string and vector  allocations if an existing buffer is not provided.\n\n    let mut new_string = strcat!(\"/proc/\" itoa.format(number) \"/tasks\");\n    let slice = strcat!(&mut new_string, \"/\" example \"/\" demo);\n\n@mmstick, Thanks Michael. Was the change supposed to make it faster? I get the same results for \n    \n    let mut url = String::new();\n    let datetime = concat_in_place::strcat!(&mut url, DATE T TIME);\n\nThe change was only for allocating new strings and vectors.\n\n    let datetime = strcat!(DATE T TIME);\n\nConcatenating to an existing string is already as fast as possible.", "id": "hyn2enu", "owner_tier": 0.7, "score": 0.018691588691588785}, {"content": "this should be quiet fast for concatening string (just an idea for now, not production ready code)\n```\nfn main(){\n\n\n    fn add_text(text:&[u8]) -> String {\n        const n: usize = u16::MAX as usize;\n        let mut s: [u8;n] = unsafe {std::mem::uninitialized()};\n        unsafe {\n            for i in 0..text.len() {\n                let elem = s.get_unchecked_mut(i);\n                let letter = text.get_unchecked(i);\n                std::ptr::write(elem, letter.to_owned());\n            }\n          String::from_utf8_unchecked(s[..text.len()].into()).trim().to_string()\n           \n        }\n    }\n    let s = add_text(b\"Hello Rust\");\n    println!(\"{s}!\");\n\n}\n```\n\nThis should be marked `unsafe`, and it will be quite slow with those allocations.\n\nIt's very hard to judge how fast code will run without benchmarking it. Test it out and see how it works\n\nthis is much better!!\n\n```\nuse std::fmt::Write;\n\nfn main(){\n\n    static mut glob: String = String::new(); \n\n    fn add_text(text:&[u8]) -> *mut String {\n        const n: usize = u16::MAX as usize;\n        let mut s: [u8;n] = unsafe {std::mem::uninitialized()};\n        unsafe {\n            for i in 0..text.len() {\n                let elem = s.get_unchecked_mut(i);\n                let letter = text.get_unchecked(i);\n                std::ptr::write(elem, letter.to_owned());\n            }\n         \n          glob.write_str(std::mem::transmute(std::str::from_utf8_unchecked(&s[..text.len()])));\n         let glob_ptr: *mut String = &mut glob;\n         glob_ptr\n        }\n    }\n    unsafe {\n        let s =  add_text(b\"Hello Rust\");\n        let s =  add_text(b\"Hello Rust\");\n        let s =  add_text(b\"Hello Rust\");\n        let s =  add_text(b\"Hello Rust\");\n        let s =  add_text(b\"Hello Rust\");\n        println!(\"{}!\", *s);\n    }\n\n}\n\nyes i know, my plan is to use std::mem::transmute and a static mut String in a future version\n\nI did test it and it's pretty fast ! I'll benchmark it in the we and make a crate of it\n\nThis is also unsafe and bad. See what `concat_in_place` is doing:\n\n\t#[macro_export]\n\tmacro_rules! strcat {\n\t    ($input:expr, $($element:expr)*) => {{\n\t\tlet out = $input;\n\t\tlet mut required = 0;\n\t\t$(\n\t\t    required += $element.len();\n\t\t)*\n\t\tlet free = out.capacity() - out.len();\n\t\tif (free < required) {\n\t\t    out.reserve(required - free);\n\t\t}\n\t\t$(\n\t\t    out.push_str($element);\n\t\t)*\n\t\t&*out\n\t    }}\n\t}\n\nNo unsafe. Still gets to the top of the charts in speed.", "id": "hy8dqoc", "owner_tier": 0.3, "score": 0.07476635504672897}], "link": "https://www.reddit.com/r/rust/comments/t06hk7/string_concatenations_benchmarks_updated/", "question": {"content": "The widely quoted [string concatenation benchmarks](https://github.com/hoodie/concatenation_benchmarks-rs) by Hendrik Sollich are 4 years old. I added a few methods and some macros from crates.io and re-ran the benches. Here are the results:\n```\n0 ns/iter (+/- 0)        from_bytes\n10 ns/iter (+/- 0)       concat_string_macro\n10 ns/iter (+/- 0)       concat_strs_macro\n10 ns/iter (+/- 0)       mut_string_with_capacity_push_str_char\n10 ns/iter (+/- 0)       string_concat_macro\n10 ns/iter (+/- 1)       mut_string_with_capacity_push_str\n14 ns/iter (+/- 0)       concat_in_place_macro\n19 ns/iter (+/- 10)      mut_string_with_too_much_capacity_push_str\n22 ns/iter (+/- 0)       array_join\n24 ns/iter (+/- 0)       array_concat\n24 ns/iter (+/- 0)       array_join_long\n24 ns/iter (+/- 0)       mut_string_push_str\n27 ns/iter (+/- 0)       string_from_plus_op\n27 ns/iter (+/- 0)       to_string_plus_op\n29 ns/iter (+/- 0)       to_owned_plus_op\n30 ns/iter (+/- 0)       collect_from_array_to_string\n34 ns/iter (+/- 0)       collect_from_vec_to_string\n39 ns/iter (+/- 0)       mut_string_with_too_little_capacity_push_str\n43 ns/iter (+/- 1)       string_from_all\n52 ns/iter (+/- 0)       format_macro\n53 ns/iter (+/- 0)       format_macro_implicit_args\n68 ns/iter (+/- 1)       mut_string_push_string\n```\n\nThe main takeaways for concatenation are:\n1. `format!()` is 5 times slower the fastest method\n2. pushing `str` or `char` into a mutable string of the right capacity is the fastest method\n3. method [2] can be replaced with one of the macros from crates.io because they implement exactly that\n\nThis [ReadMe](https://github.com/rimutaka/concatenation_benchmarks-rs/tree/macros) explains what is behind the benches.\n\n### New additions to the original study\n\n1. format!() macro with implicit arguments added in Rust 1.58\n```\nlet datetime = &format!(\"{DATE}{T}{TIME}\");\n```\n2. several string concatenation macros from crates.io\n* https://crates.io/crates/concat-string (#1 @10ns)\n* https://crates.io/crates/concat_strs (#1 @10ns, but breaks RustAnalyzer)\n* https://crates.io/crates/string_concat (#1 @10ns)\n* https://crates.io/crates/concat-in-place (#2 @14ns)\n\n### What did I miss?\n\nAre there other ways or macros to concatenate strings not included in the benches?\nI can add them to this draft PR https://github.com/hoodie/concatenation_benchmarks-rs/pull/11.", "id": "t06hk7", "title": "String concatenations benchmarks (updated)", "traffic_rate": 60.442098914354645}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "reddit"}, {"answers": [{"content": "\r\n    The best way is to do  use malloc to allocate the memory to copy it into, then use memcopy - as Richard says, trying to change a constant string can crash your app.\n\n\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <string.h>\r\nint main()\r\n    {\r\n    printf(\"Hello World\\n\");\r\n    char *A = \"Hello\";\r\n    char *B = \" World\";\r\n    int lenA = strlen(A);\r\n    int lenB = strlen(B);\r\n    char *A3 = (char*) malloc(lenA + lenB + 1);\r\n    memcpy(A3, A, lenA);\r\n    memcpy(A3 + lenA, B, lenB);\r\n    A3[lenA + lenB] = '\\0';\r\n    printf(\"\\n%s\\n\",A3);\r\n\r\n    return 0;\r\n    }\r\nmalloc provides a way to allocate memory of a variable size - so it's easier to write a function that can be called repeatedly to do the copy to fresh memory:\n\n\r\nchar* AppendStrings(const char *A, const char*B)\r\n    {\r\n    int lenA = strlen(A);\r\n    int lenB = strlen(B);\r\n    char *C = (char*) malloc(lenA + lenB + 1);\r\n    memcpy(C, A, lenA);\r\n    memcpy(C + lenA, B, lenB);\r\n    C[lenA + lenB] = '\\0';    \r\n    return C;\r\n    }Then you can call it with whatever you want:\n\n\r\nchar * C  = AppendStrings(A, B);\r\nprintf(\"\\n%s\\n\",C);\r\nchar * D  = AppendStrings(\"Hello World!\\n\", \"This is a test\");\r\nprintf(\"\\n%s\\n\",D);\r\n\n", "id": "2_5314801_1", "owner_tier": 0.9, "score": 5.0}, {"content": "\r\n    You are concatenating a single space to A so it probably appears not to work (you forgot A3). However, trying to write into a constant string is never guaranteed and you should not do it. You should create a new char buffer and copy the text into that. Something like:\nC++\n\r\nchar *A = \"Hello\";\r\nchar *A2 = \" \";\r\nchar *A3 = \"World!\";\r\n\r\nchar buffer[32]; // make sure this is big enough for the final text\r\nstrcpy(buffer, A);    // copy the first string into the buffer\r\nstrcat(buffer, A2);   // concatenate the space\r\nstrcat(buffer, A3);   //     and the final string\r\nprintf(\"\\n%s\\n\", buffer);\r\n\n", "id": "2_5314798_1", "owner_tier": 0.7, "score": 1.7033333333333334}], "link": "https://www.codeproject.com/Questions/5314795/How-do-I-concatenate-2-pointer-strings-correctly", "question": {"content": "\nHi\n\r\nI have tried, see the code below, to concatenate 2 pointer strings with the strcat() function. It didn't work.\n\n\n\r\n// Jones, Bradley L.; Peter Aitken; Dean Miller. C Programming in One Hour a Day, Sams Teach Yourself (p. 400). Pearson Education. Kindle Edition.\r\n//\r\n// 7. ON YOUR OWN: Write a function that accepts two strings. Use the malloc() function to allocate enough memory to hold\r\n// the two strings after they have been concatenated (linked). Return a pointer to this new string. For example, if you pass\r\n// \"Hello\" and \"World!\", the function returns a pointer to \"Hello World!\". Having the concatenated value be the third string\r\n// is easiest. (You might use your answers from exercises 5 and 6.)\r\n\r\n  #include <stdio.h>\r\n  #include <string.h>\r\n\r\n  int main( void )\r\n  {\r\n    char *A = \"Hello\";\r\n    char *A2 = \" \";\r\n    char *A3 = \"World!\";\r\n\r\n    strcat(A,A2);\r\n    printf(\"\\n%s\\n\",A);\r\n\r\n    return 0;\r\n }\n\r\nHow do I concatenate 2 pointer strings correctly?\n\nWhat I have tried:\n\r\nI have tried to change from \n\r\nprintf(\"\\n%s\\n\", A); to \n\r\nprintf(\"\\n%s\\n\",A);..\n\r\nI have also tried with: \n\r\nprintf(\"\\n%s\\n\", strcat(A,A2));\r\n.\r\n\t\t    ", "id": "5314795", "title": "How do I concatenate 2 pointer strings correctly?", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["C"]}, {"answers": [{"content": "\r\n    Are you sure you have the correct input parameters? What's the purpose of the number at the end of the line?\n\r\nAssuming that the number should be to tell you how many strings to concatenate, I'd expect the number to come first e.g.\n \n\r\n2 Rick Manood\r\n3 Hello Rick Manood\r\n11 By the pricking of my thumbs something wicked this way comes\n\r\nSome thoughts:\r\n1) 50 may be too short for some test cases, you're probably better off using dynamic memory, e.g. malloc()\r\n2) The problem states that you need to concatenate n strings, not just 2, so you probably want to use a function something like C\n\r\nchar *stringCatenate(size_t nargs, const char **strings)So you'd pass in a counter of the number of strings, and an array of strings, getting back a dynamically allocated string of the strings concatenated together.  If you're going to get a fail for using malloc() (a builtin function - at least for the purposes of this discussion), then you could use a large destination buffer, and then add that as a parameter to stringCatenate e.g. C\n\r\nchar *stringCatenate(char *dest, size_t nargs, const char **strings)\r\nNote that any fixed size array has the potential for overflow, leading to unexpected behavior (google \"undefined behavior\"), but 4K is likely to be enough.\r\n", "id": "2_5331987_2", "owner_tier": 0.3, "score": 3.0}, {"content": "\r\n    The reason it only passes the first test is that you haven't done anything with the numeric value, other than read it into a variable.\r\nLook at the inputs, and then look at the output. It's pretty obvious what you should be doing with it.\n\r\nBut the arrays you allocate are probably going to cause you real problems: they are pretty small, and if the number gets larger, you will run out of space very quickly and overwrite the input. I'd suggest you look at malloc instead of fixed length arrays.\r\n", "id": "2_5331986_1", "owner_tier": 0.9, "score": 2.445}], "link": "https://www.codeproject.com/Questions/5331985/Write-a-function-to-concatenate-two-strings-and-us", "question": {"content": "\nC\n\r\n#include<stdio.h>\r\n#include<string.h>\r\n\r\n\r\nvoid stringConcatenate(char str1[], char str2[]){\r\n    int i,j;\r\n    i = strlen(str1);\r\n    //for (int i = 0; str1[i] != '\\0'; ++i){\r\n        for (j = 0; str2[j] != '\\0'; i++, j++) {\r\n            str1[i] = str2[j];\r\n        }\r\n    str1[i] = '\\0';\r\n}\r\n\r\n\r\nint main() {\r\n    char s1[50], s2[30];\r\n    int N,Z;\r\n    gets(s1);\r\n    gets(s2);\r\n    scanf(\"%d\", &N);\r\n\r\n    stringConcatenate(s1,s2);\r\n    printf(\"%s\", s1);\r\n    //printf(\"%d\", )\r\n\r\n    return 0;\r\n}\n\nWhat I have tried:\n\r\nThe code is working properly, but passes only one test case.\r\nThe test cases are - \nRick manord 1 ---> Rickmanord\nHello world 2 ---> Hellowworldworld\nGram piece 3 Grampiecepiecepiece\r\nAnyone please help with why it isn't passing the other testcases\n", "id": "5331985", "title": "Write a function to concatenate two strings and use this to concatenate n (i.e, say 2) strings. Note: DO NOT USE STRCAT() or ANY INBUILT FUNCTIONS", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["C"]}, {"answers": [{"content": "\r\n    Hi,\n\r\nYou can Google it the same, you may found 1000's of links out of this, without tried out by your self asking others help that won't be helpful to your future.\n\r\nThis is for your reference Concatenate two strings in C#[^]\r\n", "id": "2_1032108_1", "owner_tier": 0.1, "score": 5.0}, {"content": "\r\n    To concatenate two or more strings just do\nC#\n\r\nstring concatenated = string.Concat(string1, string2);\r\nor\nC#\n\r\nstring concatenated = string1 + string2;\n\r\nin your case\nC#\n\r\nstring concatenated = \"Mr. \"+ txbName.Text;\r\n\n", "id": "2_1032104_3", "owner_tier": 0.1, "score": 2.055}, {"content": "\r\n    This is so ridiculously simple it's almost funny. This question tells me you have zero programming experience. You REALLY need to pickup beginners books on programming in general. You might want to also Google for \"C# Book 0\" by Charles Petzold. Though, I don't know how much that book is going to help you if you really don't have any experience.\r\n", "id": "2_1032106_1", "owner_tier": 0.7, "score": 1.835}], "link": "https://www.codeproject.com/Questions/1032098/how-to-use-concatenate-two-string-in-asp-net", "question": {"content": "\r\n\t\t\t    1st i was using  beging mr,mrs, and one text box  that text box enter a name \n\n\r\ni want mr.eliyas \n\r\nhow to make it please help me...\r\n\t\t    ", "id": "1032098", "title": "how to use concatenate two string in asp.net", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["C#", "ASP.NET"]}, {"answers": [{"content": "\r\n    You can do it however you want to do it so long as it is a valid querystring.\n\r\nFor example, you could do  ?brand=samsung,123|apple,11&price=100,12|200,\n\r\nYou can choose whatever you want to delimit the values then when you are retrieving Request.QueryString[\"brand\"] you'll then want to use the Split function to break them back out.\n\r\nAlso, this is just an example, make sure to use UrlEncode() to actually encode the url since whatever character you choose as a delimiter may need encoding.\r\n", "id": "2_887430_1", "owner_tier": 0.1, "score": 0}, {"content": "\r\n    You can use HTML5 Local Storage for this. Otherwise, I would suggest you to fetch these from database on that page and show them.\n\r\nHowever, I was checking the Flipkart site. It is sending parameters somewhat like you.\nhttp://www.flipkart.com/laptops/pr?p%5B%5D=facets.brand%255B%255D%3DAsus&p%5B%5D=facets.brand%255B%255D%3DDell&sid=6bo%2Cb5g&q=laptop&ref=f3c96052-246e-479a-83e9-d798d3770845[^].\n\r\nHere I have selected Asus and Dell as my laptop filters. It has added the parameters in URL only, but they are encoded. So, encode the URL and try to use in this format, if you can. Here %5B%5D is encoded for [].\r\n", "id": "2_887433_1", "owner_tier": 0.5, "score": 0}, {"content": "\nXML\n\r\nokey i am created simple code something like this\r\n\r\n<pre>  protected void Button1_Click(object sender, EventArgs e)\r\n    {\r\n\r\n        ArrayList brandarray = new ArrayList();\r\n        brandarray.Add(\"brand\");\r\n        brandarray.Add(\"brand2\");\r\n        brandarray.Add(\"brand3\");\r\n        brandarray.Add(\"brand4\");\r\n\r\n\r\n        string arry = String.Join(\",\", ((string[])brandarray.ToArray(typeof(String))));\r\n\r\n\r\n        ArrayList pricearr1 = new ArrayList();\r\n        pricearr1.Add(\"price\");\r\n            pricearr1.Add(\"price2\");\r\n            pricearr1.Add(\"price3\");\r\n            pricearr1.Add(\"price4\");\r\n\r\n\r\n            string arry1 = String.Join(\",\", ((string[])pricearr1.ToArray(typeof(String))));\r\n\r\n            ArrayList Attributearray = new ArrayList();\r\n            Attributearray.Add(\"Attribute\");\r\n            Attributearray.Add(\"Attribute2\");\r\n            Attributearray.Add(\"Attribute3\");\r\n            Attributearray.Add(\"Attribute4\");\r\n\r\n\r\n            string arry12 = String.Join(\",\", ((string[])Attributearray.ToArray(typeof(String))));\r\n\r\n\r\n            Response.Redirect(\"Default.aspx?brand=\" + arry + \" &amp;price=\" + arry1 + \" &amp;Discount=\" + arry12);\r\n    }</pre>\r\n\r\nand my query string coming like\r\n\r\n<blockquote class=\"quote\"><div class=\"op\">Quote:</div>http://localhost:49252/Default.aspx?brand=brand,brand2,brand3,brand4%20&price=price,price2,price3,price4%20&Discount=Attribute,Attribute2,Attribute3,Attribute4\r\n\r\nplease anyone tell me that is right or wrong way</blockquote>\n", "id": "2_887533_1", "owner_tier": 0.1, "score": 1.0}], "link": "https://www.codeproject.com/Questions/887417/how-to-Concatinate-the-three-ArrayList-and-sent-in", "question": {"content": "\r\n\t\t\t    hello all i want to pass multiple arrays variable in query string.\n\r\nfor example i have three checkbox list Brand ,Price, Attribute\n\r\nany arrays variable may have more than one value key\n\r\narrays variable are fixed for checkboxlist\n\r\n1-checkbox list Brand has Brand []arrays variable\n\r\n2-checkbox list Price has Price []arrays variable\n\r\n3-checkbox list Attribute has Attribute []arrays variable\n\r\nnow i have selecting two -two item  from every checkbox list .\n\n\n\r\nthan i want to query string something like this\n\nC#\n\r\nwww.defualt.aspx?brand[]=samsung=123&apple=11,Price[]=100=12&200=2,Attribute []=camera=1&display=2\n\n\r\nplz suggest me how to possible it ?\r\n\t\t    ", "id": "887417", "title": "How to Concatenate three  ArrayList and sent into query string", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["ASP.NET", "C#3.5"]}, {"answers": [{"content": "\nC#\n\r\nList<string> test = new List<string>(){\"aa\",\"bb\",\"ccc\"};\r\nvar result =String.Join(\", \", test.Where(s=>s.Length <3));\r\n\r\nyou will get aa, bb\n", "id": "2_768884_3", "owner_tier": 0.3, "score": 4.0}], "link": "https://www.codeproject.com/Questions/768880/How-to-concatenate-list-strings-under-some-conditi", "question": {"content": "\r\n\t\t\t    How to concatenate list strings under some conditions in linq query?give me some example\r\n\t\t    ", "id": "768880", "title": "How to concatenate list strings under some condition?give me some example", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["C#", "LINQ"]}, {"answers": [{"content": "\r\n    To answer your question, see THIS link.\n\r\nAppend data to a file as a new line in Python.\r\nSolution for this is a little tricky here. Let's start with the basic approach and then we will discuss drawbacks in it and see how to improve it.\n\r\nBasic approach:\n\r\nOpen the file in append mode (\u2018a\u2019). Write cursor points to the end of file.\r\nAppend \u2018\\n\u2019 at the end of the file using write() function.\r\nAppend the given line to the file using write() function.\r\nClose the file.\r\nWell, this approach works fine if our file already exists and already has some data in it. But if the file doesn\u2019t exist or file is empty, then this approach will fail because contents of the file will be like this.\n\r\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..\n\r\nNew added Line:\n\r\nIt first writes an empty line and then writes our line. But in this case, only appending a line was fine, we don\u2019t need to write \u2018\\n\u2019 before that.\n\r\nSo, our final approach should be like this:\n\r\nOpen the file in append & read mode (\u2018a+\u2019). Both read & write cursor points to the end of the file.\r\nMove read cursor to the start of the file.\r\nRead some text from the file and check if the file is empty or not.\r\nIf the file is not empty, then append \u2018\\n\u2019 at the end of the file using write() function.\r\nAppend a given line to the file using write() function.\r\nClose the file.\r\nThis solution will work fine in both scenarios. Let\u2019s use this solution to append a newline at the end of the file.\n\r\nSuppose we have a file \u2018sample2.txt\u2019 with the following contents:\n\n \n\r\nHello this is a sample file\r\nIt contains sample text\r\nThis is the end of file\r\nAppend new line to the file:\nPython\n\r\n# Open the file in append & read mode ('a+')\r\nwith open(\"sample2.txt\", \"a+\") as <code>file_object</code>:\r\n<pre lang=\"Python\">    # Move read cursor to the start of file.\r\n    file_object.seek(0)\r\n    # If file is not empty then append '\\n'\r\n    data = file_object.read(100)\r\n    if len(data) > 0 :\r\n        file_object.write(\"\\n\")\r\n    # Append text at the end of file\r\n    file_object.write(\"x y z\")\r\nContents of the file \u2018sample2.txt\u2019 now,\n \n\r\nHello this is a sample file\r\nIt contains sample text\r\nThis is the end of file\r\nhello hi\n", "id": "2_5326039_3", "owner_tier": 0.3, "score": 0}], "link": "https://www.codeproject.com/Questions/5326035/How-do-I-add-a-row-in-text-file", "question": {"content": "\r\n\t\t\t    I'm a beginner in Python. I want to add first row in a text file that looks like this:\n \n\r\n1 2 3\r\n4 5 6\r\n7 8 9 \r\nso that the output after adding the desired addition is:\n \n\r\nx y z\r\n1 2 3\r\n4 5 6\r\n7 8 9\r\nHow can I do that using Python?\n\nWhat I have tried:\n\r\nI have tried\nPython\n\r\ndf=pd.read_table('file.txt, header=['x', 'y', 'z'] \r\nbut it didn't work.\r\n\t\t    ", "id": "5326035", "title": "How to append text or lines to a file in Python?", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["Python"]}, {"answers": [{"content": "\nC++\n\r\nSomeStringClass amount = Window->get_text();\r\nwchar_t strAmount[100];\r\nint swprintf(strAmount, L\"Amount: %s\", amount);\n", "id": "2_597235_1", "owner_tier": 0.7, "score": 0}], "link": "https://www.codeproject.com/Questions/597205/concatenatingplustwopluswidepluscharacterplusstrin", "question": {"content": "\r\n\t\t\t    I just wrote this code to concatenate two wide characters strings. Could someone please comment if it looks OK? (seems to work at least).\n\nC++\n\r\n1. SomeStringClass amount = Window->get_text();\r\n2. wchar_t strAmount[100] = L\"Amount: \"; // I know I could remove 100 from here too\r\n3. wchar_t *ptr = wcscat( strAmount, amount.c_str() );\r\n4.  SomeStringClass  finalStr;\r\n5. finalStr.set(ptr, 10 /* 10 is roughly due to length of Amount line 2*/ + amount.length());\n\r\nNow, finalStr contains what I wanted, e.g., \"Amount: 123\"\r\n\t\t    ", "id": "597205", "title": "concatenating two wide character strings", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["C++"]}, {"answers": [{"content": "\r\n    Well, the error is clear enough: you are providing to many argument to the concat function. You could possibly perform the concatenation stepwise. For instance you could concatenate the first half of the argument sequence, then the second half, and finally concatenate the resulting strings.\n\n\n[update]\nQuote:How could I concatenate the halfs??\r\nThe idea is simple, suppose, for instance, you have {'a','b','c','d'}, then:\nSQL\n\r\nconcat( concat('a', 'b'), concat('c', 'd'))\n[/update]\n", "id": "2_1169233_3", "owner_tier": 0.5, "score": 1.0}, {"content": "\nConcat[^] function concatenates two or more strings into single one, but you want to search for specific value in specific field. As to your code, you're trying to concatenate name of fields, instead of strings. A proper way to use CONCAT function is:\nSQL\n\r\nSELECT CONCAT('Hello', ',', ' ', 'World', '!')\n\r\nI'd suggest to create Stored procedure[^] which can accept several arguments. If user can select field to search (by using radiobutton), your sp can look like this:\n\nSQL\n\r\nUse YourDatabaseName;\r\n\r\nCREATE STORED PROCEDURE usp_SearchDb\r\n    @SearchedField NVARCHAR(30),\r\n    @FindValue NVARCHAR(30)    \r\nAS\r\n    SET NOCOUNT ON;\r\n\r\n    DECLARE @qry NVARCHAR(MAX) = N'SELECT * FROM YourTable WHERE ' + @SearchedField + ' Like %' + @FindValue + '%'\r\n    EXEC(@qry)\r\n\r\nEND\r\nNote: Not tested, but it should works!\n\r\nIn case, when you need to query several columns at once, you have to read about Querying Multiple Columns (Full-Text Search)[^] \n\r\nGood luck!\r\n", "id": "2_1169252_1", "owner_tier": 0.5, "score": 0}], "link": "https://www.codeproject.com/Questions/1169228/The-concat-function-requires-to-arguments", "question": {"content": "\r\n\t\t\t    I have a problem in my system. Im trying to search specific data in my datagridview and filter it and click it the show to the texboxes.. It has an error saying  \n\n\n\r\nThe concat function requires 2 to 254 arguments\n\r\nWhat should I do? Thanks\n\nWhat I have tried:\n\nVB\n\r\n<pre>Imports System.Data.SqlClient\r\n\r\n\r\n\r\nPublic Class TreatmentHistory\r\n\r\n    Dim connection As New SqlConnection(\"Server=DESKTOP-C6IEOUN\\SQLEXPRESS;database =NEWCMO; integrated security=True;\")\r\n    Private Sub TreatmentHistory_Load(sender As Object, e As EventArgs) Handles MyBase.Load\r\n        FilterData(\"\")\r\n    End Sub\r\n\r\n    Private Sub txtPID_TextChanged(sender As Object, e As EventArgs) Handles txtPID.TextChanged\r\n\r\n    End Sub\r\n    Public Sub FilterData(valueToSearch As String)\r\n\r\n\r\n        Dim searchQuery As String = \"SELECT * FROM tblTreatment WHERE CONCAT(patientID,Surname,Firstname,Age,\r\nClm11,\r\nClm12,\r\nClm13,\r\nClm14,\r\nClm15,\r\nClm16,\r\nClm17,\r\nClm18,\r\nClm21,\r\nClm22,\r\nClm23,\r\nClm24,\r\nClm25,\r\nClm26,\r\nClm27,\r\nClm28,\r\nClm31,\r\nClm32,\r\nClm33,\r\nClm34,\r\nClm35,\r\nClm36,\r\nClm37,\r\nClm38,\r\nClm41,\r\nClm42,\r\nClm43,\r\nClm44,\r\nClm45,\r\nClm46,\r\nClm47,\r\nClm48,\r\nClm51,\r\nClm52,\r\nClm53,\r\nClm54,\r\nClm55,\r\nClm61,\r\nClm62,\r\nClm63,\r\nClm64,\r\nClm65,\r\nClm71,\r\nClm72,\r\nClm73,\r\nClm74,\r\nClm75,\r\nClm81,\r\nClm82,\r\nClm83,\r\nClm84,\r\nClm85,\r\nButton1,\r\nButton2,\r\nButton3,\r\nButton4,\r\nButton5,\r\nButton7,\r\nButton6,\r\nButton8,\r\nButton9,\r\nButton10,\r\nButton11,\r\nButton12,\r\nButton13,\r\nButton15,\r\nButton14,\r\nButton16,\r\nButton17,\r\nButton18,\r\nButton19,\r\nButton20,\r\nButton21,\r\nButton22,\r\nButton23,\r\nButton25,\r\nButton24,\r\nButton26,\r\nButton27,\r\nButton28,\r\nButton29,\r\nButton30,\r\nButton31,\r\nButton32,\r\nButton33,\r\nButton35,\r\nButton34,\r\nButton36,\r\nButton37,\r\nButton38,\r\nButton39,\r\nButton40,\r\nButton41,\r\nButton42,\r\nButton43,\r\nButton44,\r\nButton46,\r\nButton45,\r\nButton47,\r\nButton48,\r\nButton49,\r\nButton50,\r\nButton51,\r\nButton52,\r\nButton53,\r\nButton54,\r\nButton55,\r\nButton56,\r\nButton57,\r\nButton58,\r\nButton59,\r\nButton60,\r\nButton61,\r\nButton62,\r\nButton63,\r\nButton64,\r\nButton65,\r\nButton66,\r\nButton67,\r\nButton68,\r\nButton69,\r\nButton70,\r\nButton71,\r\nButton72,\r\nButton73,\r\nButton74,\r\nButton75,\r\nButton76,\r\nButton77,\r\nButton78,\r\nButton79,\r\nButton80,\r\nButton81,\r\nButton82,\r\nButton83,\r\nButton84,\r\nButton85,\r\nButton86,\r\nButton87,\r\nButton88,\r\nButton89,\r\nButton90,\r\nButton91,\r\nButton92,\r\nButton93,\r\nButton94,\r\nButton95,\r\nButton96,\r\nButton97,\r\nButton98,\r\nButton99,\r\nButton100,\r\nButton101,\r\nButton102,\r\nButton103,\r\nButton104,\r\nButton105,\r\nButton106,\r\nButton107,\r\nButton108,\r\nButton109,\r\nButton110,\r\nButton111,\r\nButton112,\r\nButton113,\r\nButton114,\r\nButton115,\r\nButton116,\r\nButton117,\r\nButton118,\r\nButton119,\r\nButton120,\r\nButton121,\r\nButton122,\r\nButton123,\r\nButton124,\r\nButton125,\r\nButton126,\r\nButton127,\r\nButton128,\r\nButton129,\r\nButton130,\r\nButton131,\r\nButton132,\r\nButton133,\r\nButton134,\r\nButton135,\r\nButton136,\r\nButton137,\r\nButton138,\r\nButton139,\r\nButton140,\r\nButton141,\r\nButton142,\r\nButton143,\r\nButton144,\r\nButton145,\r\nButton146,\r\nButton147,\r\nButton148,\r\nButton149,\r\nButton150,\r\nButton151,\r\nButton152,\r\nButton153,\r\nButton154,\r\nButton155,\r\nButton156,\r\nButton157,\r\nButton158,\r\nButton159,\r\nButton160,\r\nButton161,\r\nButton162,\r\nButton163,\r\nButton164,\r\nButton165,\r\nButton166,\r\nButton167,\r\nButton168,\r\nButton169,\r\nButton170,\r\nButton171,\r\nButton172,\r\nButton173,\r\nButton174,\r\nButton175,\r\nButton176,\r\nButton177,\r\nButton178,\r\nButton179,\r\nButton180,\r\nButton181,\r\nButton182,\r\nButton183,\r\nButton184,\r\nButton185,\r\nButton186,\r\nButton187,\r\nButton188,\r\nButton189,\r\nButton190,\r\nButton191,\r\nButton192,\r\nButton193,\r\nButton194,\r\nButton195,\r\nButton196,\r\nButton197,\r\nButton198,\r\nButton199,\r\nButton200,\r\nButton201,\r\nButton202,\r\nButton203,\r\nButton204,\r\nButton205,\r\nButton206,\r\nButton207,\r\nButton208,\r\nButton209,\r\nButton210,\r\nButton211,\r\nButton212,\r\nButton213,\r\nButton214,\r\nButton215,\r\nButton216,\r\nButton217,\r\nButton218,\r\nButton219,\r\nButton220,\r\nButton221,\r\nButton222,\r\nButton223,\r\nButton224,\r\nButton225,\r\nButton226,\r\nButton227,\r\nButton228,\r\nButton229,\r\nButton230,\r\nButton231,\r\nButton232,\r\nButton233,\r\nButton234,\r\nButton235,\r\nButton236,\r\nButton237,\r\nButton238,\r\nButton239,\r\nButton240,\r\nButton241,\r\nButton242,\r\nButton243,\r\nButton244,\r\nButton245,\r\nButton246,\r\nButton247,\r\nButton248,\r\nButton249,\r\nButton250,\r\nButton251,\r\nButton252,\r\nButton253,\r\nButton254,\r\nButton255,\r\nButton256,\r\nButton257,\r\nButton258,\r\nButton259,\r\nButton260,\r\nRemarks,\r\nComplain) like '%\" & valueToSearch & \"%'\"\r\n\r\n        Dim command As New SqlCommand(searchQuery, connection)\r\n            Dim adapter As New SqlDataAdapter(command)\r\n            Dim table As New DataTable()\r\n\r\n            adapter.Fill(table)\r\n\r\n            dgvTreatmentHistory.DataSource = table\r\n\r\n    End Sub\r\n\r\n    Private Sub PictureBox1_Click(sender As Object, e As EventArgs) Handles PictureBox1.Click\r\n        FilterData(txtPID.Text)\r\n    End Sub\r\nEnd Class\n", "id": "1169228", "title": "The concat function requires 2 to 254 arguments", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["VB", "SQL-Server-2014"]}, {"answers": [{"content": "\r\n    You have forgotten to enclose your str in the where clause with single quote. But you should not inject variable directly into the sql query. Instead, you should use parameterized query[^] to prevent sql injection[^].\r\n", "id": "2_750069_2", "owner_tier": 0.5, "score": 5.0}, {"content": "\r\n    \"i tried to concatenate the command text\"\n\r\nDON\"T!!!!\n\r\nUse a parameterized query. Every time. It always works.\r\n", "id": "2_750065_1", "owner_tier": 0.7, "score": 1.165}, {"content": "\r\n    Because your IP type is varchar, you should correct the SQL in this way:\nC#\n\r\nmyOleDbCommand.CommandText = string.Format(\"select sale_price,postion from item where ip='{0}'\", str);\n", "id": "2_750055_2", "owner_tier": 0.3, "score": 1.0}], "link": "https://www.codeproject.com/Questions/750053/how-to-concatenate-string-for-query", "question": {"content": "\r\n\t\t\t    Hello\r\ni have this code in web page\r\nmy problem:\r\nthere is 2 records in the database one of it have ip=99 and the other one have ip=000099 as varchar\r\nbut when i requset ip=99 i get record for ip=000099\r\ni tried to concatenate the command text using VB\n\r\nstring.Concat();\r\nstring.Format();\r\nstring.Append();\r\nstringBuilder\r\n but no change\r\nmy code:\nC#\n\r\ntry\r\n                {\r\n                    OleDbConnection myOleDbConnection = new OleDbConnection(connectionString);\r\n                    myOleDbConnection.Open();\r\n                    OleDbCommand myOleDbCommand = myOleDbConnection.CreateCommand();\r\n                  string str=\"99\";\r\n                    myOleDbCommand.CommandText = \"select sale_price,postion from item where ip=\" + str;\r\n                    OleDbDataReader dr = myOleDbCommand.ExecuteReader();\r\n                    dr.Read();\r\n///////////get results\r\n dr.Close();\r\n                    myOleDbConnection.Close();\r\n\r\n                }\r\n                catch \r\n                {\r\n                    \r\n                }\n", "id": "750053", "title": "how to concatenate string for query", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["C#", "ASP.NET"]}, {"answers": [{"content": "\r\n    That's not a problem - in fact with big queries it's a good idea because otherwise they become unreadable.\n\r\nAs long as you don't concatenate the content of any variables (i.e. values) you are fine.\r\n", "id": "2_5309214_1", "owner_tier": 0.9, "score": 3.0}, {"content": "\r\n    Just don't go nuts with it otherwise your going to drive yourself insane looking for some obscure typo in your concatenation code. You already have a bit of a typo just in the code you posted!\n\r\nSimplify it a bit!\nC#\n\r\nquery = \"SELECT colA, colB, colC\"\r\nquery += \" FROM SomeTable\"\r\nquery += \" WHERE colA = @Value\"\n", "id": "2_5309215_1", "owner_tier": 0.7, "score": 3.0}, {"content": "\r\n    To add to other solutions :\nQuote:Can I concatenate a query?\r\nThe way you did it, it is safe, the problem is when you concatenate user input values in query.\r\nSomething common is:\nC#\n\r\nQuery = \"SELECT \"\r\nQuery += \"colA, \"\r\nQuery += \"colB, \"\r\nQuery += \"colC, \"\r\nQuery += \" FROM SomeTable\"\r\nif (condition1)\r\n    Query += \" Where colA = @Value;\"\r\nelseif (condition2)\r\n    Query += \" Where colB = @Value;\"\r\nelse\r\n    Query += \" Where colC = @Value;\"\r\nThis make 3 different queries depending on conditions, it can safely get much more complicated.\r\nWhat is dangerous is:\nC#\n\r\nUserInput= \"My input;drop  SomeTable\"\r\nQuery = \"SELECT \"\r\nQuery += \"colA, \"\r\nQuery += \"colB, \"\r\nQuery += \"colC, \"\r\nQuery += \" FROM SomeTable\"\r\nQuery += \" Where colA = \"\r\nQuery += UserInput\r\nQuery += \";\"\r\nThanks to malicious input, you end up with this query :\nSQL\n\r\nSELECT colA, colB, colC, FROM SomeTable Where colA = My input;\r\ndrop  SomeTable;\r\nUser input is promoted to code. That is \"SQL Injection\"\r\n", "id": "2_5309216_1", "owner_tier": 0.5, "score": 3.0}], "link": "https://www.codeproject.com/Questions/5309210/Can-I-concatenate-a-query", "question": {"content": "\r\n\t\t\t    I've always heard that it's not a good practice to concatenate strings into the values \u200b\u200bof a Query. But simplistically, is there any problem in concatenating the query like this?\n\n\r\nQuery = \"SELECT \"\r\nQuery += \"colA, \"\r\nQuery += \"colB, \"\r\nQuery += \"colC \"\r\nQuery += \" FROM SomeTable\"\r\nQuery += \" Where colA = @Value;\"\r\nNote that I haven't concatenated the value, I'm passing @Value, and I'm going to treat it as a parameter in my application.\n\nWhat I have tried:\n\r\nI've been doing just that, but I really don't know if I'm wrong.\r\n\t\t    ", "id": "5309210", "title": "Can I concatenate a query?", "traffic_rate": 0}, "saved_time": {"$date": "2024-07-16T03:50:03.229Z"}, "source": "codeproject", "tags": ["SQL"]}]}