{"result": [{"answers": [{"content": "With Python 2.x, @pberkes' answer works. For Python 3, you can proceed as follows: For Python versions >= 3.4: For Python versions 3.0\u20133.3: source", "id": 55417917, "owner_tier": 0.5, "score": -1.999999987845058e-09}, {"content": "It's hard to say without seeing the code, but I suspect that file is being imported with a command equivalent to import file. Python caches imported modules, and so it would not pick up the changes in file. This is a Python feature, and is independent of Enthought Canopy. If that's the case, you can solve the problem by adding a call to reload (https://docs.python.org/2/library/functions.html#reload) after the import in test_file, to explicitly force a reload of the module:", "id": 29296139, "owner_tier": 0.5, "score": 0.9999999979999998}], "link": "https://stackoverflow.com/questions/29292029/python-changes-to-imported-file-do-not-take-effect", "question": {"content": "I have a file called test_file, which is designed to test another file, called file. 'test_file' also contains a .txt file in the same directory.  When I update file, save, select 'Change to Editor Directory...', then run test_file, Enthought does not seem to recognize that file was updated. Initially I thought I had to select the 'Change to Editor Directory' option every time I updated file, and so I did, but test_file was still printing 'success', even after I deliberately edited file so that test_file should print false. (Yes, I'm sure that it should have printed false as I added a bunch of gibberish code into file, and even code that shouldn't run, such as throwing in return statements with blatantly incorrect indentation). So, essentially, Enthought Canopy isn't realizing that I've updated file. However, if I save and quit everything, reopen Enthought, select 'Change to Editor Directory', then run test_file, it prints the correct outcome. This is very frustrating, because I spent days debugging correct code before I realized this. It has me very concerned because I don't know if what I tested in the past is actually correct, and I don't want this to happen in the future. What is the possible cause of this? (Note: I don't know if this is an Enthought issue or a Python issue)", "id": 29292029, "title": "Python - Changes to imported file do not take effect", "traffic_rate": 4}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python", "python-2.7", "debugging", "enthought"]}, {"answers": [{"content": "For Python 3.4+: For Python < 3.4: From the Python docs Reload a previously imported module. The argument must be a module object, so it must have been successfully imported before. This is useful if you have edited the module source file using an external editor and want to try out the new version without leaving the Python interpreter. Don't forget the caveats of using this method: When a module is reloaded, its dictionary (containing the module\u2019s global variables) is retained. Redefinitions of names will override the old definitions, so this is generally not a problem, but if the new version of a module does not define a name that was defined by the old version, the old definition is not removed. If a module imports objects from another module using from ... import ..., calling reload() for the other module does not redefine the objects imported from it \u2014 one way around this is to re-execute the from statement, another is to use import and qualified names (module.*name*) instead. If a module instantiates instances of a class, reloading the module that defines the class does not affect the method definitions of the instances \u2014 they continue to use the old class definition. The same is true for derived classes.", "id": 1254379, "owner_tier": 0.9, "score": 0.999999999982906}, {"content": "", "id": 66589258, "owner_tier": 0.1, "score": -1.7094017179910415e-11}, {"content": "Another small point: If you used the import some_module as sm syntax, then you have to re-load the module with its aliased name (sm in this example):", "id": 63050762, "owner_tier": 0.5, "score": 0.02905982904273504}, {"content": "If you want to import a specific function or class from a module, you can do this:", "id": 60936171, "owner_tier": 0.5, "score": 0.08034188032478633}, {"content": "Although the provided answers do work for a specific module, they won't reload submodules, as noted in This answer: If a module imports objects from another module using from ... import ..., calling reload() for the other module does not redefine the objects imported from it \u2014 one way around this is to re-execute the from statement, another is to use import and qualified names (module.*name*) instead. However, if using the __all__ variable to define the public API, it is possible to automatically reload all publicly available modules: The caveats noted in the previous answer are still valid though. Notably, modifying a submodule that is not part of the public API as described by the __all__ variable won't be affected by a reload using this function. Similarly, removing an element of a submodule won't be reflected by a reload.", "id": 60823236, "owner_tier": 0.1, "score": 0.0034188034017094016}, {"content": "In python 3, reload is no longer a built in function. If you are using python 3.4+ you should use reload from the importlib library instead: If you are using python 3.2 or 3.3 you should: instead. See http://docs.python.org/3.0/library/imp.html#imp.reload If you are using ipython, definitely consider using the autoreload extension:", "id": 14390676, "owner_tier": 0.5, "score": 0.6102564102393162}, {"content": "Actually, in Python 3 the module imp is marked as DEPRECATED. Well, at least that's true for 3.4. Instead the reload function from the importlib module should be used: https://docs.python.org/3/library/importlib.html#importlib.reload But be aware that this library had some API-changes with the last two minor versions.", "id": 23901170, "owner_tier": 0.5, "score": 0.08034188032478633}], "link": "https://stackoverflow.com/questions/1254370/reimport-a-module-while-interactive", "question": {"content": "How do I reimport a module? I want to reimport a module after making changes to its .py file.", "id": 1254370, "title": "Reimport a module while interactive", "traffic_rate": 68}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python"]}, {"answers": [{"content": "Just in addition to @ilia post:\nLet's say the module's name is main.py\nThat's the code I put in the Jupiter's notebook cell, just before calling functions from the main module", "id": 70943990, "owner_tier": 0.3, "score": -1.428571419889327e-09}, {"content": "There's actually a nifty IPython extension for this called autoreload.  This answer shows how to use it in an IPython shell, but you can do the same in a Jupyter notebook.  Just add: before you import the module whose changes you want to have tracked, and it'll be re-imported before every cell you execute.", "id": 64166391, "owner_tier": 0.3, "score": 0.9999999985714284}, {"content": "Suppose we have a file at folder_name/filename.py and call it in some .ipynb which was modified like this In this case, second call of the following code in .ipynb returns test To update the function, you need to reload the module: This code will return test2 \nDon't forget to import importlib before you run reload", "id": 64294886, "owner_tier": 0.3, "score": 0.8571428557142856}, {"content": "This has happened to me. You need to restart the python kernel so jupyter can read the new state of the python scripts located in the working directory. Then the variable a should print the new assigned value.", "id": 64158748, "owner_tier": 0.1, "score": 0.28571428428571427}], "link": "https://stackoverflow.com/questions/64158622/jupyter-does-not-see-changes-in-the-imported-module", "question": {"content": "I have a file called \"Notebook.ipynb\". I want to import my own module into it patterns.py. Let's say in patterns.py I have a variable a=1. If I print it in Jupyter after importing it, I expect to get 1. But if I change the value of the variable to patterns.py Jupyter will continue to think that the variable a is equal to one. At the same time, of course, I restart the cell in which the variable is imported from patterns.py What do I need to do to make Jupyter understand that the value of the variable has changed?", "id": 64158622, "title": "Jupyter does not see changes in the imported module", "traffic_rate": 18}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python-3.x", "jupyter-notebook"]}, {"answers": [{"content": "No, it will probably use the original. When you import the class C from B in A you will create a reference to an object in A (happens to be a class) called C. If you don't reassign to C it will still refer to the same object, so unless you actually modify the very same object during the update of B the changes wouldn't be visibly from A via the use of C. Now for some examples of how you might have done: If you just edit the source of B (after the input in the below code) and have the following python code: Then you haven't modified anything as far as A is concerned, it even didn't bother to look at your modified source. Now let's try to reimport: Now you do reassign to C, but still Python does not bother to look at your modification. The second import first checks if it has loaded the B module, and it has and then it just grabs C from it and puts into As namespace. Now let's try a little bit harder: Then still no luck; the reload(B) only tells the interpreter to reload the module, so now B refers to the new module, but C wasn't updated in this process. Now for the nearest you get: Now c2 = C() will use the class definition from the modified B, but be aware that the c1 did use the old definition and its type is still the old version of the class C. Last, as I mentioned, actually modifying the very same object I guess I'd give an example: Here the class C is first defined and an object is created. Then I modify the class C by adding a method to it. The type of c hasn't changed. It's the very same class, but now that class have got a new method since c was created.", "id": 32987149, "owner_tier": 0.5, "score": 0.0}, {"content": "That depends on you notion of update: Remember that Python is a compiled language: A module is read and compiled into byte code. So when you change the source file, nothing happens because the code was already compiled. Simply importing a module repeatedly also does nothing, the importer simply checks sys.modules and returns the already existing module from there. A module load is only triggered when you load an unknown module (according to sys.modules). There is also no auto-check for changed source files, so source files are not automatically recompiled when they have changed. However, compiled files (.pyc, .pyo) are checked against their source files before they are used. If the corresponding source files are newer or have a different size, recompilation happens for fresh loads (not on import, on load). Note, however, that the .pyc timestamp resolution is only 32 bits, so the actual file system timestamp is truncated. You can jump through some serious hoops to make Python import a changed source file: This is actually by coincidence, but the code shows one of the real problems that occur with reimporting and recompilation. Because the two B.pys are created quickly after another, their timestamps more often than not compare equal to the .pyc timestamp. You might get lucky and hit the actual timestamp flip, but that's just luck. Since the files are also the same size on Unix (note the extra newline for the second version), the file size check also reports both source files to be equal. If you remove the unlink() operations, you --most of the time-- get no module recompile. Instead you get the version version of B loaded from the .pyc file, even though it does not match B.py any more. In any case, the code objects from the initial import are retained. In this example, first_class is from the initial version of B.py, second_class is from the updated version. The first class is already compiled into byte code and in memory, it does not change just because you change its source file. For all practical purposes, both classes are from different modules that incidentally happen to have the same source file. This is probably only useful for debugging and I strongly advise against using it for anything productive. This is especially true, if your module has more than the single source file. That said, reload() doesn't exist any more in Python 3, because it never worked as expected even in Python 2.", "id": 32973360, "owner_tier": 0.5, "score": 0.0}], "link": "https://stackoverflow.com/questions/32972902/does-python-detect-updating-of-an-imported-module", "question": {"content": "Module A imports a class C from B. A has a 'run' procedure which inter alia creates an instance of C.\nAfter the first run, module B is updated without exiting A; then a second run is done. Will the new instance of C be from the updated version of B or the original?", "id": 32972902, "title": "Does Python detect updating of an imported module?", "traffic_rate": 1}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python", "python-module"]}, {"answers": [{"content": "All the answers above about reload() or imp.reload() are deprecated. reload() is no longer a builtin function in python 3 and imp.reload() is marked deprecated (see help(imp)). It's better to use importlib.reload() instead.", "id": 22894171, "owner_tier": 0.5, "score": 0.5885286782793018}, {"content": "Update for Python3: (quoted from the already-answered answer, since the last edit/comment here suggested a deprecated method) In Python 3, reload was moved to the imp module. In 3.4, imp was deprecated in favor of importlib, and reload was added to the latter. When targeting 3 or later, either reference the appropriate module when calling reload or import it. Takeaway: Use the reload builtin function: https://docs.python.org/2/library/functions.html#reload When reload(module) is executed: Example:", "id": 684186, "owner_tier": 0.7, "score": 0.9999999999750623}, {"content": "Short answer: try using reimport: a full featured reload for Python. Longer answer: It looks like this question was asked/answered prior to the release of reimport, which bills itself as a \"full featured reload for Python\": This module intends to be a full featured replacement for Python's reload function. It is targeted towards making a reload that works for Python plugins and extensions used by longer running applications. Reimport currently supports Python 2.4 through 2.6. By its very nature, this is not a completely solvable problem. The goal of this module is to make the most common sorts of updates work well. It also allows individual modules and package to assist in the process. A more detailed description of what happens is on the overview page. Note: Although the reimport explicitly supports Python 2.4 through 2.6, I've been trying it on 2.7 and it seems to work just fine.", "id": 8637233, "owner_tier": 0.5, "score": 0.019950124663341645}, {"content": "No matter how many times you import a module, you'll get the same copy of the module from sys.modules - which was loaded at first import mymodule I am answering this late, as each of the above/previous answer has a bit of the answer, so I am attempting to sum it all up in a single answer. Using built-in function: For Python 2.x - Use the built-in reload(mymodule) function. For Python 3.x - Use the imp.reload(mymodule). For Python 3.4 - In Python 3.4 imp has been deprecated in favor of importlib i.e. importlib.reload(mymodule) Few caveats:  External packages: reimport - Reimport currently supports Python 2.4 through 2.7. xreload- This works by executing the module in a scratch namespace, and then\npatching classes, methods and functions in place.  This avoids the\nneed to patch instances.  New objects are copied into the target\nnamespace. livecoding - Code reloading allows a running application to change its behaviour in response to changes in the Python scripts it uses. When the library detects a Python script has been modified, it reloads that script and replaces the objects it had previously made available for use with newly reloaded versions. As a tool, it allows a programmer to avoid interruption to their workflow and a corresponding loss of focus. It enables them to remain in a state of flow. Where previously they might have needed to restart the application in order to put changed code into effect, those changes can be applied immediately.", "id": 36375742, "owner_tier": 0.5, "score": 0.047381546109725683}, {"content": "dragonfly's answer worked for me (python 3.4.3). Here is a lower level solution :", "id": 34201014, "owner_tier": 0.3, "score": -2.4937655708791247e-11}, {"content": "", "id": 30608568, "owner_tier": 0.1, "score": 0.009975062319201995}, {"content": "So, far I have been exiting and reentering the Interpreter because re importing the file again is not working for me. Yes, just saying import again gives you the existing copy of the module from sys.modules. You can say reload(module) to update sys.modules and get a new copy of that single module, but if any other modules have a reference to the original module or any object from the original module, they will keep their old references and Very Confusing Things will happen. So if you've got a module a, which depends on module b, and b changes, you have to \u2018reload b\u2019 followed by \u2018reload a\u2019. If you've got two modules which depend on each other, which is extremely common when those modules are part of the same package, you can't reload them both: if you reload p.a it'll get a reference to the old p.b, and vice versa. The only way to do it is to unload them both at once by deleting their items from sys.modules, before importing them again. This is icky and has some practical pitfalls to do with modules entries being None as a failed-relative-import marker. And if you've got a module which passes references to its objects to system modules\u2009\u2014\u2009for example it registers a codec, or adds a warnings handler\u2009\u2014\u2009you're stuck; you can't reload the system module without confusing the rest of the Python environment. In summary: for all but the simplest case of one self-contained module being loaded by one standalone script, reload() is very tricky to get right; if, as you imply, you are using a \u2018package\u2019, you will probably be better off continuing to cycle the interpreter.", "id": 684229, "owner_tier": 0.9, "score": 0.0922693266583541}, {"content": "In Python 3, the behaviour changes.   ... do something with my_stuff, then later: and you get a brand new, reloaded my_stuff.", "id": 13121908, "owner_tier": 0.3, "score": 0.06483790521197007}, {"content": "See here for a good explanation of how your dependent modules won't be reloaded and the effects that can have: http://pyunit.sourceforge.net/notes/reloading.html The way pyunit solved it was to track dependent modules by overriding __import__ then to delete each of them from sys.modules and re-import.  They probably could've just reload'ed them, though.", "id": 684311, "owner_tier": 0.5, "score": 0.002493765561097257}, {"content": "Not sure if this does all expected things, but you can do just like that:", "id": 685040, "owner_tier": 0.5, "score": 0.009975062319201995}, {"content": "Basically reload as in allyourcode's asnwer. But it won't change underlying the code of already instantiated object or referenced functions. Extending from his answer:", "id": 685004, "owner_tier": 0.9, "score": 0.01745635907730673}], "link": "https://stackoverflow.com/questions/684171/how-to-re-import-an-updated-package-while-in-python-interpreter", "question": {"content": "I often test my module in the Python Interpreter, and when I see an error, I quickly update the .py file. But how do I make it reflect on the Interpreter ? So, far I have been exiting and reentering the Interpreter because re importing the file again is not working for me.", "id": 684171, "title": "How to re import an updated package while in Python Interpreter?", "traffic_rate": 98}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python"]}, {"answers": [{"content": "It's possible that Python is using a cached bytecode version of your file, rather than reading the new version. If you have a __pycache__ directory, or any files with the extension .pyc, try deleting them and importing your file again.", "id": 51214336, "owner_tier": 0.5, "score": 0.9999999975}], "link": "https://stackoverflow.com/questions/51214041/updates-from-updated-py-file-not-working-when-imported", "question": {"content": "I have a python file with various functions, called mypyfile. For a while now I have had custom functions there that I use, and I import them in using import mypyfile. I recently moved to 3.6 from 3.4 because of dependencies from a specific package I was using. I am now trying to import mypyfile, but the update that I made to the file and saved it, is not working.  The mypyfile.py exists in the main working directory. The import function does work, and it does import my file in. When I use the newly changed function from that file is when it fails, indicating that the changes I made were not updated.  I'm likely not doing the package thing right in python, I just have a .py file with functions in it, no init.py file, or structured package folder. just one .py file with a bunch of functions in it.", "id": 51214041, "title": "updates from updated py file not working when imported", "traffic_rate": 3240}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python", "module"]}, {"answers": [{"content": "I suspect you have at least one other module with the same name as one of yours in your PYTHONPATH. Either look for old copies you left around or try changing your module names and see what happens. You'd see a similar effect if you forgot to reload your modules before running them after you modified them, but restarting your Python session would obviously cause all your modules to be loaded afresh at the first import of each.", "id": 7595390, "owner_tier": 0.5, "score": 0.9999999966666667}], "link": "https://stackoverflow.com/questions/7595297/modules-source-changes-dont-take-effect", "question": {"content": "I am having an issue with python which  looks really weird to me. My script starts to be quite big and is suposed to run a test suite for a program.\nMy inclusion tree is: The weird behavior I am having is that when I add a modification to my Module, Section or Test module's source file, they don't take effect at all. I am developing with emacs in my terminal and simply run my script using: I tried: The version of my python is 2.5.2 and I am working under a Debian Lenny in VirtualBox. And I haven't been able to reproduce this behavior on another smaller program to observe it better.", "id": 7595297, "title": "Module&#39;s source changes don&#39;t take effect", "traffic_rate": 1}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python", "module"]}, {"answers": [{"content": "You need to explicitly reload the module, as in: note that imp module is pending depreciation in favor of importlib and in python 3.4 one should use: importlib.reload.", "id": 25866649, "owner_tier": 0.9, "score": 0.99999999875}, {"content": "As an alternative answer inside reload you can use \nwatchdog \n .  A simple program that uses watchdog to monitor directories specified as command-line arguments and logs events generated: From the website Supported Platforms Linux 2.6 (inotify) Mac OS X (FSEvents, kqueue) FreeBSD/BSD (kqueue) Windows (ReadDirectoryChangesW with I/O completion ports; ReadDirectoryChangesW worker threads) OS-independent (polling the disk for directory snapshots and comparing them periodically; slow and not recommended)", "id": 25866782, "owner_tier": 0.9, "score": -1.2499999924031613e-09}, {"content": "You should use reload every time you make a change and then import again:", "id": 25866665, "owner_tier": 0.5, "score": -1.2499999924031613e-09}], "link": "https://stackoverflow.com/questions/25866555/python-does-not-show-code-changes-from-imported-file", "question": {"content": "I am using a linux python shell and each time I make changes to the imported file I need restart the shell (I tried reimporting the file but the changes were not reflected)  I have a definition in a file called handlers.py I import the file in the python shell I then change print statement to \"Hello I am there\", reimport handlers, it does not show the change? Using Python 2.7 with Mint 17.1", "id": 25866555, "title": "Python does not show code changes from imported file", "traffic_rate": 6743}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python", "import"]}, {"answers": [{"content": "Use can use Python's built-in function reload. From the docs: When reload(module) is executed: Here is an example: First, we create a file that defines a variable msg and a method to print it. Now we modify the file, removing variable msg and adding a and b variables (without exiting the current Python REPL). This is useful if you have edited the module source file using an external editor and want to try out the new version without leaving the Python interpreter. One final note: reload(myfile) only reloads the specified modules. The module's (myfile) imports must be individually reloaded. Also, any objects that refer to anything in the module (like an instance whose class is defined in the module) will continue to use the previously loaded value.", "id": 21970306, "owner_tier": 0.5, "score": -1.0000000000000002e-08}, {"content": "From the imp.reload documentation: When a module is reloaded, its dictionary (containing the module\u2019s global variables) is retained. Redefinitions of names will override the old definitions, so this is generally not a problem. If the new version of a module does not define a name that was defined by the old version, the old definition remains. The module is not wiped before the reload. The module's new code is executed with all old variable bindings still present. Any names the new code defines replace the old bindings, but anything the new version doesn't define retains its old value. This also applies in Python 2.", "id": 21965170, "owner_tier": 0.9, "score": 0.9999999900000001}], "link": "https://stackoverflow.com/questions/21965009/does-reloading-a-module-changes-the-names-in-the-module-previously-imported-relo", "question": {"content": "I have a module named myfile.py Then I import it: import myfile Then I make some modifications, such as: Then I call the reload function: Now when I run: dir(myfile)\nits showing the names from the current module reload as well as the previous (all other previous import/reloads) Does this mean \"all\" the names (even names omitted after updating) are available separately for outside world when the module is imported/reloaded?", "id": 21965009, "title": "Does reloading a module changes the names in the module previously imported/reloaded?", "traffic_rate": 505}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python"]}, {"answers": [{"content": "The issue was that PYTHONPATH was set to a wrong folder. We had two folders with the project: old and new, similarly named, with identical project structure (but different file contents) and PYTHONPATH was set to the old project.", "id": 65096617, "owner_tier": 0.5, "score": 0.0}, {"content": "assuming that you've successfully cloned the project into your machine, If it is a problem with importing functions or methods from a different .py file, please check the points below. check your working directory, whether you're in the same directory where the .py file/module with functions/methods exist. once you import any function/method from a module, even you comment out the function/method and save the .py file, it won't affect the already imported functions as long as you re-import it. as long as it is a problem of importing from your own .py files, the virtual environment has nothing to do with that. EDITED: check this link, it may give you some information about how caching works while importing python modules.", "id": 65095624, "owner_tier": 0.3, "score": 0.0}], "link": "https://stackoverflow.com/questions/65095357/python-does-not-see-new-changes-in-files", "question": {"content": "When I am adding new functions to a file I can't import them neither if I just run the script in terminal or if I launch ipython and try importing a function there. I have no .pyc files. It looks as if there is some kind of caching going on. I never actually faced such an issue even though have been working with various projects for a while. Why could it happen? What I see is the following: I launch ipython and the functions that were written long time ago by other programmers can be imported fine. If I comment them out and save the file, they still can be imported without any issues. If I write new functions they can't be imported. The directory is git directory, I cloned the repo. Then the new branch was created and I switched to it. Python version is 3.7.5, and I am working with virtual environment that I created some time ago which I activated with source activate py37. I don't know whether its important but I have an empty __init__.py in the folder where script is located. The code (I don't think its relevant, but still): public_class_props is an old function and can be imported, but hello - can't.", "id": 65095357, "title": "Python does not see new changes in files", "traffic_rate": 3007}, "saved_time": 1721102434, "source": "stackoverflow", "tags": ["python", "git", "caching", "import", "git-clone"]}, {"answers": [{"content": "There's a built-in for that: [`reload()`](http://docs.python.org/2/library/functions.html?highlight=reload#reload)\n\nI can't say with certainty that it will work in an IPython interpreter session, but if it doesn't it's probably a bug they're working on or would work on.\n\nHmm, thanks for the pointer to reload()... I'm not seeing how to use it if I have imported a module with 'from X import *' though.  Is this possible?  Or do I need to import the module by name to be able to use reload()?\n\nI'm very glad I read that link, btw, because I would not have guessed that existing instances would retain their methods.  I would have assumed that either all existing instances would be invalidated, or their internal vtables (or whatever Python uses in lieu of them) would be rewritten to point to the new code.  That could have caused some confusion!\n\nI have a related question: is there an easy way to un-shadow something? A common mistake I make with IPython is:\n\n    ylim = (0, 50)\n\nWhen it should be:\n\n    ylim(0,50)\n\nSimply because I forgot the exact syntax, I've replaced `ylim()` with a tuple and now can't set the y-axis on a plot. What's the easiest way to fix that? \n\nThe relevant documentation is this:\n\n* Other references to the old objects (such as names external to the module) are not rebound to refer to the new objects and must be updated in each namespace where they occur if that is desired.\n\nSo you need to call `reload(X)` and then set everything you imported from * to the \"new\" X's values. I don't have the means to test it right now, but I suspect re-running the `from X import *` line would rebind all of the names to the new module.\n\nHave you tried using \"del ylim\"?  I think that should delete the current contexts reference which should cause ylim to get resolved by the outer context again.\n\nJust re-import the module that provides that name. It will not re-run any initialization code, but it will rebind the names.\n\nNope, now I get:\n\n    NameError: name 'ylim' is not defined\n\nI can do this if I know the module that it came from, but I'm sure there's a better solution:\n\n    from pylab import *\n\nAll del does is remove the name. It doesn't delete objects\n\nYeah, that's what I do, but it took me some time to figure out the module that provided that particular function. I guess that's a bigger problem with IPython since the namespace has so much already imported.\n\nActually otakucode's suggestion works for things in the default namespace. Just not thing that have been imported later, it seems. \n\n\nWhich is precisely what he wants, no?", "id": "c883cpo", "owner_tier": 0.3, "score": 0.9999999992307692}, {"content": "Use reload if you imported the module.\n\nUse %run foo if you imported things from foo.", "id": "c883tku", "owner_tier": 0.5, "score": 0.07692307615384616}, {"content": "Reloading modules is a hard problem. Using the reload function won't update instances. You need to restart the REPL and reinstantiate your objects. \n\nIf you have some tedious setup code, drop it in a file, and use the -i flag to run it and hop back into an interactive session:\n\n    python -i mysetup.py\n\nThen you'll have an interpreter session with the setup code already performed. \n\nI'm fairly certain you can do this with ipython too. ", "id": "c885b6m", "owner_tier": 0.5, "score": -7.692307645557915e-10}], "link": "https://www.reddit.com/r/learnpython/comments/17r64a/how_do_i_reimport_something_into_the_repl_after/", "question": {"content": "I'm using IPython (and loving it) and I often edit a source file and want to just re-import that file, replacing the contents of the previous import.  If I do 'from module import *', it doesn't pick up any of the changes.  There is a bit of IPython magic that will let me completely reset the REPL, removing everything that has been imported or defined, but that's not what I want.  I want to just remove the module then re-import it from the changed source.  Is there a magic for this in IPython or some support for this in Python itself?", "id": "17r64a", "title": "How do I 're-import' something into the REPL after changing the source file (using IPython)?", "traffic_rate": 153.13037037037037}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "If your python shell is `ipython` or `jupyter console` you can load the magic\n ```\n%load_ext autoreload \n%autoreload 2\n```\n\nMind to share your configuration?\n\nThank you. Several people have suggested something similar. As nanounanue says, can you share your configuration?", "id": "jofl63p", "owner_tier": 0.1, "score": 0.9999999989999999}, {"content": "You can, conceptually (as others say), reload modules in a python shell.\n\nBut that is not foolproof. There are ways for dangling references to old module code to linger; particularly if you have objects referencing code in stale, old modules in your `globals()`. Be very careful with this!\n\nHonestly, if you're building \"real\" software that spans multiple files, and not just single-file scripts and so on, you're probably better off not using the repl for this and instead interact with your application's state through a test + breakpoints or even by dropping into a shell directly in the parts of the code you want to test.\n\nSource: 15+ years of commercial python experience.\n\nTrue. The python repl is nothing similar than the lisp repl\n\n> But that is not foolproof. There are ways for dangling references to old module code to linger; particularly if you have objects referencing code in stale, old modules in your globals(). Be very careful with this!\n\nI definitely see your point. I haven't coded in Python until recently, but I'm familiar with the problem of dangling references that you mention. Many interpreters and programming system suffer from it. There's a little bit of it in Emacs itself, as you're probably aware.\n\n> Honestly, if you're building \"real\" software that spans multiple files, and not just single-file scripts and so on, you're probably better off not using the repl for this and instead interact with your application's state through a test + breakpoints or even by dropping into a shell directly in the parts of the code you want to test.\n\nI can see the advantages of doing that. Python-mode seems to be very focused on the REPL. Is there another mode that changes this behaviour?\n\nI use `M-x compile` for script running. (Note I tend to wrap most of those in a Makefile to make things repeatable in/outside of Emacs. But that is of course optional.)\n\nIf it's an executable script, you can call it via that, or using `python -m` if it's a module that you've installed. Tracebacks are correctly highlighted and link back to your code regardless of the method, provided it's output to stdout.\n\nAnother option that I also use is to run things through a test runner. `pytest` is the defacto standard for most commercial projects that aren't stuck with the builtin `unittest` package.\n\nPytest is good because regardless of your views of unit testing; tdd; etc. it's just a really good way of writing repeatable test harnesses. There's a nice `python-pytest.el` package that adds magit integration. I use a heavily modified version of that; it's great.\n\nOh, and the reason why I recommend ditching the REPL is that a lot of things don't really map well into a \"reload or send stuff to a REPL\". Things like request-response actions if you're doing web dev. (It's *possible*, but it's not ergonomic at all.)\n\nOh and check out my combobulate package: it's needs tree-sitter and Emacs 29, but it's got good python integration.\n\nExcellent, thank you!", "id": "joftvoy", "owner_tier": 0.3, "score": 0.9999999989999999}, {"content": "Developing \"SLIME\" style sounds nice but I found it to be impractical.  I recommend the standard compile-iterate workflow combined with writing unit tests; as a bonus you can keep the unit tests for future regression testing.  You can set up Emacs to run compile automatically and show the results in a buffer, so you can see the results live as you edit/save.\n\nMind to share how to do that?\n\nI'm not sure what you mean. I've haven't had any serious experience with SLIME.\n\nDo you mean that it's best to use compile-mode with python rather than an inferior python process (with run-python)? I can see the advantages of that, but it seems to me that python-mode is setup entirely to use an inferior python process.\n\nThis is something that I had thought of. I imagined that someone had created a version of the python shell that reboots the python interpreter every time a library is re-imported. If that exists, then it solves the problem (though probably at the expense of time). Using compile mode is another option.", "id": "jogddlz", "owner_tier": 0.5, "score": 0.399999999}, {"content": "Unrelated to emacs, but I've done this with limited success using an ipython shell with the [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) magic. It lists the caveats (of which there are a few) at the bottom of the page.", "id": "jofl6sm", "owner_tier": 0.5, "score": -9.99999993922529e-10}, {"content": "Please share your config.", "id": "jofp5kf", "owner_tier": 0.1, "score": -9.99999993922529e-10}, {"content": "If I understand correctly you are using a Python shell (or \u201cinferior Python process\u201d in Emacs terminology) to run your code, is that correct?\n\nThis is not necessarily an Emacs problem, rather this is just how Python works. Others have mentioned the autoload magic which should work if you use either `ipython` or `jupyter console`. However if you don\u2019t, try the following:\n\n```\nimport importlib\nimportlib.reload(packagename)\n```\n\nThank you!\n\n>foolproof\n\nThis doesn't work. I have tried", "id": "jofr7h8", "owner_tier": 0.1, "score": 0.199999999}, {"content": "It\u2019s one of the real frustrations of interactive python, and the contrast is especially notable when you are inside a live, readily self-updating system like Emacs.  When you have say 10s of GB of data loaded, the admonition to \u201cjust restart python, that\u2019s how it\u2019s done\u201d is galling.  That said, you can certainly unload a library, e.g. by deleting it from sys.modules, then send it again and re-import.  \n\nThe problem is that existing objects reference a compiled internal version, and so point to the old code.  You can of course recreate your affected objects and it will work fine. But it\u2019s hard to do this rigorously (easy to miss some objects). \n\nIn iPython, %autoreload magic works pretty well to do all this \u201cmagically\u201d. It checks for changes on disk, reimports if seen, then scours existing objects and updates them to point to the new code. But heed this:\n\n> Reloading Python modules in a reliable way is in general difficult, and unexpected things may occur. ``%autoreload`` tries to work around\ncommon pitfalls by replacing function code objects and parts of classes previously in the module with new versions.", "id": "jogjkpm", "owner_tier": 0.3, "score": -9.99999993922529e-10}], "link": "https://www.reddit.com/r/emacs/comments/14bfcq9/emacs_and_python_imports/", "question": {"content": "Recently I have been doing some programming in python. I have got it working nicely in Emacs - I may share my configuration another time.\n\nI'm have a problem with imports though. In Python you bring in a library by \"importing\" it. I often have to edit libraries that are part of the project I'm working on. The problem is that in Python 3 you can't unload a library, nor can you replace it with a newer version.\n\nThis is a problem because Emacs python-mode is based around the idea of sending python code to a python shell. This works fine unless imports get involved. Once imports get involved you run into the problem that python will never re-import a library after it has imported it once. So, if you're editing a library the only way to update to the new version (which could be what you just wrote) is to stop the python process and start another one.\n\nIs there a fix for this? Has anyone written a package to at least make constantly restarting python more convenient?", "id": "14bfcq9", "title": "Emacs and Python Imports", "traffic_rate": 12.050219817382482}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "For importing python modules, there's importlib.reload(). I use it a lot since I execute code on notebooks but have my code on a python file. When you reload a module, it gets all changes without having to restart the kernel.\n\nI'm not sure it works for your particular case, though.\n\nGot it! Thanks for the answer.", "id": "kuwk6sd", "owner_tier": 0.5, "score": 0.599999998}, {"content": "How does the file which is modified get used? What type of file is it? How often does it get modified? Can you control when this is? Is the previous content of the file still usable for a period after the content is changed or must the new content be used immediately? Is restarting the container itself a problem or do you just need constant availability? Would reading the file on every use degrade your performance to an unacceptable level?", "id": "kux18gk", "owner_tier": 0.3, "score": 0.399999998}, {"content": "i feel there is some gap in the translation.\n\n>Most programs load the contents of the file when the application starts up, and that's it!\n\ni'm not sure what this means.\n\n>Hence my question: how can I load a file and reload it automatically when it changes (without restarting the application)? What's best practices in my case?\n\nhow do you load this file? normally?\n\ni'm confused .. seems to be way to simple of a thing to be confusing.\n\nyou can add a checksum mechanic and cycle it on timer. on a different process?\n\nthen if file checksum is different then you reload.", "id": "kuxhak6", "owner_tier": 0.3, "score": 0.399999998}, {"content": "I don't think your goal is a good one: it's much simpler to reason about a program that doesn't rely on an external value that might change transparently partway through execution. It's also much easier to hook into audit systems of changes usually if you have to kick off a rolling restart, which is helpful when systems start paging.\n\nIf you _really_ want to avoid restarting for some reason, I'd have the app pulling secrets directly from Vault every time, perhaps with a time-based cache tuned to your requirements. But I really prefer baked secrets at container startup and kicked rollouts (just have to have a system or process that ensures these do happen).", "id": "kuxlfk4", "owner_tier": 0.7, "score": 0.399999998}, {"content": "You could check the modified time of the file in a loop and only reload if it's changed.\n\nThat's pretty much what I imagined, but I guess there must be a lib that takes care of that and will be much better done than the one I could make.\n\nSomething like this should work\n\n&#x200B;\n\n    def has_file_changed(filename):\n    `global last_modified_time`\n    \n    `current_modified_time = os.path.getmtime(filename)`\n    \n    `if current_modified_time != last_modified_time:`\n    \n    \t`last_modified_time = current_modified_time`\n    \n    \t`return True`\n    \n    `return False`\n    \n\nthen where you want to check if it's changed.\n\n    \t`while True:`\n    \n    \t\t`if has_file_changed(selected_filename):`\n                        data = read_json(selected_filename)\n    \t\t`df = data_to_dataframe(data)`\n\nThanks for the instructions! But it's going to block my programme! I'd have to run it asynchronously, wouldn't I? I've never run it asynchronously, so I don't know if that's possible yet.\n\nno, the while loop runs within your program and only does anything when the file's changed.", "id": "kuwtjv5", "owner_tier": 0.3, "score": 0.9999999980000001}, {"content": "Fastapi does this when you are working on your code so maybe take a look at that\n\nWatchfiles package\n\nThat's true! Uvicorn do this. Thanks I will get a look.", "id": "kv415ho", "owner_tier": 0.1, "score": 0.599999998}, {"content": "Search \"watch file for changes Python\".", "id": "kuxsfcc", "owner_tier": 0.7, "score": -2e-09}], "link": "https://www.reddit.com/r/learnpython/comments/1bexikb/how_can_i_load_a_file_and_reload_it_automatically/", "question": {"content": "Hi,\n\n  \nContext: I'm working on Hashicorp Vault in Kubernetes, with FastAPI; this is a detail, you don't need to master these technologies to be able to help me.\n\n  \nVault is capable of modifying a file containing a secret on the fly, without needing to restart my container. But it can't do the same for environment variables (that would require restarting the container).    \nExcept that, if I use a secret in a file, the limitation comes from elsewhere. Most programs load the contents of the file when the application starts up, and that's it! So even if I manage to update my file, it won't be reloaded.\n\n  \nHence my question: how can I load a file and reload it automatically when it changes (without restarting the application)? What's best practices in my case?  \n\n\n  \nThanks!!!  \n", "id": "1bexikb", "title": "How can I load a file and reload it automatically when it changes (without restarting the application)?", "traffic_rate": 153.13037037037037}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "There is some talk about this in stack overflow, but generally the only time I have seen imports done in a method or function it was for one of two reasons. 1. The method is called so very rarely that importing it at the beginning gives worse performance because it is generally never used. This is more an issue for microservices. 2. To hide from a circular import issue. Neither are stellar reasons to do it. Importing in the method will have a smallish impact on the runtime of that method the first time you call it. Honestly I hate seeing it done that way but that's just me.\n\n> 1. The method is called so very rarely that importing it at the beginning gives worse performance because it is generally never used.\n\nAlso because *you don't want to make the user install this library*.\n\n> 2. To hide from a circular import issue.\n\nI hadn't thought of / remembered that one. Good point. \n\nI'd add unittests to that list.\n\nYour test can be more granular if you import inside the test itself.\n\nCircular imports are not an issue, Python's memory allocator is smart enough for that. I don't actually know or understand what kind of magic that uses to work safely, but this worked fine:  \n\n\nfoo.py\n\n    import bar\n    def foo():\n        return 'foo'\n    def foobar():\n        return bar.bar()\n\nbar.py\n\n    import foo\n    def bar():\n        return 'bar'\n    def foobar():\n        return foo.foo()\n\n$ python3\n\n    >>> import foo\n    >>> foo.foo()\n    'foo'\n    >>> foo.foobar()\n    'bar'\n    >>> foo.bar.foo.bar.foobar()\n    'foo'\n    >>> # And just out of curiosity, let's check the IDs\n    ... id(foo)\n    139627125511576\n    >>> id(foo.bar)\n    139627125511816\n    >>> id(foo.bar.foo)\n    139627125511576\n    >>> id(foo.bar.foo.bar)\n    139627125511816\n\nThey will have to to install the library regardless. If the method isn't called by the user then remove it before shipping :) add a test to verify it is removed.\n\nWhile this might seem true and granular is good for tests. Python caches the import after it sees it the first time. So after the first test it will not reimport the library in the next test. Use a global counter to verify this.\n\nI promise you circular imports are an issue. As I am fighting them at work right now because someone before me did some crazy things and used importing in functions to get around it.\n\nWhat happens is that it sees a module you have already imported in your sys.modules and.doesn't try again\n\nBut this breaks if you use the \n\nfrom x import y \n\nsyntax since you need to get to the end of x\n\nWell the place this tends to come up is when you have a rarely-used feature. \n\nFor example, suppose ou are writing a git client, and it can optionally output it's results to graphviz, or plot a graph or something. You might not want to depend on matplotlib for normally functionality (e.g. running on a server - doing useful things). But you might still want the functionality there for the desktop client.\n\nI guess there are alternatives. I suppose you could have two libraries built from the same code base with different dependencies couldn't you. I'm not sure that's much better tho!\n\nAnother example is the Excel functionality in pandas - it doesn't import xlrd or pyopenxl until you try and read/write an Excel file because 90% of users probably only work with CSVs and they don't want to force the installation of dependencies that aren't necessary\n\n`reload`", "id": "e9hh7v2", "owner_tier": 0.1, "score": 0.9999999998734178}, {"content": "Some arguments:\n\n* Importing things can be slow (scipy and numpy come to mind) and importing is done when the import statement is run. This can add slowdowns when the programming is running (rather than when it is starting). Sometimes this is desirable - sometimes not.\n* Importing things later means that missing imports are detected later than they might otherwise be. All things being equal, it is good to detect errors earlier.\n* Sometimes you might not want to rely on having modules installed but use them if they are there for a particular feature. (Suppose your tool can export to some niche format - excel comes to mind (I was reminded about this from another comment)). It can be natural to delay the import here, and cleaner than a bunch of ugly try/except code.\n* Given the above *reasons* for importing later. It can violate the \"rule of least surprise\" to import late. People might think \"why are they importing here - it might be for this reason - but there is no comment\". \n* There are a couple of \"standard\" arguments that people might come up with (personally I think these are post-hoc rubbish arguments used to win arguments). a) It might be confusing to assume that you a module is in global scope in one function and then find it isn't (an awful lot of things are confusing - that is why you use a linter and run your code) (b) It is nicer to see all the imports in one place (meh, there are quite a lot of imports when do you ever read them) (c) some tools might  use top level imports (this is a little more compelling)..\n* Doing what other people do unless there is a good reason not to results in less surprise and less confusion.\n\nI don't know. Programming is hard.... or rather ordering all the junk when coding is hard. \n\nMy personal bias would be towards top-level imports base on a neatness argument (keep things in one place; fewer categories are good), reserving late imports for when they are required with imports. I would then refactor at the *module* level to reduce the number of imports in scope (e.g. add more modules), or use dependency injection of some description, maybe.\n\nI think the really compelling argument is \"early error detection\" and \"consistent run-time post startup\". \n\nI hate complexity... I hate programmers :/\n\n\n\n*Edit: grammer*\n\n\n\n\n\n\n\n\n\n\nBut complex is better than complicated. \n\n:) Indeed... each and every one of us must [medidate on the scriptures](https://www.python.org/dev/peps/pep-0020/) and interpret them ourselves.", "id": "e9hhwmx", "owner_tier": 0.3, "score": 0.13924050620253164}, {"content": "Surprised no-one mentioned when your script is meant to be run with command-line arguments (such as through arg-parse). In such a case, you may want your script to start up quickly so it can display that --help instead of waiting for unused imports to load.\n\nIn that case I'd still put the imports near the top, just after the argparse collection which I'd shuffle off in one function call to its own module,then have if-thens for the imports", "id": "e9ij957", "owner_tier": 0.3, "score": 0.03797468341772152}, {"content": "PEP-8 says to do all imports at the top. Further to that you should do all built-in imports first then 3rd-party imports and your local application imports last. Personally I don't bother so much with separating built-in from 3rd-party because I don't remember what's actually built-in and what I installed on my system years ago, but I still keep local imports last.\n\nBasically, imports always affect the global scope, and messing with the global scope somewhere down in a method or clause **never** makes \"more sense\" as it will change the scope for every other method & clause regardless of their position in the code. I have in the past done something like `mod = import('MyModule')` which should import in the local scope, I would say I was wrong to do so but it might be acceptable in some very very rare circumstances\n\ntl;dr: Imports first, then global constant variable definitions, then class/function/etc definitions, then you have your logic usually enclosed in a `if __name__ == '__main__'` but that's entirely up to you.", "id": "e9j6k72", "owner_tier": 0.3, "score": 0.03797468341772152}, {"content": "Yes. From PEP8: \"Imports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants.\"\nThere's generally no reason to import in the middle of the file\n\nYet many open source libraries and core python does it.  There is always an exception.\n\nThat's why I said \"generally\". There of course are cases. ", "id": "e9igkgv", "owner_tier": 0.7, "score": 0.05063291126582278}, {"content": "Others have covered some of the exceptions, but the general rule is to put everything at the top unless you have a specific reason to do otherwise. ", "id": "e9iuhn5", "owner_tier": 0.7, "score": 0.025316455569620255}, {"content": "Please keep imports at the top.  https://www.python.org/dev/peps/pep-0008/#imports", "id": "e9j2u03", "owner_tier": 0.5, "score": 0.012658227721518988}, {"content": "Importing at time-of-usage makes sense to me, if the docs make it clear that optional dependencies enables a specifc feature.  Else, just raise a clear NotImplementedError.", "id": "e9i1fs2", "owner_tier": 0.1, "score": -1.2658227771171254e-10}, {"content": "It depends how dependent your program is on the import.  If you have a library that you import once in a blue moon and don't expect all users to install, then putting it into a function helps keep start up times low and the program from breaking completely.", "id": "e9jglbl", "owner_tier": 0.5, "score": -1.2658227771171254e-10}, {"content": "I hate it, but there are some cases when it makes sense.\n\nFor example in the awesome flask mega tutorial:\n\n[https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world)\n\nthe imports of your own routes, models are done after some code is executed that is necessary for localization.", "id": "e9jnqui", "owner_tier": 0.1, "score": -1.2658227771171254e-10}, {"content": "I do it all the time - I write a LOT of scripts at work to move data around and it makes it super easy to copy/paste a chunk of code .. with the import if it does something unusual .. I run all my stuff through black and flake8 ..\n\n&#x200B;\n\nNot a great example but i was playing with limits for recursion, memoizing, etc the other day - you can see where I added sys and functools.\n\n    #!/usr/bin/env python3\n    import argparse\n    \n    import sys\n    sys.setrecursionlimit(200000)\n    \n    parser = argparse.ArgumentParser(description=\"Process some integers.\")\n    parser.add_argument(\"fibof\", type=int, help=\"What Number did you want to fib?\")\n    args = parser.parse_args()\n    fibof = args.fibof\n    \n    # @memoized\n    import functools\n    @functools.lru_cache(maxsize=20001)\n    def fib(n):\n        if n <= 1:\n            return 1\n        return fib(n - 1) + fib(n - 2)\n    \n    print(f\"fib({fibof})={fib(fibof)}\")\n\n&#x200B;\n\nMy thinking is if it ever becomes an issue, I can find a tool to move them for me.", "id": "e9mtyf0", "owner_tier": 0.3, "score": -1.2658227771171254e-10}], "link": "https://www.reddit.com/r/Python/comments/9w4m96/is_it_bad_form_to_import_in_the_middle_of_the/", "question": {"content": "I usually import all the libraries I need to use at the top, but sometimes it looks nicer elsewhere and if I only need that library in one meathod or clause does it make more sense to do that or just import everything at start.", "id": "9w4m96", "title": "Is it bad form to import in the middle of the program", "traffic_rate": 207.942496260595}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "When you import a module, all code that is in the module is ran, this may be needed as a setup for some module.\n\nIf you dant want to run some code when you import the file, use this:\n\n    if __name__ == \"__main__\":\n        bar()\n\nThis will make sure that bar() function is only ran when you run hello.py directly, but not when you import it.\n\nSo then what's the difference between these two lines? Won't they both run everything in that module?\n\n    from hello import foo\n    from hello import *\n\n> When you import a module, all code that is in the module is ran, this may be needed as a setup for some module.\n\nThis is a good answer. \n\nI'd also add that when you import a package (not an individual .py module), something similar happens - the \\_\\_init\\_\\_.py file is run. Importing pandas runs this code - https://github.com/pandas-dev/pandas/blob/main/pandas/\\_\\_init\\_\\_.py\n\nMost developers try to minimize the amount of global code. Use it when needed, but otherwise keep your code inside functions with a clear control flow.\n\nBro, this is fantastic. You have no idea how this is going to help me on a couple projects I have going.\n\n    from hello import foo\n\nwill only allow you to use foo function in world.py\n\n    from hello import *\n\nwill allow you to everything from hello.py in world.py\n\nThe difference between these two lines is THAT YOU NEVER USE THE SECOND FORM!  EVER!\n\n(Except when you have a reason for it, but you don't sound like someone who is or at least was far enough in Python experience to know when)\n\nIf you are doing multiple python projects and you weren't aware of this, you might want to spend some extra time learning about python before proceeding\n\nOk so they both run the entire module but the difference is in namespace\n\nSo does `import hello`.  Never ever ever use `import *`.  Ever.\n\nThis is a sub for learning python. Don't be weird.\n\nI've already made and deployed several for some teams at my workplace that have worked to increase efficiency and give the teams more time for other things. This will help me to divide out some more complex ones that I have in the works. But thanks, I'll just keep learning python by doing.", "id": "jmv0v8m", "owner_tier": 0.5, "score": 0.9999999999090909}, {"content": "Because individual functions or classes or variables may depend on the presence of functions or classes or variables in the rest of the module. They may not, but there is no reliable way to determine this. The only reliable option is to run the entire file.\n\nFor example, consider something like this:\n\n    # module.py\n    import json\n    import os\n    DATA_DIR = \"/path/to/data\"\n    \n    def get_data_file(filename, key):\n        with open(os.path.join(DATA_DIR, filename)) as f:\n            return json.load(f).get(key)\n\nAnd then you do:\n\n    from module import get_data_file\n\nIf Python \"only ran\" the definition of the specific function, it would error out when you ran it because `json` and `os` wouldn't be imported, and `DATA_DIR` wouldn't be defined.\n\nI see, that makes sense. So I guess that's why you would do the whole if \\_\\_name\\_\\_ thing like the other commenter helpfully mentioned.\n\n&#x200B;\n\nWhen would it be a good idea to use that condition? The only thing I can think of is for debugging purposes if you're only interested in testing a single file\n\nThe typical use case for that is for modules that you want to provide a library interface as well as an interactive interface, i.e. they do something useful and different when executed standalone from the command line.\n\nI might have a module which just provides some functions when it is imported, but if I do `python module.py` on the command line it gives me a command-line interface, or similar.\n\nFor example there's the Python module `http.server`. When you import it it gives you a bunch of functions and classes related to HTTP servers, as the name suggests. But if you do `python -m http.server` (-m means to run a module as a standalone program), it starts up an actual working HTTP server serving the contents of the current directory. Very useful to quickly throw up a file share on the local network.\n\nIn short, in case you want it to be a script, but also have some functions you might use elsewhere.\n\n\n The name =main bit let's you call the script directly or with python -m module.submod (this calls the file  __main__.py in module/submodule) but also be able to import it without the script bits hijacking the process.\n\nits useful for scripts, that take some arguments and produce some output in terminal or do other stuff.\n\nThis is the equivalent of the main function in any other language. So it is the same answer to when should you add a main function to a module in Java, C/C++, etc?", "id": "jmv1bwq", "owner_tier": 0.7, "score": 0.1818181817272727}, {"content": "Basically, because anything can happen in \"the rest\" of the file.\n\n\nYou can have\n\n    def hello():\n        print(\"hello\")\n\nAs the first thing in the file, then at the bottom have\n\n    hello = lambda: print(\"goodbye\")", "id": "jmvaq6k", "owner_tier": 0.7, "score": 0.027272727181818182}, {"content": "One thing you need to realize about Python is that the `def foo():` in\n\n    def foo();\n        print('i am foo')\n\nis not a declaration like in other languages, but actually a statement like \u00e0 = 5`.  Python compiles and then executes it.  Everything in your Python module or script is a statement (`from module import function` is a statement that gets *executed* at runtime)\n\nYes, every module gets loaded and executed.  Everything in there.  So, if you don't want `bar` to be executed, don't put a function call into your module.", "id": "k3rn6l7", "owner_tier": 0.5, "score": -9.090909035659355e-11}, {"content": "Under the hood, \u2018from hello import foo\u2019 imports the entire module \u2018hello\u2019 and then afterwards removes all imported things that are not \u2018foo\u2019.\nIt\u2019s a bit counterintuitive, but Python has never been known for being the most efficient language\n\nIt doesn't \"remove\" anything. It just only creates a specific `foo` variable in the calling environment. If there was a module-level object defined that isn't imported, `foo` will still have access to it.\n\n`from foo import bar as baz` is effectively equal to\n\n```\nimport foo as _temp\nbaz = _temp.foo\ndel _temp\n```\n\n... which only creates a reference in the calling environment and then deletes the reference... the module still exists. The fact that foo can still refer to module-level variables and other functions from that module proves that the loaded module is still there.\n\n[Others agree](https://softwareengineering.stackexchange.com/questions/187403/import-module-vs-from-module-import-function).\n\nWhich means that \"foo\" is still loaded, completely.  There's just no name referencing this module in the importing module's namespace (since you deleted the reference, `_temp`).\n\n`del` doesn't do what you seem to think it does.\n\nOh, and then your code is also wrong: `baz = _temp.bar` would be correct.", "id": "jmvqbsg", "owner_tier": 0.1, "score": 0.009090909000000001}], "link": "https://www.reddit.com/r/learnpython/comments/140d9ha/why_does_python_run_an_entire_module_when_you/", "question": {"content": "Say I have two files.\n\n[hello.py](https://hello.py):\n\n    def foo():\n        print('i am foo')\n    \n    def bar():\n        print('i am bar')\n    \n    bar()\n\n&#x200B;\n\nand [world.py](https://world.py):\n\n    from hello import foo\n\nWhen I run the command, `python` [`world.py`](https://world.py) I didn't expect the `bar()` line to execute. I thought I'm just importing the `foo` function definition into the [world.py](https://world.py) file. Can anyone explain how and why this is happening?", "id": "140d9ha", "title": "Why does Python run an entire module when you only import one function from it?", "traffic_rate": 153.13037037037037}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "I'd say it's normal behaviour in Python and, by extension, MicroPython. Once a module is imported, it's added to the global module list and will not be imported again, even if the file itself has changed. Renaming the file makes you import it under the new name, so Python thinks it's a completely different module and adds it to the list. I assume here that the Pico is not reset before running a new project, which is weird, but not impossible and depends entirely on how the VS Code extension works. I know that Thonny forces a soft reset before running any file, probably to avoid some problems, including the one you're experiencing.\n\nI've never experience that Python does not recompile a library file that hac been modified. But I guess something else is happening here.   \n\n\nIf I disconnect and reconnect the RPI Pico, the changes appear.  \n\n\nBut thank you, horuable. \"I assume here that the Pico is not reset before running a new project\".   \n\n\nI tired:  \n* Change a library file (in root folder)\n* MicroPico: Reset > Soft\n* MicroPico: Upload project to Pico\n* VS Code: Run main project file\nWorks!\n\nQuite annoying though. And if this is the right way to do it, it should probably be documented MicroPico how-to-get-started..\n\nAFAIK Python never reloaded modules that were previously imported and always used the version that was already loaded in memory. There are ways to force reload, but they're exclusive to Python and don't work with MicroPython. Reconnecting Pico or resetting it clears the memory, so the module can be loaded again, with the changes that were made.\n\nAs for the documentation, RPi recommends using Thonny for MicroPython development, so I doubt they would be willing to add third party VS Code extension to their documentation.\n\nYes, you are quite right.  This is my first micropython project, so it just didn't occur to me that it wasn't starting \"from scratch\" each time I pressed play.   \n\n\nBut the way the system behaves, it all makes sense now. What I experienced as \"cached\" was just \"imported\" in a running python module.   \n\n\nJust a shame that the MicroPico didn't bundle this in one operation.   \n\n\nBut thank you both! I have a better understanding now.  :)", "id": "kp1w5bh", "owner_tier": 0.5, "score": 0.9999999980000001}, {"content": "I have used vs code micropico for over a year on raspberry pi and find it very stable and ideal for programming.  I have a similar scenario where I have supporting project files, and re-upload them when needed by running \u201cupload project to pico\u201d.  (Supporting files have been html and py files).  All works well. \n\nYou may want to ensure the supporting file types you want uploaded are standard and defined in micropico settings.  Also ensure the files are in the main project folder,  or in nested subfolders.\n\nCorrection: last sentence should read NOT in nested subfolder.", "id": "kp2kbki", "owner_tier": 0.1, "score": -1.999999987845058e-09}], "link": "https://www.reddit.com/r/raspberrypipico/comments/1ajlr85/micropico_for_vs_code_changing_library_files_dont/", "question": {"content": "When I change the main file, all updates take effect when I debug or run the code on my Raspberry Pi Pico.   \n\n\nBut when I change any of my library files, there is no change on the program running on my Pico. And I do use 'MicroPico: Upload project to Pico' before testing.   \n\n\nHowever, if I rename changed file from [mylib.py](https://mylib.py), to [mylib2.py](https://mylib2.py), save all referencing files, and then upload project to Pico, suddenly my changes take effect. \n\n&#x200B;\n\nAnyone else experiencing this?   \nIs there a fix? Or is this a bug I should report?\n\n&#x200B;\n\n*(Similar, but not the same question as* [*VS Code (Micropico) Workflow*](https://www.reddit.com/r/raspberrypipico/comments/174zrg7/vs_code_micropico_workflow/)*)*", "id": "1ajlr85", "title": "Micropico (for VS Code): Changing library files don't update", "traffic_rate": 8.432283464566929}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "[`collections` is also a standard Python module](https://docs.python.org/3.7/library/collections.html#module-collections), that's probably why.\n\nIf you inspect the collections module, it should become clear that it's not the one from your `collections.py` at first. `importlib` probably uses a different path resolution method for modules.\n\nIf you don't want to rename your module, you could investigate using a package so you could use relative imports.\n\nAh, that clears it up. Thanks!", "id": "ex98obh", "owner_tier": 0.1, "score": 0.9999999980000001}, {"content": "Hello! I'm a bot!\n\nIt looks to me like your post might be better suited for r/learnpython, \na sub geared towards questions and learning more about python. \nThat said, I am a bot and it is hard to tell.\nPlease follow the subs rules and guidelines when you do post there, it'll help you get better answers faster.\n\nShow /r/learnpython the code you have tried and describe where you are stuck. \n\nYou can also ask this question in the [Python discord](https://discord.gg/3Abzge7), \na large, friendly community focused around the Python programming language, open to those who wish to learn the language \nor improve their skills, as well as those looking to help others. \n\n\n\n***\n\n[^(README)](https://github.com/CrakeNotSnowman/redditPythonHelper) \n^(|)\n[^(FAQ)](https://github.com/CrakeNotSnowman/redditPythonHelper/blob/master/FAQ.md) \n^(|)\n^(this bot is written and managed by /u/IAmKindOfCreative) \n\n\n\n^(This bot is currently under development and experiencing changes to improve its usefulness)", "id": "ex94x4i", "owner_tier": 0.3, "score": -1.999999987845058e-09}], "link": "https://www.reddit.com/r/Python/comments/crtfps/why_are_my_imports_not_working_without_importlib/", "question": {"content": "I have three files - `models.py`, `tasks.py`, and `collections.py`. `tasks.py` imports the other two. It works just fine for the models file, but doesn't work for collections:\n    \n    import collections    \n    from models import FirstModel, SecondModel\n\n    # First / Second model can be used just fine, but accessing a variable from the collections file throws this: \n    # AttributeError: module 'collections' has no attribute 'COL_A' \n    \n\nHowever, if I use `importlib.reload`, it starts working fine:\n\n    import importlib\n    import collections\n    importlib.reload(collections)\n    \n    # collections.COL_A can be accessed normally.\n\nCan anyone help me understand what's happening here? Coming from the JS world, I've been scratching my head for the last half hour.", "id": "crtfps", "title": "Why are my imports not working without importlib?", "traffic_rate": 207.942496260595}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": ">does Python even require such a directive?\n\nNo, python rarely cares about things like this", "id": "go7jtli", "owner_tier": 0.3, "score": 0.6666666633333334}, {"content": "You don't need to worry about importing the same library multiple times.\n\nIt's done as efficiently as possible... (usually actually importing only once)\n\nI read that the garbage collection in Python was a non-issue as it is handled on the back end or something and the programmer will almost never have to even think about it. This led me to question whether multiple imports would be an issue.\n\nSo, even though I might import a library twice or more times just to make the code in separate modules work, the back end is smart enough to only import it once when the program is executed? Nice! One less thing to worry about!", "id": "go7jcic", "owner_tier": 0.7, "score": 0.6666666633333334}, {"content": "Each import creates something like a separate namespace, so you will never have to worry about this. It may use more RAM if something is imported twice, but if your module requires it and your main file also requires it, you have no choice so there's no point worrying about it.\n\n> It may use more RAM if something is imported twice\n\nThis is also something I eventually want to avoid. Perhaps I could refactor the text wrap code so that it doesn't require the library, or streamline it so it's not so bulky. The more I think about it, the more I believe someone already invented this wheel... I'm almost certain that there may be a separate library which handles pygame text operations...\n\nYou can import just the parts you want, for example\n\nfrom library import function\n\nI don't know if that reduces RAM usage, but worth investigating.\n\nHonestly if resources are that important Python is the wrong language anyway. An eight byte integer uses something like 28 bytes of RAM. There are things you can do to work more efficiently but you're just fighting the language when you could be using one that's better suited.\n\nI'm guessing you don't want to move away from python since you're using PyGame. If you know C or C++ you could write some helper code in those languages, and then use it in python via the ctypes module (or various other methods).", "id": "go7lb3i", "owner_tier": 0.7, "score": 0.9999999966666667}, {"content": "You may find [this importlib tutorial](https://realpython.com/python-import/) of interest.", "id": "go9h9ny", "owner_tier": 0.3, "score": -3.3333333130750966e-09}], "link": "https://www.reddit.com/r/learnpython/comments/losdq6/do_i_have_to_worry_about_importing_a_library/", "question": {"content": "SOLVED! (And then some)\n\nI'm experimenting with pygame, and I want to put a rather large function which handles text wrapping into its own file and import it into the main file. However, it also relies on pygame for the font objects. I am aware that in C and probably a few other languages there needs to be compiler directives such as \"#ifndef\" to prevent duplicate imports. Being an interpreted rather than compiled language, does Python even require such a directive?", "id": "losdq6", "title": "Do I have to worry about importing a library multiple times?", "traffic_rate": 153.13037037037037}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "For external modules like the google module you're talking about, the issue is the interpreter. If you always and forever want to use the same interpreter when you're using pycharm, you can [configure a system interpreter](https://www.jetbrains.com/help/pycharm/configuring-local-python-interpreters.html). This should make it so that your desired interpreter is always used as the base interpreter for any new projects. \n\nI don't know why re isn't importing as this module is a built in module. I guess it could be that a new project does not have an interpreter associated with it at all. In that case configuring the system interpreter should fix it. \n\nAlso, what system are you on and how do you manage your python versions?\n\nThank you! Good to know about the option to configure system interpreters.\n\nMy O/S is Win 10.  For this project I used 3.6 which I had installed after downloading from [python.org](https://python.org) just prior to the project.\n\nI was able to get the google module working again by switching the python version in project interpreter back to 3.6 - not sure why but it was set to 3.7 just now before I did that.  I also redid the pip-install google.\n\nThankfully re is importing again now, I'm not sure what it was that fixed that but I can get my code to execute again so all good.\n\nEdit: I think I figured out why Pycharm was stating that the modules were not defined.  Looking at File/Settings/Project/Python Interpreter I have multiple installations of Python 3.6 on my system.  As far as I can tell, the interpreter was updated to 3.7 somehow (I'm not sure how that happened).  Then when I changed to 3.6, I initially changed to the wrong one - i.e. one where the modules I needed were not present in the python folder in Windows.  By switching the python interpreter to the correct installation of python where the modules (e.g. the google module) are installed, I was able to execute my script without getting an error that modules are not defined.\n\nI'm still not sure why re was coming back as not defined though because as lanemik mentioned it is a built in module.\n\nI recommend learning about virtual environments. PyCharm will set one up for you super easily. You install every dependency you need on the virtual environment and things like updating python on your machine, or uninstalling an old version, won\u2019t break your production environment. \n\nBonus tip: keep track of every library you install (and the version!) in a text file, so if you ever share the application you can make sure changes between versions of your dependencies don\u2019t break your functionality!\n\nThanks for the great tip, yes I definitely need to do that because I think it's at the root of my module issues", "id": "i7xeoij", "owner_tier": 0.5, "score": 0.9999999980000001}], "link": "https://www.reddit.com/r/learnpython/comments/ult5g3/why_would_pycharm_fail_to_find_modules_that/", "question": {"content": "I'm an infrequent coder and am relatively new to Python.  I'm using Pycharm and have found importing modules to be one of the biggest 'casual user' pain points.\n\nAn issue that I'm facing currently is that code I wrote about a month ago which executed fine then won't execute now.  I'm getting errors stating that modules are not defined.  These modules are imported by global functions which are used in my script.  For example the re module and google module are supposedly not defined now even though I could import them without an issue last time I executed the script.\n\nI'm not sure why this is happening.  I haven't opened Pycharm since it worked about a month ago.  Perhaps Pycharm auto-updated in the interim though I'm not sure.\n\nAre there settings within Pycharm which I should configure to ensure nothing changes between (infrequent) uses?  For example, do I need to configure Pycharm not to auto-update which version of Python my projects use as interpreter?  Do people generally set Pycharm itself not to auto-update, or do you have to be on the lookout for updates it applies so that you can change your settings to fix stuff like the above?\n\nIn the current case one of my problems (Pycharm thinking the google module is not defined) was resolved by changing the Python interpreter for my project from 3.7 back to 3.6 in project settings.  I can't figure out why it thinks re isn't defined though.  When I open the global function which is importing re, the import works fine in that script.  When the calling script imports re directly that works fine.  It's just when it calls the global script, the re import within the global script doesn't work.", "id": "ult5g3", "title": "Why would Pycharm fail to find modules that previously imported without a problem?", "traffic_rate": 153.17222222222222}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "Regardless of how you import a module, the entire module is loaded into your program.\n\nThe variations in import statements determine how the names in the module are made available to your code.\n\nWhen you do something like `import time`, you must reference the contents of that module using the module name e.g. `time.time`.\n\nWhen you do like `from time import time` or `from time import *`, you can reference the same function as `time`, e.g. without the module name.\n\n>\t\u00a0from time import *\n\nPlease don\u2019t encourage people to do this. It\u2019s bad practice.\n\nDamn, I always just assumed it was about optimizing memory usage by picking individual classes!\n\nfrom * import *\n\nWhy?\n\nis it okay tho if you import your own module? for example:\n\n> from MyClasses import *\n\nthis way you can easily keep your classes in a separate file but also use them as if they're in the same file\n\nHey just wondering, why is this bad practice?\n\nfrom * import * as foo\n\nhttps://giphy.com/gifs/success-dem-u8u0R51ND9L2\n\nCan confirm after doing this my computer hates me now\n\nwildcard imports can result in name clashes that results in code that runs differently depending on which order the imports are imported\n\n    \u279c  cat a.py\n    def hello():\n        print('hello from a!')\n    \n    \u279c  cat b.py\n    def hello():\n        print('hello from b!')\n    \n    \u279c  cat run1.py\n    from a import *\n    from b import *\n    hello()\n    \u279c  cat run2.py\n    from b import *\n    from a import *\n    hello()\n    \u279c  python3 run1.py\n    hello from b!\n    \u279c  python3 run2.py\n    hello from a!\n\nas a user you have no idea where `hello` comes from. it's better to always quality your imports, either through using `libraryname.function()` or `from libraryname import function` so it's obvious where it came from", "id": "iaxf71s", "owner_tier": 0.3, "score": 0.999999999970238}, {"content": "you mean why they do `from module import x, y, z` instead of `import module`?\nBecause they don't care about the rest and if you do selective import you don't have to type in the module.\n\nor maybe you are asking why they don't import all modules every time?\n\nSo say I\u2019m importing flask. Usually I would do From flask import flask. Should I just do import flask?\n\n> Should I just do import flask?\n\nYou should do what is best for your situation.  Do you care about anything else in the top level `flask` package?\n\nIf not then you would just have to type `flask.flask` to use it instead of just `flask`.\n\nWhat makes more sense for your code?\n\nYou should import so that it remains obvious where the code you are running is located.\n\nFor example, `from flask import Flask`, when I use `Flask()` in my code, it's still pretty obvious that function belongs to the flask module. Similarly for things in the standard library: `randint()` and `permutations()`, as an example, are relatively unique and commonly known, so they can be assumed to be identifiable.\n\nHowever, is `sqrt()` from `math` or `numpy`? In this case, `import math; math.sqrt()` is probably more clear than `from math import sqrt; sqrt()`.\n\nAt the extreme end, consider modules that duplicate built-in functions: `from numpy import sum` now changes what happens when you call `sum()` in your code. As `sum()` is a builtin, very few readers are going to assume that a bare `sum()` call doesn't refer to the built in function. In this case I would say it's imperative that you call using the module name if using the numpy version.", "id": "iax7k4e", "owner_tier": 0.7, "score": 0.17857142854166666}, {"content": "personally I avoid importing things that are not modules, because I prefer to keep namespaces in my code. It makes it immediately clear that I am using a dependency.", "id": "iay4sgd", "owner_tier": 0.7, "score": 0.08035714282738095}, {"content": "To avoid polluting your namespace. \n\nLet\u2019s say moduleA has a function called doIt() that you intend to use. ModuleB also has a doIt() function, but you\u2019re using moduleB\u2019s doThisInstead() function. \n\nIf you import both modules, you\u2019ll have 2 functions named doIt() for no reason. Additionally, anytime you use either function you\u2019ll have to call it by entering moduleA.doIt(), which is a lot more to type out than doIt() potentially hundreds of times.\n\nThat won\u2019t pollute your namespace because you need the module\u2019s name to access everything in each case. Using from x import a actually creates this potential issue.\n\n    from x import a\n    from y import a\n\n    # access to x.a() is lost\n    a()\n\nI don't understand what you're saying. What import method are you advocating? If you did `import moduleA` and `import moduleB`, how does that pollute the namespace?\n\nBut this is why aliasing exists.\n\n    from x import a as x_a\n    from y import a as y_a\n\nYes, I agree; but the point is `import x` doesn't pullute the program's namespace.", "id": "iay5nl9", "owner_tier": 0.7, "score": 0.12202380949404762}, {"content": "Why don't I eat the whole cake? I don't need it and it could cause issues. It is delicious though...\n\nwhat issues would it cause?\n\nExcept you DO end up eating the whole cake regardless of how you import. That's the point both OP and top-upvoted answer is making.\n\nKeeping your code both readable and maintainable is an important consideration.\n1. If I'm trying to read the code, I have no idea where that function came from.\n2. If multiple modules have the same class or function name, I could (have) use the wrong one.", "id": "iazd5xa", "owner_tier": 0.5, "score": 0.05059523806547619}, {"content": "Huh.. Learn something new every day. I've been toying with Python for a while now and I always kind of assumed it was to save time/resources from loading entire modules by doing like \"from x import y\" instead of just \"import x\". Didn't realize it was loading the entire thing regardless. This may change how I do things in the future.", "id": "ib06ebr", "owner_tier": 0.3, "score": 0.035714285684523804}, {"content": "To add to the discussion: READABILITY. It can be helpful for somebody to explicitly import only the utilities of a module that they are going to use, so right off the bat I can know what to expect.\n\nAlso, if I see a bunch of imports from deep within a library, I know it's going to be doing some advanced things in the code below.\n\nLastly, if you ```from module import *``` from a library I don't know very well, I have to read the code much more slowly looking for functions I don't know the names of.", "id": "ib084nz", "owner_tier": 0.1, "score": 0.035714285684523804}, {"content": "Do you mean in every script?", "id": "iax1zp4", "owner_tier": 0.7, "score": 0.03273809520833333}, {"content": "Many libraries can use the same name for their functions.  You may call the function from the wrong lib if you import everything.  You\u2019d have to call them explicitly to avoid confusion", "id": "iaxps1w", "owner_tier": 0.5, "score": 0.03273809520833333}, {"content": "This is a good question actually. Sure, stuff like asyncio takes ages to load (comparatively), but whether or not you import math, time and/or random makes no practical difference when actually using the script, even if you don't need any of the functions. It's perhaps some psychological thing that makes people minimalist about stuff like this, to the point that they use linters to check for unused imports or get fuzzy over this in reviews. I guess one benefit of only ever importing what you need is documentation. \"import math?\" \"Ah, math stuff happens here\".\n\nIt doesn\u2019t make a difference anyways because when you import from a module the entire module is still loaded at run time, and the unused parts of the module are deleted. There\u2019s no time saving difference between \u201cfrom x import y\u201d and \u201cimport x\u201d. I usually prefer to import the entire module because it becomes more clear where you functions are coming from.\n\n> and the unused parts of the module are deleted.\n\nNothing in the imported module is deleted since it's very expensive to figure out what is \"unused\".\n\nI have been told that, I\u2019ve never fact checked it. From what I have been told though when you import a library all functions and classes of the library are loaded into memory. When you specify which ones you want, they\u2019re all loaded but then the unused ones are subsequently removed. If this is not true is there any way you can link me anything that shows that? I genuinely would love to see the inner workings\n\nThe import mechanism [is documented here](https://docs.python.org/3/reference/import.html), but that's hard to read.  Searching on \"python import mechanism\" gets hits but may not cover the subject in depth.\n\nApart from the difficulty of deciding which parts of a module are unused there is also a module caching mechanism.  Doing an import of a module a second time uses the cached module from the first import, speeding things up.  Deleting unused parts of a module would make module caching unworkable.  That would make code like this inefficient and slow due to multiple imports of the same module:\n\n    from math import sin    # so we don't have to use \"math.sin()\" a lot, just \"sin()\"\n    import math             # for all other little used functions", "id": "iaxk0tt", "owner_tier": 0.5, "score": 0.041666666636904756}, {"content": "maybe its a file they wrote and they know everything in it. other times, could be they'd rather get a direct reference to everything in a file. it can get confusing though if its over used. if you have a lot of code and do that for many modules it can be hard to tell where something came from. i think doing what you suggested is ideal, but in some circumstances, it might be worth it to do from module import etc", "id": "iaxknhv", "owner_tier": 0.3, "score": 0.029761904732142856}, {"content": "It's just easier that way, if you only need 1 specific part of the module, why not just type from genericpath import exists, instead of typing genericpath.exists 20 times or something..       \n         \nOr I'll do you one better you can just import it as whichever name you want, you can say from genericpath import exists as ex, then you could just type ex(path) to check if it's true or not, saves lots of typing, or sometimes makes it easier to understand what exactly it does.         \n         \nIt could also be that if you compile it for release, like as an exe with pyinstaller, and you package it as 1 file that maybe (I'm not sure about this one but I'm just guessing) it includes all the modules you import in your code, so it might result in a bigger than necessary binary if you just import everything (but again i never actually checked that so I'm just guessing)", "id": "iaye7pt", "owner_tier": 0.7, "score": 0.029761904732142856}, {"content": "You\u2019ve already gotten plenty of high-quality answers. So I\u2019ll just add - What\u2019s really gonna bake your noodle is when you see people doing things like this:\n\n    import numpy as np\n    from numpy import nan", "id": "iayxvgo", "owner_tier": 0.7, "score": 0.029761904732142856}, {"content": "Some common reasons are that you only need one small part of it and don\u2019t want to type it all out. \n\n    from getpass import getpass\n    from pprint import pprint\n\n    password = getpass()\n    pprint(thatdict)\n\nVs\n\n    import getpass\n    import pprint \n\n    password = getpass.getpass()\n    pprint.pprint(thatdict)\n\nIf there\u2019s only one class in a module that you need, it makes it easier to type and read. \n\nFor example, I work in networking and made a library called `nwtools`. Within it, I have classes for working with different platforms (mostly shortcuts for dealing with other libraries). If I\u2019m working on a script that only uses my Clearpass API module (`nwtools.cppm()`), I\u2019d `from nwtools import cppm` because I don\u2019t want to have to type out `nwtools.cppm` every time.\n\ncan still do with import wildcard\n\n`from x import *` is generally recommended against unless you *really* know the package. Very easy to have overlapping namespaces. \n\nPEP8 has this to say on it:\n\n>\tWildcard imports (from <module> import *) should be avoided, as they make it unclear which names are present in the namespace, confusing both readers and many automated tools. There is one defensible use case for a wildcard import, which is to republish an internal interface as part of a public API (for example, overwriting a pure Python implementation of an interface with the definitions from an optional accelerator module and exactly which definitions will be overwritten isn\u2019t known in advance).", "id": "iazccvs", "owner_tier": 0.9, "score": 0.035714285684523804}, {"content": "Odds are that if you\u2019re doing that then your eyes are bigger than your stomach.", "id": "iazj55m", "owner_tier": 0.3, "score": 0.029761904732142856}, {"content": "I think ive read importing individual functions or classes from a module cuts down on the time it takes for the program to call those functions/classes, and speeds up execution time. Please correct me if I'm mistaken", "id": "ib21u37", "owner_tier": 0.1, "score": 0.029761904732142856}, {"content": "Save working memory (RAM)", "id": "iax2us1", "owner_tier": 0.7, "score": -2.9761907224415804e-11}], "link": "https://www.reddit.com/r/learnpython/comments/v3akjc/why_dont_people_always_import_all_of_a_module/", "question": {"content": "why don't people always do \"import time\" or \"import random\"?", "id": "v3akjc", "title": "why don't people always import all of a module", "traffic_rate": 153.17222222222222}, "saved_time": 1721102434, "source": "reddit", "tags": []}, {"answers": [{"content": "\r\n    The only barrier between DLLs could be the access modifier internal. And even this barrier can be broken via reflection, but you don't need it at all.\n\r\nFirst of all, you should not think in terms of DLLs. The central modularity concept of .NET is assembly, and \"DLL\" is nothing but a file naming convention; as to the file itself, it's nothing but a module of an assembly. Strictly speaking, each assembly can be composed from several modules, more than one, but usually you deal with only single-module assemblies; this is what Visual Studio creates by default.\n\r\nIf you use several assemblies in your application, they all are reference each other to be loaded through the main application assembly, directly or not, you access things in exact same way as all code was in the same assembly, with only one difference: internal declarations make types and type member accessible between any types of the same assembly, but access across assemblies requires public or internal. Please see:\nAccess Modifiers (C# Programming Guide)[^],\nAccess Modifiers (C# Reference)[^],\nUnderstanding and Using Assemblies and Namespaces in .NET[^].\n\r\nThat's all. I don't think I need to cover reflection topics.\n\r\n[EDIT]\n\r\nI scratched out my sentence about reflection above after I read the comment quoted below.\n\nMember 11326763 wrote:\r\nI can't pass it from the main program , or call one dll from another one, because I only write the plugins (dll's) to the system.\r\nAnd each dll implement a complex module , and I can't mix between them (the dll's load by reflection in running mode) .\r\nSo if you have any elegant solution I will happy.If it comes to plug-ins, I have to cover approaches based on reflection. Please see my past answers on related topics, all referenced in this one: Access a custom object that resides in plug in dll[^].\n\r\nThese topics are relatively complicated, especially if you have a need to unload some plug-ins to reload different once; I hope you don't.\n\r\nOne alternative approach is using the Microsoft framework for extensibility, MEF:\nManaged Extensibility Framework \u2014 Wikipedia, the free encyclopedia[^],\nManaged Extensibility Framework \u2014 Home[^],\nManaged Extensibility Framework (MEF)[^].\n\r\nStarting with Visual Studio 2010 and .NET v.4, you don't need to download MEF from CodePlex, it is already bundled.\n\n\u2014SA\n", "id": "2_1075043_3", "owner_tier": 0.9, "score": 5.0}], "link": "https://www.codeproject.com/Questions/1075039/How-to-transfer-data-between-two-different-dlls-in", "question": {"content": "\r\n\t\t\t    Hello !\r\nI have 3 diffrent dll's that runinig in the same process in the same app domain.\r\nThe dll's are use as plugins for enterprise software that execute the dlls.\r\nThe dlls are running on the same machine.\r\nI can pass data from the enterprise software to the dlls but I can't pass data from one dll to the another.\r\nI can change the dlls but I cant merge between them.\r\nI can't make a change in the enterprise software.\r\nHow I can pass data from one dll to the another in running mode (I need to pass data in high freq).\r\nThanks\r\n\t\t    ", "id": "1075039", "title": "How to transfer data between two different dlls in the same app domain", "traffic_rate": 0}, "saved_time": 1721102434, "source": "codeproject", "tags": ["C#"]}, {"answers": [{"content": "\r\n    I'm pretty late to this, but I have a real solution and can explain why!\n\r\nIt turns out that LocalReport here is using .NET Remoting to dynamically create a sub appdomain and run the report in order to avoid a leak internally somewhere. We then notice that, eventually, the report will release all the memory after 10 to 20 minutes. For people with a lot of PDFs being generated, this isn't going to work. However, the key here is that they are using .NET Remoting. One of the key parts to Remoting is something called \"Leasing\". Leasing means that it will keep that Marshal Object around for a while since Remoting is usually expensive to setup and its probably going to be used more than once. LocalReport RDLC is abusing this.\n\r\nBy default, the leasing time is... 10 minutes! Also, if something makes various calls into it, it adds another 2 minutes to the wait time! Thus, it can randomly be between 10 and 20 minutes depending how the calls line up. Luckily, you can change how long this timeout happens. Unluckily, you can only set this once per app domain... Thus, if you need remoting other than PDF generation, you will probably need to make another service running it so you can change the defaults. To do this, all you need to do is run these 4 lines of code at startup:\n\n\r\nLifetimeServices.LeaseTime = TimeSpan.FromSeconds(5);\r\nLifetimeServices.LeaseManagerPollTime = TimeSpan.FromSeconds(5);\r\nLifetimeServices.RenewOnCallTime = TimeSpan.FromSeconds(1);\r\nLifetimeServices.SponsorshipTimeout = TimeSpan.FromSeconds(5);\r\n\r\nYou'll see the memory use start to rise and then within a few seconds you should see the memory start coming back down. Took me days with a memory profiler to really track this down and realize what was happening.\n\r\nYou can't wrap ReportViewer in a using statement (Dispose crashes), but you should be able to if you use LocalReport directly. After that disposes, you can call GC.Collect() if you want to be doubly sure you are doing everything you can to free up that memory.\n\r\nHope this helps!\r\n", "id": "2_3132481_1", "owner_tier": 0.1, "score": 5.0}, {"content": "\r\n    Hi, I am able to come out with a workaround after many tests. I added below codes into my application and also app.config file:\n\n\r\n            rpvBaseReport.LocalReport.ExecuteReportInCurrentAppDomain(AppDomain.CurrentDomain.Evidence);           \r\nrpvBaseReport.LocalReport.AddTrustedCodeModuleInCurrentAppDomain(\"assembly name here\");\n\r\nAs for the app.config:\n\n\r\n<runtime>\r\n<NetFx40_LegacySecurityPolicy enabled=\"true\" />\r\n</runtime>\n\r\nAs whenever an event is fired(e.g. click on submit button to fetch data from db and render it into RDLC), a new instance will get created in a new app domain. Thus memory will keep on shoot up and although the resource will get released using proper codes(e.g. Dispose()), it will just get rid of the latest app domain while the previous app domains created will still be there in application cache. \r\nForcibly ask the RDLC to use only one app domain will prevent a new app domain from being created and thus reduce the memory usage and it will get released every time the form is closed.\r\nPlease feel free to correct me or add on any points that I have missed out. Thank you.\r\n", "id": "2_1213559_1", "owner_tier": 0.1, "score": 0}], "link": "https://www.codeproject.com/Questions/1213225/Memory-usage-shoot-up-when-using-RDLC", "question": {"content": "\r\n\t\t\t    Hi, I have a reporting RDLC designed for WinForms. I noticed whenever the RDLC is getting loaded with data, the memory will shoot up by approx. 20MB per request from database. Below are my scenario:\r\n1. Open up a winform with RDLC in it.\r\n2. Click submit button to trigger db call to get data.\r\n3. RDLC is loading ti display data.(this is where the memory started to shoot up by 20MB).\r\n4. Click again the submit button with same parameter, RDLC will reload again(memory shoot up by another ~20MB)\n\r\nI have cleared off any datasource prior RDLC load. Below are my codes:\n\n\r\nprotected Microsoft.Reporting.WinForms.ReportViewer rpvBaseReport;\n\n\r\nrpvBaseReport.ProcessingMode = ProcessingMode.Local;\r\nrpvBaseReport.LocalReport.SetBasePermissionsForSandboxAppDomain(new PermissionSet(PermissionState.Unrestricted));\r\nrpvBaseReport.LocalReport.DataSources.Clear();\r\n\r\nrpvBaseReport.LocalReport.DataSources.Add(reportDataSource);\r\n//further logic here\r\nrpvBaseReport.RefreshReport();\n\r\nAny idea would be welcomed. Thank you.\n\nWhat I have tried:\n\r\n1. Used Performance Profiler to track Memory Usage.\r\n2. Search internet for solution, have tried ReleaseSandBoxAppDomain(), Dispose() but to no avail.\r\n\t\t    ", "id": "1213225", "title": "Memory usage shoot up when using RDLC", "traffic_rate": 0}, "saved_time": 1721102434, "source": "codeproject", "tags": ["C#", "RDLC"]}, {"answers": [{"content": "\r\n    No, you cannot do it, because all modules currently loaded for execution are protected by the OS from deletion or any modifications, by apparent reasons.\n\r\nHowever, you can do something similar. You can add an assembly to the currently running process if you load it using reflection. Removing/replacing such assembly is also possible, but this is much harder. There is no such functionality as \"unloading\" of any already loaded assembly. This is done for the purpose of reliability. It's hard to remove the assembly safely, because some other assemblies my still reference some objects in the assembly which is not needed anymore, and this is so hard detect that such functionality as unloading the assembly is not available in CLR.\n\r\nAt the same time, the assembly can be unloaded indirectly, if it is loaded in a separate Application Domain. You can unload the whole application domain, with all its assemblies. But it will make programming considerably harder, because Application Domains are isolated from each other as well as the processes; all objects live in separate isolated address spaces. Communication across application domain means using IPC. The class System.AppDomain provides simplified IPC facility which simplifies the communications, but this is still not quite trivial.\n\r\nI explained most of the detail relevant to such approach to programming in my past answers. I referenced them in this one: Access a custom object that resides in plug in dll[^].\n\n\u2014SA\n", "id": "2_1060457_2", "owner_tier": 0.9, "score": 5.0}, {"content": "\n \n\r\n Yes,sometimes necessary to replace a DLL with a newer version. Before replacing a DLL, perform a version check to ensure that you are replacing an older version with a newer version. It is possible to replace a DLL that is in use. The method you use to replace DLLs that are in use depends on the operating system you are using. On Windows XP and later, applications should use Isolated Applications and Side-by-side Assemblies.\r\n\r\nIt is not necessary to restart the computer if you perform the following steps:\r\n\r\n1.Use the MoveFileEx function to rename the DLL being replaced. Do not specify MOVEFILE_COPY_ALLOWED, and make sure the renamed file is on the same volume that contains the original file. You could also simply rename the file in the same directory by giving it a different extension.\r\n\r\n2.Copy the new DLL to the directory that contains the renamed DLL. All applications will now use the new DLL.\r\n\r\n3.Use MoveFileEx with MOVEFILE_DELAY_UNTIL_REBOOT to delete the renamed DLL.\r\n\r\nNOTE : Before you make this replacement, applications will use the original DLL until it is unloaded. After you make the replacement, applications will use the new DLL. When you write a DLL, you must be careful to ensure that it is prepared for this situation, especially if the DLL maintains global state information or communicates with other services. If the DLL is not prepared for a change in global state information or communication protocols, updating the DLL will require you to restart the computer to ensure that all applications are using the same version of the DLL.\n\n[Reference^]\r\n", "id": "2_1060452_2", "owner_tier": 0.1, "score": 1.0}], "link": "https://www.codeproject.com/Questions/1060437/Is-it-possible-to-replace-net-dll-file-while-clien", "question": {"content": "\r\n\t\t\t    I copied one .net dll file to my server and every client want to register that dll with the same path using regasm /codebase example.dll. now everything working fine but sometimes i want to do some modification in this dll so i am trying to replace that dll but i cannot do it. always it says \"The action can't be completed because the folder or a file in it is open in another program\" message. i think some clients are using this application while i am updating it so please help me to solve this problem.\r\nNote: I don't want to close application that which is using by my clients. means without closing application i want to do this.\r\n\t\t    ", "id": "1060437", "title": "Is it possible to replace .net dll file while client using it?", "traffic_rate": 0}, "saved_time": 1721102434, "source": "codeproject", "tags": ["C#"]}, {"answers": [{"content": "\r\n    That's because your code is hogging the UI (startup) thread. While the UI thread is busy running your code it cannot process the application message pump and cannot repaint anything, including your label.\n\r\nYou have to move your work to a background thread, a Task or BackgroundWorker. This will free up the UI thread to maintain the UI. Your background code has to marshal called back to the UI thread to update things like your label.\n\r\nSomething like this[^].\r\n", "id": "2_1151036_1", "owner_tier": 0.7, "score": 2.5}, {"content": "\r\n    use Application.DoEvents Method (System.Windows.Forms)[^] \nC#\n\r\n TextBox.Text = s;\r\nApplication.DoEvents();\n", "id": "2_1152198_1", "owner_tier": 0.3, "score": 2.25}, {"content": "\r\n    For this type of thing, perhaps another thread is overkill. Look at adding a timer to the form, that fires at an interval of 1 second. That way, you are still on the UI thread when it is activated, so yu don't need to marshal the setting of the label text, and you don't need to do any Sleep calls to delay proceeding, as the call is only fired at the selected interval.\r\n", "id": "2_1151523_1", "owner_tier": 0.3, "score": 3.0}, {"content": "\r\n    I found another solution on the internet and am posting it here in case anyone is interested.  I created a Label on the WinForm and named it LabelBox.  The following code worked to output the number as it changed between sleeps.\n\nC#\n\r\namespace First_WinFormsTest\r\n{\r\n\r\n    public partial class Form1 : Form\r\n\r\n    {\r\n        public Form1()\r\n        {\r\n            InitializeComponent();\r\n            Thread t = new Thread(new ThreadStart(ChangeLabel));\r\n            t.Start();\r\n        }\r\n        private void ChangeLabel()\r\n        {\r\n            for (int i=0; i<20; i++)\r\n            {\r\n                SetLabelText(i);\r\n                Thread.Sleep(1000);\r\n\r\n            }\r\n        }\r\n        private delegate void SetLabelTextDelegate(int number);\r\n        private void SetLabelText( int number)\r\n        {\r\n            if (this.InvokeRequired)\r\n            {\r\n                this.BeginInvoke(new SetLabelTextDelegate(SetLabelText), new object[] { number});\r\n                return;\r\n            }\r\n            LabelBox.Text = number.ToString();\r\n        }\r\n    }\r\n}\n", "id": "2_1151486_1", "owner_tier": 0.1, "score": 1.0}], "link": "https://www.codeproject.com/Questions/1151034/Update-a-label-while-running", "question": {"content": "\r\n\t\t\t    I am building a simple real time app to test a GPS module using WinForms.  I would like to send current data from the GPS to a label or text box continuously to validate performance.  I have tried a simple program to test how to do this, shown below:\n\nC#\n\r\n    public partial class Form1 : Form\r\n    {\r\n        public Form1()\r\n        {\r\n            int i;\r\n            string s;\r\n            InitializeComponent();\r\n            for (i=0; i<20; i++)\r\n            {\r\n                s = String.Format(\"Curent value of i {0}\", i);\r\n                //                FirstLabel.Text = \"This is a test\";\r\n                FirstLabel.Text = s;\r\n                FirstLabel.Refresh();\r\n\r\n                TextBox.Text = s;\r\n                TextBox.Refresh();\r\n                \r\n                \r\n                Thread.Sleep(1000);\r\n             \r\n            }\r\n//            FirstLabel.Text = \"This is a test\";\r\n//            Thread.Sleep(1000);\r\n//            FirstLabel.Text = \"Hello World\";\r\n        }\n\r\nWhen I do this the winform screen only shows up after the loop is complete with the last string i=19 displayed.  What I want to happen is to display the winform continuously and have the contents of the boxes increment from 0 to 19 once each second.  I have looked through a lot of posts and thought the TextBox.Refresh(); would to the trick but evidently not.  Should be really simple but I can't figure out what to do.  Any help would be greatly appreciated.\n\nWhat I have tried:\n\r\nWhat I have tried described above.\r\n\t\t    ", "id": "1151034", "title": "Update a label while running", "traffic_rate": 0}, "saved_time": 1721102434, "source": "codeproject", "tags": ["C#"]}, {"answers": [{"content": "\r\n    I thought of a very easy work-around that might work for others. My underlying problem was due to how Windows caches the icons of application shortcuts. This was preventing me from changing the taskbar icon at runtime. Which is certainly possible. So instead of having the start shortcut pointing directly at the main application exe, I am pointing the shortcut to a launcher application that shells out to the main application. This way, the main application exe is never launched from a shortcut. Thus, the icon on the taskbar can be changed at runtime. This is working very well for me.\r\n", "id": "2_600060_1", "owner_tier": 0.1, "score": 3.0}, {"content": "\r\n    I am having the exact same issue but I never realized that it was happening because of a \"Shortcut\". I noticed this behavior when I would pin my application to the windows 10 task bar. If I don't pin the application, I can simply change the taskbar icon by using {this.Icon = new Icon(\"my icon path\")} and it works as expected. Once I pin the application, the icon will not change. As the original poster mentioned, this also seems to happen if you create a shortcut to the application (and not pin it to the taskbar). \n\r\nNone of the proposed solutions above seem to actually solve the issue and the \"chosen solution\" was a hack of a work around by someone who was in desperate need of a solution but was not offered any.\n\r\nUnfortunately this is also not a solution but I am attempting to revive this issue as it is still unresolved but the original poster has made a connection that could be key to solving this (a shortcut to the application prevents the taskbar icon from changing).\n\r\nThere also seems to be some unhelpful comments by a few individuals claiming that this has been solved, which it hasn't (only a workaround provided by the original poster), or that it's impossible, which it isn't since there are many examples of applications that change the taskbar icon as a form of notification (outlook when you have unread emails or express vpn when you are connected to a VPN).\n\r\nThe issues as far as I can tell revolves specifically around windows behavior when a shortcut to an application exists (or pinned to taskbar which I assume is creating a shortcut somewhere). Without the shortcut, it is very much possible for the taskbar icon to be changes as I mentioned above.\n\r\nIs anyone familiar enough with this specific windows behavior to help overcome this challenge?\r\n", "id": "2_5295661_1", "owner_tier": 0.1, "score": 0}, {"content": "\r\n    Please see my comment to the question. Why?\n\r\nNow, just some notes. The form icon is a different thing, you can really change it easily during runtime. It may even make some sense (different mode of operation, different part of functionality). The icon shown in the Taskbar is a different thing, it is called application icon. As OS uses it, it should be stored in the PE module (file) in some universal way, not specific to .NET. The application icon is actually build in application manifest. For an assembly, this is stored in a module, the one holding an application manifest for the assembly. (Visual Studio supports only creation of the assembles with one module per assembly, but compiling on lower level will allow you to have more then one per assembly, but only one of them will hold the manifest; it's called \"main assembly module\".)\n\r\nThe MSBuild uses the icon file in this build step: http://msdn.microsoft.com/en-us/library/microsoft.build.tasks.generateapplicationmanifest.aspx[^].\n\r\nThat said, unlike the form icon, this icon is readonly. And, as you should know, the executable module loaded for execution cannot be modified, no matter how high your permissions are. This is an important protection feature of most modern OS.\n\r\nAnd even if you could change this icon by some means (no, I don't think it's possible), it would defeat the purpose of them. OS controls rely on this icon to keep your application well-recognizable; it would not get any notifications if you could change it, because this is not how things are designed.\n\n\u2014SA\n", "id": "2_600042_1", "owner_tier": 0.9, "score": 1.0}, {"content": "\r\n    Application won't show you taskbar in runtime until you have any shortcuts to it.\r\nIf you get rid of all shortcuts and run from Runtime folder, it will work fine...\r\nBut this is not what we need.\n\r\nnobody anywhere didn't provide for solution what... what a shame....\r\n", "id": "2_5272646_1", "owner_tier": 0.1, "score": 0.5}], "link": "https://www.codeproject.com/Questions/600037/Changeplusiconplusdisplayedplusinplustaskbarplusat", "question": {"content": "\r\n\t\t\t    I have a Windows 7 application where I need to change the icon displayed on the main form and the icon that is displayed by Windows on the taskbar at runtime.  \n\r\nIn code I am simply changing the Form.Icon property and this works no problem if I run the app from the EXE.  The icon changes in the form and on the taskbar no problem. \n\r\nHowever, if I run the app from a desktop shortcut the icon only changes in the main form and the icon shown on the taskbar never changes.  Apparently Windows is loading the taskbar icon from a cache. The only suggestions I can find on how to refresh the cached taskbar icon are to delete the iconcache and then restart windows.  This solution obviously will not work for changing the icon at runtime.\n\r\nDoes any one know how change the taskbar icon at runtime for an app launched via a desktop shortcut???  I am guessing there are some api functions that will work, but I cannot figure it out.\r\n\t\t    ", "id": "600037", "title": "Change icon displayed in taskbar at runtime", "traffic_rate": 0}, "saved_time": 1721102434, "source": "codeproject", "tags": ["Windows", ".NET", "Win7", "icon"]}, {"answers": [{"content": "\r\n    We can't tell - we do not know what you did last time it worked to stop it working.\r\nHowever, you can try adding it back in: Right click the solution in the Solution explorer, and select \"Add...Existing Project\". Follow the dialogs to put your project back in the solution.\r\n", "id": "2_523695_1", "owner_tier": 0.9, "score": 2.5}, {"content": "\r\n    right click on solutions files in solution explorer and right click then choose reload project. it will recover old files\r\n", "id": "2_523706_2", "owner_tier": 0.1, "score": 0.4090909090909091}, {"content": "\r\n    The most common cause I've seen of this issue is failing to run Visual Studio in administrator mode. Many projects, such as websites, require admin mode to load.\r\n", "id": "2_5320574_1", "owner_tier": 0.1, "score": 0}, {"content": "\r\n    close application then delete .vs file and reopen the visual studio\r\n", "id": "2_5292765_2", "owner_tier": 0.1, "score": 0.3475}, {"content": "\r\n    In my case, run visual studio in admin mode solved it.\r\nApparently, I was earlier running VS in admin mode to allow \"attach to process\" while running local IIS\r\n", "id": "2_5164916_1", "owner_tier": 0.1, "score": 0.4366666666666667}, {"content": "\r\n    you also open your project from the documents where the window application is saved ,i think if you run the application from the document then vs2010 and then the winform something u will be able to recover all the files!!!\r\n", "id": "2_523701_2", "owner_tier": 0.1, "score": 0.5}, {"content": "\r\n    Change the name of the folder back to what it was, and then it will work.\r\n", "id": "2_5254680_1", "owner_tier": 0.1, "score": 1.0}, {"content": "\r\n    I got the same problem. Before the project become unloaded I had another error about file name. A word file it read had a very long name and the error was like \"file name can not be longer than 260 characters.\" Because of this error I couldn't open my controller classes etc. \r\nThe word file was in temp folder and I deleted it then I had to do nothing but open the project again.\r\n", "id": "2_5297172_1", "owner_tier": 0.1, "score": 0.5}], "link": "https://www.codeproject.com/Questions/523582/solutionplusfilepluswasplusunloaded", "question": {"content": "\r\n\t\t\t    i opened my windows application solutions file at today morning its showing the project file was unloaded in the solution explorer ., but it was working fine till yesterday night., now what happened why i am getting this error now i am unable to open my project please help me out\r\n\t\t    ", "id": "523582", "title": "Project file was unloaded", "traffic_rate": 0}, "saved_time": 1721102434, "source": "codeproject", "tags": ["VS2008", "Visual-Studio"]}, {"answers": [{"content": "With Python 2.x, @pberkes' answer works. For Python 3, you can proceed as follows: For Python versions >= 3.4: For Python versions 3.0\u20133.3: source", "id": 55417917, "owner_tier": 0.5, "score": -1.999999987845058e-09}, {"content": "It's hard to say without seeing the code, but I suspect that file is being imported with a command equivalent to import file. Python caches imported modules, and so it would not pick up the changes in file. This is a Python feature, and is independent of Enthought Canopy. If that's the case, you can solve the problem by adding a call to reload (https://docs.python.org/2/library/functions.html#reload) after the import in test_file, to explicitly force a reload of the module:", "id": 29296139, "owner_tier": 0.5, "score": 0.9999999979999998}], "link": "https://stackoverflow.com/questions/29292029/python-changes-to-imported-file-do-not-take-effect", "question": {"content": "I have a file called test_file, which is designed to test another file, called file. 'test_file' also contains a .txt file in the same directory.  When I update file, save, select 'Change to Editor Directory...', then run test_file, Enthought does not seem to recognize that file was updated. Initially I thought I had to select the 'Change to Editor Directory' option every time I updated file, and so I did, but test_file was still printing 'success', even after I deliberately edited file so that test_file should print false. (Yes, I'm sure that it should have printed false as I added a bunch of gibberish code into file, and even code that shouldn't run, such as throwing in return statements with blatantly incorrect indentation). So, essentially, Enthought Canopy isn't realizing that I've updated file. However, if I save and quit everything, reopen Enthought, select 'Change to Editor Directory', then run test_file, it prints the correct outcome. This is very frustrating, because I spent days debugging correct code before I realized this. It has me very concerned because I don't know if what I tested in the past is actually correct, and I don't want this to happen in the future. What is the possible cause of this? (Note: I don't know if this is an Enthought issue or a Python issue)", "id": 29292029, "title": "Python - Changes to imported file do not take effect", "traffic_rate": 4}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python", "python-2.7", "debugging", "enthought"]}, {"answers": [{"content": "For Python 3.4+: For Python < 3.4: From the Python docs Reload a previously imported module. The argument must be a module object, so it must have been successfully imported before. This is useful if you have edited the module source file using an external editor and want to try out the new version without leaving the Python interpreter. Don't forget the caveats of using this method: When a module is reloaded, its dictionary (containing the module\u2019s global variables) is retained. Redefinitions of names will override the old definitions, so this is generally not a problem, but if the new version of a module does not define a name that was defined by the old version, the old definition is not removed. If a module imports objects from another module using from ... import ..., calling reload() for the other module does not redefine the objects imported from it \u2014 one way around this is to re-execute the from statement, another is to use import and qualified names (module.*name*) instead. If a module instantiates instances of a class, reloading the module that defines the class does not affect the method definitions of the instances \u2014 they continue to use the old class definition. The same is true for derived classes.", "id": 1254379, "owner_tier": 0.9, "score": 0.999999999982906}, {"content": "", "id": 66589258, "owner_tier": 0.1, "score": -1.7094017179910415e-11}, {"content": "Another small point: If you used the import some_module as sm syntax, then you have to re-load the module with its aliased name (sm in this example):", "id": 63050762, "owner_tier": 0.5, "score": 0.02905982904273504}, {"content": "If you want to import a specific function or class from a module, you can do this:", "id": 60936171, "owner_tier": 0.5, "score": 0.08034188032478633}, {"content": "Although the provided answers do work for a specific module, they won't reload submodules, as noted in This answer: If a module imports objects from another module using from ... import ..., calling reload() for the other module does not redefine the objects imported from it \u2014 one way around this is to re-execute the from statement, another is to use import and qualified names (module.*name*) instead. However, if using the __all__ variable to define the public API, it is possible to automatically reload all publicly available modules: The caveats noted in the previous answer are still valid though. Notably, modifying a submodule that is not part of the public API as described by the __all__ variable won't be affected by a reload using this function. Similarly, removing an element of a submodule won't be reflected by a reload.", "id": 60823236, "owner_tier": 0.1, "score": 0.0034188034017094016}, {"content": "In python 3, reload is no longer a built in function. If you are using python 3.4+ you should use reload from the importlib library instead: If you are using python 3.2 or 3.3 you should: instead. See http://docs.python.org/3.0/library/imp.html#imp.reload If you are using ipython, definitely consider using the autoreload extension:", "id": 14390676, "owner_tier": 0.5, "score": 0.6102564102393162}, {"content": "Actually, in Python 3 the module imp is marked as DEPRECATED. Well, at least that's true for 3.4. Instead the reload function from the importlib module should be used: https://docs.python.org/3/library/importlib.html#importlib.reload But be aware that this library had some API-changes with the last two minor versions.", "id": 23901170, "owner_tier": 0.5, "score": 0.08034188032478633}], "link": "https://stackoverflow.com/questions/1254370/reimport-a-module-while-interactive", "question": {"content": "How do I reimport a module? I want to reimport a module after making changes to its .py file.", "id": 1254370, "title": "Reimport a module while interactive", "traffic_rate": 68}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python"]}, {"answers": [{"content": "Just in addition to @ilia post:\nLet's say the module's name is main.py\nThat's the code I put in the Jupiter's notebook cell, just before calling functions from the main module", "id": 70943990, "owner_tier": 0.3, "score": -1.428571419889327e-09}, {"content": "There's actually a nifty IPython extension for this called autoreload.  This answer shows how to use it in an IPython shell, but you can do the same in a Jupyter notebook.  Just add: before you import the module whose changes you want to have tracked, and it'll be re-imported before every cell you execute.", "id": 64166391, "owner_tier": 0.3, "score": 0.9999999985714284}, {"content": "Suppose we have a file at folder_name/filename.py and call it in some .ipynb which was modified like this In this case, second call of the following code in .ipynb returns test To update the function, you need to reload the module: This code will return test2 \nDon't forget to import importlib before you run reload", "id": 64294886, "owner_tier": 0.3, "score": 0.8571428557142856}, {"content": "This has happened to me. You need to restart the python kernel so jupyter can read the new state of the python scripts located in the working directory. Then the variable a should print the new assigned value.", "id": 64158748, "owner_tier": 0.1, "score": 0.28571428428571427}], "link": "https://stackoverflow.com/questions/64158622/jupyter-does-not-see-changes-in-the-imported-module", "question": {"content": "I have a file called \"Notebook.ipynb\". I want to import my own module into it patterns.py. Let's say in patterns.py I have a variable a=1. If I print it in Jupyter after importing it, I expect to get 1. But if I change the value of the variable to patterns.py Jupyter will continue to think that the variable a is equal to one. At the same time, of course, I restart the cell in which the variable is imported from patterns.py What do I need to do to make Jupyter understand that the value of the variable has changed?", "id": 64158622, "title": "Jupyter does not see changes in the imported module", "traffic_rate": 18}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python-3.x", "jupyter-notebook"]}, {"answers": [{"content": "No, it will probably use the original. When you import the class C from B in A you will create a reference to an object in A (happens to be a class) called C. If you don't reassign to C it will still refer to the same object, so unless you actually modify the very same object during the update of B the changes wouldn't be visibly from A via the use of C. Now for some examples of how you might have done: If you just edit the source of B (after the input in the below code) and have the following python code: Then you haven't modified anything as far as A is concerned, it even didn't bother to look at your modified source. Now let's try to reimport: Now you do reassign to C, but still Python does not bother to look at your modification. The second import first checks if it has loaded the B module, and it has and then it just grabs C from it and puts into As namespace. Now let's try a little bit harder: Then still no luck; the reload(B) only tells the interpreter to reload the module, so now B refers to the new module, but C wasn't updated in this process. Now for the nearest you get: Now c2 = C() will use the class definition from the modified B, but be aware that the c1 did use the old definition and its type is still the old version of the class C. Last, as I mentioned, actually modifying the very same object I guess I'd give an example: Here the class C is first defined and an object is created. Then I modify the class C by adding a method to it. The type of c hasn't changed. It's the very same class, but now that class have got a new method since c was created.", "id": 32987149, "owner_tier": 0.5, "score": 0.0}, {"content": "That depends on you notion of update: Remember that Python is a compiled language: A module is read and compiled into byte code. So when you change the source file, nothing happens because the code was already compiled. Simply importing a module repeatedly also does nothing, the importer simply checks sys.modules and returns the already existing module from there. A module load is only triggered when you load an unknown module (according to sys.modules). There is also no auto-check for changed source files, so source files are not automatically recompiled when they have changed. However, compiled files (.pyc, .pyo) are checked against their source files before they are used. If the corresponding source files are newer or have a different size, recompilation happens for fresh loads (not on import, on load). Note, however, that the .pyc timestamp resolution is only 32 bits, so the actual file system timestamp is truncated. You can jump through some serious hoops to make Python import a changed source file: This is actually by coincidence, but the code shows one of the real problems that occur with reimporting and recompilation. Because the two B.pys are created quickly after another, their timestamps more often than not compare equal to the .pyc timestamp. You might get lucky and hit the actual timestamp flip, but that's just luck. Since the files are also the same size on Unix (note the extra newline for the second version), the file size check also reports both source files to be equal. If you remove the unlink() operations, you --most of the time-- get no module recompile. Instead you get the version version of B loaded from the .pyc file, even though it does not match B.py any more. In any case, the code objects from the initial import are retained. In this example, first_class is from the initial version of B.py, second_class is from the updated version. The first class is already compiled into byte code and in memory, it does not change just because you change its source file. For all practical purposes, both classes are from different modules that incidentally happen to have the same source file. This is probably only useful for debugging and I strongly advise against using it for anything productive. This is especially true, if your module has more than the single source file. That said, reload() doesn't exist any more in Python 3, because it never worked as expected even in Python 2.", "id": 32973360, "owner_tier": 0.5, "score": 0.0}], "link": "https://stackoverflow.com/questions/32972902/does-python-detect-updating-of-an-imported-module", "question": {"content": "Module A imports a class C from B. A has a 'run' procedure which inter alia creates an instance of C.\nAfter the first run, module B is updated without exiting A; then a second run is done. Will the new instance of C be from the updated version of B or the original?", "id": 32972902, "title": "Does Python detect updating of an imported module?", "traffic_rate": 1}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python", "python-module"]}, {"answers": [{"content": "All the answers above about reload() or imp.reload() are deprecated. reload() is no longer a builtin function in python 3 and imp.reload() is marked deprecated (see help(imp)). It's better to use importlib.reload() instead.", "id": 22894171, "owner_tier": 0.5, "score": 0.5885286782793018}, {"content": "Update for Python3: (quoted from the already-answered answer, since the last edit/comment here suggested a deprecated method) In Python 3, reload was moved to the imp module. In 3.4, imp was deprecated in favor of importlib, and reload was added to the latter. When targeting 3 or later, either reference the appropriate module when calling reload or import it. Takeaway: Use the reload builtin function: https://docs.python.org/2/library/functions.html#reload When reload(module) is executed: Example:", "id": 684186, "owner_tier": 0.7, "score": 0.9999999999750623}, {"content": "Short answer: try using reimport: a full featured reload for Python. Longer answer: It looks like this question was asked/answered prior to the release of reimport, which bills itself as a \"full featured reload for Python\": This module intends to be a full featured replacement for Python's reload function. It is targeted towards making a reload that works for Python plugins and extensions used by longer running applications. Reimport currently supports Python 2.4 through 2.6. By its very nature, this is not a completely solvable problem. The goal of this module is to make the most common sorts of updates work well. It also allows individual modules and package to assist in the process. A more detailed description of what happens is on the overview page. Note: Although the reimport explicitly supports Python 2.4 through 2.6, I've been trying it on 2.7 and it seems to work just fine.", "id": 8637233, "owner_tier": 0.5, "score": 0.019950124663341645}, {"content": "No matter how many times you import a module, you'll get the same copy of the module from sys.modules - which was loaded at first import mymodule I am answering this late, as each of the above/previous answer has a bit of the answer, so I am attempting to sum it all up in a single answer. Using built-in function: For Python 2.x - Use the built-in reload(mymodule) function. For Python 3.x - Use the imp.reload(mymodule). For Python 3.4 - In Python 3.4 imp has been deprecated in favor of importlib i.e. importlib.reload(mymodule) Few caveats:  External packages: reimport - Reimport currently supports Python 2.4 through 2.7. xreload- This works by executing the module in a scratch namespace, and then\npatching classes, methods and functions in place.  This avoids the\nneed to patch instances.  New objects are copied into the target\nnamespace. livecoding - Code reloading allows a running application to change its behaviour in response to changes in the Python scripts it uses. When the library detects a Python script has been modified, it reloads that script and replaces the objects it had previously made available for use with newly reloaded versions. As a tool, it allows a programmer to avoid interruption to their workflow and a corresponding loss of focus. It enables them to remain in a state of flow. Where previously they might have needed to restart the application in order to put changed code into effect, those changes can be applied immediately.", "id": 36375742, "owner_tier": 0.5, "score": 0.047381546109725683}, {"content": "dragonfly's answer worked for me (python 3.4.3). Here is a lower level solution :", "id": 34201014, "owner_tier": 0.3, "score": -2.4937655708791247e-11}, {"content": "", "id": 30608568, "owner_tier": 0.1, "score": 0.009975062319201995}, {"content": "So, far I have been exiting and reentering the Interpreter because re importing the file again is not working for me. Yes, just saying import again gives you the existing copy of the module from sys.modules. You can say reload(module) to update sys.modules and get a new copy of that single module, but if any other modules have a reference to the original module or any object from the original module, they will keep their old references and Very Confusing Things will happen. So if you've got a module a, which depends on module b, and b changes, you have to \u2018reload b\u2019 followed by \u2018reload a\u2019. If you've got two modules which depend on each other, which is extremely common when those modules are part of the same package, you can't reload them both: if you reload p.a it'll get a reference to the old p.b, and vice versa. The only way to do it is to unload them both at once by deleting their items from sys.modules, before importing them again. This is icky and has some practical pitfalls to do with modules entries being None as a failed-relative-import marker. And if you've got a module which passes references to its objects to system modules\u2009\u2014\u2009for example it registers a codec, or adds a warnings handler\u2009\u2014\u2009you're stuck; you can't reload the system module without confusing the rest of the Python environment. In summary: for all but the simplest case of one self-contained module being loaded by one standalone script, reload() is very tricky to get right; if, as you imply, you are using a \u2018package\u2019, you will probably be better off continuing to cycle the interpreter.", "id": 684229, "owner_tier": 0.9, "score": 0.0922693266583541}, {"content": "In Python 3, the behaviour changes.   ... do something with my_stuff, then later: and you get a brand new, reloaded my_stuff.", "id": 13121908, "owner_tier": 0.3, "score": 0.06483790521197007}, {"content": "See here for a good explanation of how your dependent modules won't be reloaded and the effects that can have: http://pyunit.sourceforge.net/notes/reloading.html The way pyunit solved it was to track dependent modules by overriding __import__ then to delete each of them from sys.modules and re-import.  They probably could've just reload'ed them, though.", "id": 684311, "owner_tier": 0.5, "score": 0.002493765561097257}, {"content": "Not sure if this does all expected things, but you can do just like that:", "id": 685040, "owner_tier": 0.5, "score": 0.009975062319201995}, {"content": "Basically reload as in allyourcode's asnwer. But it won't change underlying the code of already instantiated object or referenced functions. Extending from his answer:", "id": 685004, "owner_tier": 0.9, "score": 0.01745635907730673}], "link": "https://stackoverflow.com/questions/684171/how-to-re-import-an-updated-package-while-in-python-interpreter", "question": {"content": "I often test my module in the Python Interpreter, and when I see an error, I quickly update the .py file. But how do I make it reflect on the Interpreter ? So, far I have been exiting and reentering the Interpreter because re importing the file again is not working for me.", "id": 684171, "title": "How to re import an updated package while in Python Interpreter?", "traffic_rate": 98}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python"]}, {"answers": [{"content": "It's possible that Python is using a cached bytecode version of your file, rather than reading the new version. If you have a __pycache__ directory, or any files with the extension .pyc, try deleting them and importing your file again.", "id": 51214336, "owner_tier": 0.5, "score": 0.9999999975}], "link": "https://stackoverflow.com/questions/51214041/updates-from-updated-py-file-not-working-when-imported", "question": {"content": "I have a python file with various functions, called mypyfile. For a while now I have had custom functions there that I use, and I import them in using import mypyfile. I recently moved to 3.6 from 3.4 because of dependencies from a specific package I was using. I am now trying to import mypyfile, but the update that I made to the file and saved it, is not working.  The mypyfile.py exists in the main working directory. The import function does work, and it does import my file in. When I use the newly changed function from that file is when it fails, indicating that the changes I made were not updated.  I'm likely not doing the package thing right in python, I just have a .py file with functions in it, no init.py file, or structured package folder. just one .py file with a bunch of functions in it.", "id": 51214041, "title": "updates from updated py file not working when imported", "traffic_rate": 3240}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python", "module"]}, {"answers": [{"content": "I suspect you have at least one other module with the same name as one of yours in your PYTHONPATH. Either look for old copies you left around or try changing your module names and see what happens. You'd see a similar effect if you forgot to reload your modules before running them after you modified them, but restarting your Python session would obviously cause all your modules to be loaded afresh at the first import of each.", "id": 7595390, "owner_tier": 0.5, "score": 0.9999999966666667}], "link": "https://stackoverflow.com/questions/7595297/modules-source-changes-dont-take-effect", "question": {"content": "I am having an issue with python which  looks really weird to me. My script starts to be quite big and is suposed to run a test suite for a program.\nMy inclusion tree is: The weird behavior I am having is that when I add a modification to my Module, Section or Test module's source file, they don't take effect at all. I am developing with emacs in my terminal and simply run my script using: I tried: The version of my python is 2.5.2 and I am working under a Debian Lenny in VirtualBox. And I haven't been able to reproduce this behavior on another smaller program to observe it better.", "id": 7595297, "title": "Module&#39;s source changes don&#39;t take effect", "traffic_rate": 1}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python", "module"]}, {"answers": [{"content": "You need to explicitly reload the module, as in: note that imp module is pending depreciation in favor of importlib and in python 3.4 one should use: importlib.reload.", "id": 25866649, "owner_tier": 0.9, "score": 0.99999999875}, {"content": "As an alternative answer inside reload you can use \nwatchdog \n .  A simple program that uses watchdog to monitor directories specified as command-line arguments and logs events generated: From the website Supported Platforms Linux 2.6 (inotify) Mac OS X (FSEvents, kqueue) FreeBSD/BSD (kqueue) Windows (ReadDirectoryChangesW with I/O completion ports; ReadDirectoryChangesW worker threads) OS-independent (polling the disk for directory snapshots and comparing them periodically; slow and not recommended)", "id": 25866782, "owner_tier": 0.9, "score": -1.2499999924031613e-09}, {"content": "You should use reload every time you make a change and then import again:", "id": 25866665, "owner_tier": 0.5, "score": -1.2499999924031613e-09}], "link": "https://stackoverflow.com/questions/25866555/python-does-not-show-code-changes-from-imported-file", "question": {"content": "I am using a linux python shell and each time I make changes to the imported file I need restart the shell (I tried reimporting the file but the changes were not reflected)  I have a definition in a file called handlers.py I import the file in the python shell I then change print statement to \"Hello I am there\", reimport handlers, it does not show the change? Using Python 2.7 with Mint 17.1", "id": 25866555, "title": "Python does not show code changes from imported file", "traffic_rate": 6743}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python", "import"]}, {"answers": [{"content": "Use can use Python's built-in function reload. From the docs: When reload(module) is executed: Here is an example: First, we create a file that defines a variable msg and a method to print it. Now we modify the file, removing variable msg and adding a and b variables (without exiting the current Python REPL). This is useful if you have edited the module source file using an external editor and want to try out the new version without leaving the Python interpreter. One final note: reload(myfile) only reloads the specified modules. The module's (myfile) imports must be individually reloaded. Also, any objects that refer to anything in the module (like an instance whose class is defined in the module) will continue to use the previously loaded value.", "id": 21970306, "owner_tier": 0.5, "score": -1.0000000000000002e-08}, {"content": "From the imp.reload documentation: When a module is reloaded, its dictionary (containing the module\u2019s global variables) is retained. Redefinitions of names will override the old definitions, so this is generally not a problem. If the new version of a module does not define a name that was defined by the old version, the old definition remains. The module is not wiped before the reload. The module's new code is executed with all old variable bindings still present. Any names the new code defines replace the old bindings, but anything the new version doesn't define retains its old value. This also applies in Python 2.", "id": 21965170, "owner_tier": 0.9, "score": 0.9999999900000001}], "link": "https://stackoverflow.com/questions/21965009/does-reloading-a-module-changes-the-names-in-the-module-previously-imported-relo", "question": {"content": "I have a module named myfile.py Then I import it: import myfile Then I make some modifications, such as: Then I call the reload function: Now when I run: dir(myfile)\nits showing the names from the current module reload as well as the previous (all other previous import/reloads) Does this mean \"all\" the names (even names omitted after updating) are available separately for outside world when the module is imported/reloaded?", "id": 21965009, "title": "Does reloading a module changes the names in the module previously imported/reloaded?", "traffic_rate": 505}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python"]}, {"answers": [{"content": "The issue was that PYTHONPATH was set to a wrong folder. We had two folders with the project: old and new, similarly named, with identical project structure (but different file contents) and PYTHONPATH was set to the old project.", "id": 65096617, "owner_tier": 0.5, "score": 0.0}, {"content": "assuming that you've successfully cloned the project into your machine, If it is a problem with importing functions or methods from a different .py file, please check the points below. check your working directory, whether you're in the same directory where the .py file/module with functions/methods exist. once you import any function/method from a module, even you comment out the function/method and save the .py file, it won't affect the already imported functions as long as you re-import it. as long as it is a problem of importing from your own .py files, the virtual environment has nothing to do with that. EDITED: check this link, it may give you some information about how caching works while importing python modules.", "id": 65095624, "owner_tier": 0.3, "score": 0.0}], "link": "https://stackoverflow.com/questions/65095357/python-does-not-see-new-changes-in-files", "question": {"content": "When I am adding new functions to a file I can't import them neither if I just run the script in terminal or if I launch ipython and try importing a function there. I have no .pyc files. It looks as if there is some kind of caching going on. I never actually faced such an issue even though have been working with various projects for a while. Why could it happen? What I see is the following: I launch ipython and the functions that were written long time ago by other programmers can be imported fine. If I comment them out and save the file, they still can be imported without any issues. If I write new functions they can't be imported. The directory is git directory, I cloned the repo. Then the new branch was created and I switched to it. Python version is 3.7.5, and I am working with virtual environment that I created some time ago which I activated with source activate py37. I don't know whether its important but I have an empty __init__.py in the folder where script is located. The code (I don't think its relevant, but still): public_class_props is an old function and can be imported, but hello - can't.", "id": 65095357, "title": "Python does not see new changes in files", "traffic_rate": 3007}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "stackoverflow", "tags": ["python", "git", "caching", "import", "git-clone"]}, {"answers": [{"content": "There's a built-in for that: [`reload()`](http://docs.python.org/2/library/functions.html?highlight=reload#reload)\n\nI can't say with certainty that it will work in an IPython interpreter session, but if it doesn't it's probably a bug they're working on or would work on.\n\nHmm, thanks for the pointer to reload()... I'm not seeing how to use it if I have imported a module with 'from X import *' though.  Is this possible?  Or do I need to import the module by name to be able to use reload()?\n\nI'm very glad I read that link, btw, because I would not have guessed that existing instances would retain their methods.  I would have assumed that either all existing instances would be invalidated, or their internal vtables (or whatever Python uses in lieu of them) would be rewritten to point to the new code.  That could have caused some confusion!\n\nI have a related question: is there an easy way to un-shadow something? A common mistake I make with IPython is:\n\n    ylim = (0, 50)\n\nWhen it should be:\n\n    ylim(0,50)\n\nSimply because I forgot the exact syntax, I've replaced `ylim()` with a tuple and now can't set the y-axis on a plot. What's the easiest way to fix that? \n\nThe relevant documentation is this:\n\n* Other references to the old objects (such as names external to the module) are not rebound to refer to the new objects and must be updated in each namespace where they occur if that is desired.\n\nSo you need to call `reload(X)` and then set everything you imported from * to the \"new\" X's values. I don't have the means to test it right now, but I suspect re-running the `from X import *` line would rebind all of the names to the new module.\n\nHave you tried using \"del ylim\"?  I think that should delete the current contexts reference which should cause ylim to get resolved by the outer context again.\n\nJust re-import the module that provides that name. It will not re-run any initialization code, but it will rebind the names.\n\nNope, now I get:\n\n    NameError: name 'ylim' is not defined\n\nI can do this if I know the module that it came from, but I'm sure there's a better solution:\n\n    from pylab import *\n\nAll del does is remove the name. It doesn't delete objects\n\nYeah, that's what I do, but it took me some time to figure out the module that provided that particular function. I guess that's a bigger problem with IPython since the namespace has so much already imported.\n\nActually otakucode's suggestion works for things in the default namespace. Just not thing that have been imported later, it seems. \n\n\nWhich is precisely what he wants, no?", "id": "c883cpo", "owner_tier": 0.3, "score": 0.9999999992307692}, {"content": "Use reload if you imported the module.\n\nUse %run foo if you imported things from foo.", "id": "c883tku", "owner_tier": 0.5, "score": 0.07692307615384616}, {"content": "Reloading modules is a hard problem. Using the reload function won't update instances. You need to restart the REPL and reinstantiate your objects. \n\nIf you have some tedious setup code, drop it in a file, and use the -i flag to run it and hop back into an interactive session:\n\n    python -i mysetup.py\n\nThen you'll have an interpreter session with the setup code already performed. \n\nI'm fairly certain you can do this with ipython too. ", "id": "c885b6m", "owner_tier": 0.5, "score": -7.692307645557915e-10}], "link": "https://www.reddit.com/r/learnpython/comments/17r64a/how_do_i_reimport_something_into_the_repl_after/", "question": {"content": "I'm using IPython (and loving it) and I often edit a source file and want to just re-import that file, replacing the contents of the previous import.  If I do 'from module import *', it doesn't pick up any of the changes.  There is a bit of IPython magic that will let me completely reset the REPL, removing everything that has been imported or defined, but that's not what I want.  I want to just remove the module then re-import it from the changed source.  Is there a magic for this in IPython or some support for this in Python itself?", "id": "17r64a", "title": "How do I 're-import' something into the REPL after changing the source file (using IPython)?", "traffic_rate": 153.13037037037037}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "If your python shell is `ipython` or `jupyter console` you can load the magic\n ```\n%load_ext autoreload \n%autoreload 2\n```\n\nMind to share your configuration?\n\nThank you. Several people have suggested something similar. As nanounanue says, can you share your configuration?", "id": "jofl63p", "owner_tier": 0.1, "score": 0.9999999989999999}, {"content": "You can, conceptually (as others say), reload modules in a python shell.\n\nBut that is not foolproof. There are ways for dangling references to old module code to linger; particularly if you have objects referencing code in stale, old modules in your `globals()`. Be very careful with this!\n\nHonestly, if you're building \"real\" software that spans multiple files, and not just single-file scripts and so on, you're probably better off not using the repl for this and instead interact with your application's state through a test + breakpoints or even by dropping into a shell directly in the parts of the code you want to test.\n\nSource: 15+ years of commercial python experience.\n\nTrue. The python repl is nothing similar than the lisp repl\n\n> But that is not foolproof. There are ways for dangling references to old module code to linger; particularly if you have objects referencing code in stale, old modules in your globals(). Be very careful with this!\n\nI definitely see your point. I haven't coded in Python until recently, but I'm familiar with the problem of dangling references that you mention. Many interpreters and programming system suffer from it. There's a little bit of it in Emacs itself, as you're probably aware.\n\n> Honestly, if you're building \"real\" software that spans multiple files, and not just single-file scripts and so on, you're probably better off not using the repl for this and instead interact with your application's state through a test + breakpoints or even by dropping into a shell directly in the parts of the code you want to test.\n\nI can see the advantages of doing that. Python-mode seems to be very focused on the REPL. Is there another mode that changes this behaviour?\n\nI use `M-x compile` for script running. (Note I tend to wrap most of those in a Makefile to make things repeatable in/outside of Emacs. But that is of course optional.)\n\nIf it's an executable script, you can call it via that, or using `python -m` if it's a module that you've installed. Tracebacks are correctly highlighted and link back to your code regardless of the method, provided it's output to stdout.\n\nAnother option that I also use is to run things through a test runner. `pytest` is the defacto standard for most commercial projects that aren't stuck with the builtin `unittest` package.\n\nPytest is good because regardless of your views of unit testing; tdd; etc. it's just a really good way of writing repeatable test harnesses. There's a nice `python-pytest.el` package that adds magit integration. I use a heavily modified version of that; it's great.\n\nOh, and the reason why I recommend ditching the REPL is that a lot of things don't really map well into a \"reload or send stuff to a REPL\". Things like request-response actions if you're doing web dev. (It's *possible*, but it's not ergonomic at all.)\n\nOh and check out my combobulate package: it's needs tree-sitter and Emacs 29, but it's got good python integration.\n\nExcellent, thank you!", "id": "joftvoy", "owner_tier": 0.3, "score": 0.9999999989999999}, {"content": "Developing \"SLIME\" style sounds nice but I found it to be impractical.  I recommend the standard compile-iterate workflow combined with writing unit tests; as a bonus you can keep the unit tests for future regression testing.  You can set up Emacs to run compile automatically and show the results in a buffer, so you can see the results live as you edit/save.\n\nMind to share how to do that?\n\nI'm not sure what you mean. I've haven't had any serious experience with SLIME.\n\nDo you mean that it's best to use compile-mode with python rather than an inferior python process (with run-python)? I can see the advantages of that, but it seems to me that python-mode is setup entirely to use an inferior python process.\n\nThis is something that I had thought of. I imagined that someone had created a version of the python shell that reboots the python interpreter every time a library is re-imported. If that exists, then it solves the problem (though probably at the expense of time). Using compile mode is another option.", "id": "jogddlz", "owner_tier": 0.5, "score": 0.399999999}, {"content": "Unrelated to emacs, but I've done this with limited success using an ipython shell with the [autoreload](https://ipython.org/ipython-doc/3/config/extensions/autoreload.html) magic. It lists the caveats (of which there are a few) at the bottom of the page.", "id": "jofl6sm", "owner_tier": 0.5, "score": -9.99999993922529e-10}, {"content": "Please share your config.", "id": "jofp5kf", "owner_tier": 0.1, "score": -9.99999993922529e-10}, {"content": "If I understand correctly you are using a Python shell (or \u201cinferior Python process\u201d in Emacs terminology) to run your code, is that correct?\n\nThis is not necessarily an Emacs problem, rather this is just how Python works. Others have mentioned the autoload magic which should work if you use either `ipython` or `jupyter console`. However if you don\u2019t, try the following:\n\n```\nimport importlib\nimportlib.reload(packagename)\n```\n\nThank you!\n\n>foolproof\n\nThis doesn't work. I have tried", "id": "jofr7h8", "owner_tier": 0.1, "score": 0.199999999}, {"content": "It\u2019s one of the real frustrations of interactive python, and the contrast is especially notable when you are inside a live, readily self-updating system like Emacs.  When you have say 10s of GB of data loaded, the admonition to \u201cjust restart python, that\u2019s how it\u2019s done\u201d is galling.  That said, you can certainly unload a library, e.g. by deleting it from sys.modules, then send it again and re-import.  \n\nThe problem is that existing objects reference a compiled internal version, and so point to the old code.  You can of course recreate your affected objects and it will work fine. But it\u2019s hard to do this rigorously (easy to miss some objects). \n\nIn iPython, %autoreload magic works pretty well to do all this \u201cmagically\u201d. It checks for changes on disk, reimports if seen, then scours existing objects and updates them to point to the new code. But heed this:\n\n> Reloading Python modules in a reliable way is in general difficult, and unexpected things may occur. ``%autoreload`` tries to work around\ncommon pitfalls by replacing function code objects and parts of classes previously in the module with new versions.", "id": "jogjkpm", "owner_tier": 0.3, "score": -9.99999993922529e-10}], "link": "https://www.reddit.com/r/emacs/comments/14bfcq9/emacs_and_python_imports/", "question": {"content": "Recently I have been doing some programming in python. I have got it working nicely in Emacs - I may share my configuration another time.\n\nI'm have a problem with imports though. In Python you bring in a library by \"importing\" it. I often have to edit libraries that are part of the project I'm working on. The problem is that in Python 3 you can't unload a library, nor can you replace it with a newer version.\n\nThis is a problem because Emacs python-mode is based around the idea of sending python code to a python shell. This works fine unless imports get involved. Once imports get involved you run into the problem that python will never re-import a library after it has imported it once. So, if you're editing a library the only way to update to the new version (which could be what you just wrote) is to stop the python process and start another one.\n\nIs there a fix for this? Has anyone written a package to at least make constantly restarting python more convenient?", "id": "14bfcq9", "title": "Emacs and Python Imports", "traffic_rate": 12.050219817382482}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "For importing python modules, there's importlib.reload(). I use it a lot since I execute code on notebooks but have my code on a python file. When you reload a module, it gets all changes without having to restart the kernel.\n\nI'm not sure it works for your particular case, though.\n\nGot it! Thanks for the answer.", "id": "kuwk6sd", "owner_tier": 0.5, "score": 0.599999998}, {"content": "How does the file which is modified get used? What type of file is it? How often does it get modified? Can you control when this is? Is the previous content of the file still usable for a period after the content is changed or must the new content be used immediately? Is restarting the container itself a problem or do you just need constant availability? Would reading the file on every use degrade your performance to an unacceptable level?", "id": "kux18gk", "owner_tier": 0.3, "score": 0.399999998}, {"content": "i feel there is some gap in the translation.\n\n>Most programs load the contents of the file when the application starts up, and that's it!\n\ni'm not sure what this means.\n\n>Hence my question: how can I load a file and reload it automatically when it changes (without restarting the application)? What's best practices in my case?\n\nhow do you load this file? normally?\n\ni'm confused .. seems to be way to simple of a thing to be confusing.\n\nyou can add a checksum mechanic and cycle it on timer. on a different process?\n\nthen if file checksum is different then you reload.", "id": "kuxhak6", "owner_tier": 0.3, "score": 0.399999998}, {"content": "I don't think your goal is a good one: it's much simpler to reason about a program that doesn't rely on an external value that might change transparently partway through execution. It's also much easier to hook into audit systems of changes usually if you have to kick off a rolling restart, which is helpful when systems start paging.\n\nIf you _really_ want to avoid restarting for some reason, I'd have the app pulling secrets directly from Vault every time, perhaps with a time-based cache tuned to your requirements. But I really prefer baked secrets at container startup and kicked rollouts (just have to have a system or process that ensures these do happen).", "id": "kuxlfk4", "owner_tier": 0.7, "score": 0.399999998}, {"content": "You could check the modified time of the file in a loop and only reload if it's changed.\n\nThat's pretty much what I imagined, but I guess there must be a lib that takes care of that and will be much better done than the one I could make.\n\nSomething like this should work\n\n&#x200B;\n\n    def has_file_changed(filename):\n    `global last_modified_time`\n    \n    `current_modified_time = os.path.getmtime(filename)`\n    \n    `if current_modified_time != last_modified_time:`\n    \n    \t`last_modified_time = current_modified_time`\n    \n    \t`return True`\n    \n    `return False`\n    \n\nthen where you want to check if it's changed.\n\n    \t`while True:`\n    \n    \t\t`if has_file_changed(selected_filename):`\n                        data = read_json(selected_filename)\n    \t\t`df = data_to_dataframe(data)`\n\nThanks for the instructions! But it's going to block my programme! I'd have to run it asynchronously, wouldn't I? I've never run it asynchronously, so I don't know if that's possible yet.\n\nno, the while loop runs within your program and only does anything when the file's changed.", "id": "kuwtjv5", "owner_tier": 0.3, "score": 0.9999999980000001}, {"content": "Fastapi does this when you are working on your code so maybe take a look at that\n\nWatchfiles package\n\nThat's true! Uvicorn do this. Thanks I will get a look.", "id": "kv415ho", "owner_tier": 0.1, "score": 0.599999998}, {"content": "Search \"watch file for changes Python\".", "id": "kuxsfcc", "owner_tier": 0.7, "score": -2e-09}], "link": "https://www.reddit.com/r/learnpython/comments/1bexikb/how_can_i_load_a_file_and_reload_it_automatically/", "question": {"content": "Hi,\n\n  \nContext: I'm working on Hashicorp Vault in Kubernetes, with FastAPI; this is a detail, you don't need to master these technologies to be able to help me.\n\n  \nVault is capable of modifying a file containing a secret on the fly, without needing to restart my container. But it can't do the same for environment variables (that would require restarting the container).    \nExcept that, if I use a secret in a file, the limitation comes from elsewhere. Most programs load the contents of the file when the application starts up, and that's it! So even if I manage to update my file, it won't be reloaded.\n\n  \nHence my question: how can I load a file and reload it automatically when it changes (without restarting the application)? What's best practices in my case?  \n\n\n  \nThanks!!!  \n", "id": "1bexikb", "title": "How can I load a file and reload it automatically when it changes (without restarting the application)?", "traffic_rate": 153.13037037037037}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "There is some talk about this in stack overflow, but generally the only time I have seen imports done in a method or function it was for one of two reasons. 1. The method is called so very rarely that importing it at the beginning gives worse performance because it is generally never used. This is more an issue for microservices. 2. To hide from a circular import issue. Neither are stellar reasons to do it. Importing in the method will have a smallish impact on the runtime of that method the first time you call it. Honestly I hate seeing it done that way but that's just me.\n\n> 1. The method is called so very rarely that importing it at the beginning gives worse performance because it is generally never used.\n\nAlso because *you don't want to make the user install this library*.\n\n> 2. To hide from a circular import issue.\n\nI hadn't thought of / remembered that one. Good point. \n\nI'd add unittests to that list.\n\nYour test can be more granular if you import inside the test itself.\n\nCircular imports are not an issue, Python's memory allocator is smart enough for that. I don't actually know or understand what kind of magic that uses to work safely, but this worked fine:  \n\n\nfoo.py\n\n    import bar\n    def foo():\n        return 'foo'\n    def foobar():\n        return bar.bar()\n\nbar.py\n\n    import foo\n    def bar():\n        return 'bar'\n    def foobar():\n        return foo.foo()\n\n$ python3\n\n    >>> import foo\n    >>> foo.foo()\n    'foo'\n    >>> foo.foobar()\n    'bar'\n    >>> foo.bar.foo.bar.foobar()\n    'foo'\n    >>> # And just out of curiosity, let's check the IDs\n    ... id(foo)\n    139627125511576\n    >>> id(foo.bar)\n    139627125511816\n    >>> id(foo.bar.foo)\n    139627125511576\n    >>> id(foo.bar.foo.bar)\n    139627125511816\n\nThey will have to to install the library regardless. If the method isn't called by the user then remove it before shipping :) add a test to verify it is removed.\n\nWhile this might seem true and granular is good for tests. Python caches the import after it sees it the first time. So after the first test it will not reimport the library in the next test. Use a global counter to verify this.\n\nI promise you circular imports are an issue. As I am fighting them at work right now because someone before me did some crazy things and used importing in functions to get around it.\n\nWhat happens is that it sees a module you have already imported in your sys.modules and.doesn't try again\n\nBut this breaks if you use the \n\nfrom x import y \n\nsyntax since you need to get to the end of x\n\nWell the place this tends to come up is when you have a rarely-used feature. \n\nFor example, suppose ou are writing a git client, and it can optionally output it's results to graphviz, or plot a graph or something. You might not want to depend on matplotlib for normally functionality (e.g. running on a server - doing useful things). But you might still want the functionality there for the desktop client.\n\nI guess there are alternatives. I suppose you could have two libraries built from the same code base with different dependencies couldn't you. I'm not sure that's much better tho!\n\nAnother example is the Excel functionality in pandas - it doesn't import xlrd or pyopenxl until you try and read/write an Excel file because 90% of users probably only work with CSVs and they don't want to force the installation of dependencies that aren't necessary\n\n`reload`", "id": "e9hh7v2", "owner_tier": 0.1, "score": 0.9999999998734178}, {"content": "Some arguments:\n\n* Importing things can be slow (scipy and numpy come to mind) and importing is done when the import statement is run. This can add slowdowns when the programming is running (rather than when it is starting). Sometimes this is desirable - sometimes not.\n* Importing things later means that missing imports are detected later than they might otherwise be. All things being equal, it is good to detect errors earlier.\n* Sometimes you might not want to rely on having modules installed but use them if they are there for a particular feature. (Suppose your tool can export to some niche format - excel comes to mind (I was reminded about this from another comment)). It can be natural to delay the import here, and cleaner than a bunch of ugly try/except code.\n* Given the above *reasons* for importing later. It can violate the \"rule of least surprise\" to import late. People might think \"why are they importing here - it might be for this reason - but there is no comment\". \n* There are a couple of \"standard\" arguments that people might come up with (personally I think these are post-hoc rubbish arguments used to win arguments). a) It might be confusing to assume that you a module is in global scope in one function and then find it isn't (an awful lot of things are confusing - that is why you use a linter and run your code) (b) It is nicer to see all the imports in one place (meh, there are quite a lot of imports when do you ever read them) (c) some tools might  use top level imports (this is a little more compelling)..\n* Doing what other people do unless there is a good reason not to results in less surprise and less confusion.\n\nI don't know. Programming is hard.... or rather ordering all the junk when coding is hard. \n\nMy personal bias would be towards top-level imports base on a neatness argument (keep things in one place; fewer categories are good), reserving late imports for when they are required with imports. I would then refactor at the *module* level to reduce the number of imports in scope (e.g. add more modules), or use dependency injection of some description, maybe.\n\nI think the really compelling argument is \"early error detection\" and \"consistent run-time post startup\". \n\nI hate complexity... I hate programmers :/\n\n\n\n*Edit: grammer*\n\n\n\n\n\n\n\n\n\n\nBut complex is better than complicated. \n\n:) Indeed... each and every one of us must [medidate on the scriptures](https://www.python.org/dev/peps/pep-0020/) and interpret them ourselves.", "id": "e9hhwmx", "owner_tier": 0.3, "score": 0.13924050620253164}, {"content": "Surprised no-one mentioned when your script is meant to be run with command-line arguments (such as through arg-parse). In such a case, you may want your script to start up quickly so it can display that --help instead of waiting for unused imports to load.\n\nIn that case I'd still put the imports near the top, just after the argparse collection which I'd shuffle off in one function call to its own module,then have if-thens for the imports", "id": "e9ij957", "owner_tier": 0.3, "score": 0.03797468341772152}, {"content": "PEP-8 says to do all imports at the top. Further to that you should do all built-in imports first then 3rd-party imports and your local application imports last. Personally I don't bother so much with separating built-in from 3rd-party because I don't remember what's actually built-in and what I installed on my system years ago, but I still keep local imports last.\n\nBasically, imports always affect the global scope, and messing with the global scope somewhere down in a method or clause **never** makes \"more sense\" as it will change the scope for every other method & clause regardless of their position in the code. I have in the past done something like `mod = import('MyModule')` which should import in the local scope, I would say I was wrong to do so but it might be acceptable in some very very rare circumstances\n\ntl;dr: Imports first, then global constant variable definitions, then class/function/etc definitions, then you have your logic usually enclosed in a `if __name__ == '__main__'` but that's entirely up to you.", "id": "e9j6k72", "owner_tier": 0.3, "score": 0.03797468341772152}, {"content": "Yes. From PEP8: \"Imports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants.\"\nThere's generally no reason to import in the middle of the file\n\nYet many open source libraries and core python does it.  There is always an exception.\n\nThat's why I said \"generally\". There of course are cases. ", "id": "e9igkgv", "owner_tier": 0.7, "score": 0.05063291126582278}, {"content": "Others have covered some of the exceptions, but the general rule is to put everything at the top unless you have a specific reason to do otherwise. ", "id": "e9iuhn5", "owner_tier": 0.7, "score": 0.025316455569620255}, {"content": "Please keep imports at the top.  https://www.python.org/dev/peps/pep-0008/#imports", "id": "e9j2u03", "owner_tier": 0.5, "score": 0.012658227721518988}, {"content": "Importing at time-of-usage makes sense to me, if the docs make it clear that optional dependencies enables a specifc feature.  Else, just raise a clear NotImplementedError.", "id": "e9i1fs2", "owner_tier": 0.1, "score": -1.2658227771171254e-10}, {"content": "It depends how dependent your program is on the import.  If you have a library that you import once in a blue moon and don't expect all users to install, then putting it into a function helps keep start up times low and the program from breaking completely.", "id": "e9jglbl", "owner_tier": 0.5, "score": -1.2658227771171254e-10}, {"content": "I hate it, but there are some cases when it makes sense.\n\nFor example in the awesome flask mega tutorial:\n\n[https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world)\n\nthe imports of your own routes, models are done after some code is executed that is necessary for localization.", "id": "e9jnqui", "owner_tier": 0.1, "score": -1.2658227771171254e-10}, {"content": "I do it all the time - I write a LOT of scripts at work to move data around and it makes it super easy to copy/paste a chunk of code .. with the import if it does something unusual .. I run all my stuff through black and flake8 ..\n\n&#x200B;\n\nNot a great example but i was playing with limits for recursion, memoizing, etc the other day - you can see where I added sys and functools.\n\n    #!/usr/bin/env python3\n    import argparse\n    \n    import sys\n    sys.setrecursionlimit(200000)\n    \n    parser = argparse.ArgumentParser(description=\"Process some integers.\")\n    parser.add_argument(\"fibof\", type=int, help=\"What Number did you want to fib?\")\n    args = parser.parse_args()\n    fibof = args.fibof\n    \n    # @memoized\n    import functools\n    @functools.lru_cache(maxsize=20001)\n    def fib(n):\n        if n <= 1:\n            return 1\n        return fib(n - 1) + fib(n - 2)\n    \n    print(f\"fib({fibof})={fib(fibof)}\")\n\n&#x200B;\n\nMy thinking is if it ever becomes an issue, I can find a tool to move them for me.", "id": "e9mtyf0", "owner_tier": 0.3, "score": -1.2658227771171254e-10}], "link": "https://www.reddit.com/r/Python/comments/9w4m96/is_it_bad_form_to_import_in_the_middle_of_the/", "question": {"content": "I usually import all the libraries I need to use at the top, but sometimes it looks nicer elsewhere and if I only need that library in one meathod or clause does it make more sense to do that or just import everything at start.", "id": "9w4m96", "title": "Is it bad form to import in the middle of the program", "traffic_rate": 207.942496260595}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "When you import a module, all code that is in the module is ran, this may be needed as a setup for some module.\n\nIf you dant want to run some code when you import the file, use this:\n\n    if __name__ == \"__main__\":\n        bar()\n\nThis will make sure that bar() function is only ran when you run hello.py directly, but not when you import it.\n\nSo then what's the difference between these two lines? Won't they both run everything in that module?\n\n    from hello import foo\n    from hello import *\n\n> When you import a module, all code that is in the module is ran, this may be needed as a setup for some module.\n\nThis is a good answer. \n\nI'd also add that when you import a package (not an individual .py module), something similar happens - the \\_\\_init\\_\\_.py file is run. Importing pandas runs this code - https://github.com/pandas-dev/pandas/blob/main/pandas/\\_\\_init\\_\\_.py\n\nMost developers try to minimize the amount of global code. Use it when needed, but otherwise keep your code inside functions with a clear control flow.\n\nBro, this is fantastic. You have no idea how this is going to help me on a couple projects I have going.\n\n    from hello import foo\n\nwill only allow you to use foo function in world.py\n\n    from hello import *\n\nwill allow you to everything from hello.py in world.py\n\nThe difference between these two lines is THAT YOU NEVER USE THE SECOND FORM!  EVER!\n\n(Except when you have a reason for it, but you don't sound like someone who is or at least was far enough in Python experience to know when)\n\nIf you are doing multiple python projects and you weren't aware of this, you might want to spend some extra time learning about python before proceeding\n\nOk so they both run the entire module but the difference is in namespace\n\nSo does `import hello`.  Never ever ever use `import *`.  Ever.\n\nThis is a sub for learning python. Don't be weird.\n\nI've already made and deployed several for some teams at my workplace that have worked to increase efficiency and give the teams more time for other things. This will help me to divide out some more complex ones that I have in the works. But thanks, I'll just keep learning python by doing.", "id": "jmv0v8m", "owner_tier": 0.5, "score": 0.9999999999090909}, {"content": "Because individual functions or classes or variables may depend on the presence of functions or classes or variables in the rest of the module. They may not, but there is no reliable way to determine this. The only reliable option is to run the entire file.\n\nFor example, consider something like this:\n\n    # module.py\n    import json\n    import os\n    DATA_DIR = \"/path/to/data\"\n    \n    def get_data_file(filename, key):\n        with open(os.path.join(DATA_DIR, filename)) as f:\n            return json.load(f).get(key)\n\nAnd then you do:\n\n    from module import get_data_file\n\nIf Python \"only ran\" the definition of the specific function, it would error out when you ran it because `json` and `os` wouldn't be imported, and `DATA_DIR` wouldn't be defined.\n\nI see, that makes sense. So I guess that's why you would do the whole if \\_\\_name\\_\\_ thing like the other commenter helpfully mentioned.\n\n&#x200B;\n\nWhen would it be a good idea to use that condition? The only thing I can think of is for debugging purposes if you're only interested in testing a single file\n\nThe typical use case for that is for modules that you want to provide a library interface as well as an interactive interface, i.e. they do something useful and different when executed standalone from the command line.\n\nI might have a module which just provides some functions when it is imported, but if I do `python module.py` on the command line it gives me a command-line interface, or similar.\n\nFor example there's the Python module `http.server`. When you import it it gives you a bunch of functions and classes related to HTTP servers, as the name suggests. But if you do `python -m http.server` (-m means to run a module as a standalone program), it starts up an actual working HTTP server serving the contents of the current directory. Very useful to quickly throw up a file share on the local network.\n\nIn short, in case you want it to be a script, but also have some functions you might use elsewhere.\n\n\n The name =main bit let's you call the script directly or with python -m module.submod (this calls the file  __main__.py in module/submodule) but also be able to import it without the script bits hijacking the process.\n\nits useful for scripts, that take some arguments and produce some output in terminal or do other stuff.\n\nThis is the equivalent of the main function in any other language. So it is the same answer to when should you add a main function to a module in Java, C/C++, etc?", "id": "jmv1bwq", "owner_tier": 0.7, "score": 0.1818181817272727}, {"content": "Basically, because anything can happen in \"the rest\" of the file.\n\n\nYou can have\n\n    def hello():\n        print(\"hello\")\n\nAs the first thing in the file, then at the bottom have\n\n    hello = lambda: print(\"goodbye\")", "id": "jmvaq6k", "owner_tier": 0.7, "score": 0.027272727181818182}, {"content": "One thing you need to realize about Python is that the `def foo():` in\n\n    def foo();\n        print('i am foo')\n\nis not a declaration like in other languages, but actually a statement like \u00e0 = 5`.  Python compiles and then executes it.  Everything in your Python module or script is a statement (`from module import function` is a statement that gets *executed* at runtime)\n\nYes, every module gets loaded and executed.  Everything in there.  So, if you don't want `bar` to be executed, don't put a function call into your module.", "id": "k3rn6l7", "owner_tier": 0.5, "score": -9.090909035659355e-11}, {"content": "Under the hood, \u2018from hello import foo\u2019 imports the entire module \u2018hello\u2019 and then afterwards removes all imported things that are not \u2018foo\u2019.\nIt\u2019s a bit counterintuitive, but Python has never been known for being the most efficient language\n\nIt doesn't \"remove\" anything. It just only creates a specific `foo` variable in the calling environment. If there was a module-level object defined that isn't imported, `foo` will still have access to it.\n\n`from foo import bar as baz` is effectively equal to\n\n```\nimport foo as _temp\nbaz = _temp.foo\ndel _temp\n```\n\n... which only creates a reference in the calling environment and then deletes the reference... the module still exists. The fact that foo can still refer to module-level variables and other functions from that module proves that the loaded module is still there.\n\n[Others agree](https://softwareengineering.stackexchange.com/questions/187403/import-module-vs-from-module-import-function).\n\nWhich means that \"foo\" is still loaded, completely.  There's just no name referencing this module in the importing module's namespace (since you deleted the reference, `_temp`).\n\n`del` doesn't do what you seem to think it does.\n\nOh, and then your code is also wrong: `baz = _temp.bar` would be correct.", "id": "jmvqbsg", "owner_tier": 0.1, "score": 0.009090909000000001}], "link": "https://www.reddit.com/r/learnpython/comments/140d9ha/why_does_python_run_an_entire_module_when_you/", "question": {"content": "Say I have two files.\n\n[hello.py](https://hello.py):\n\n    def foo():\n        print('i am foo')\n    \n    def bar():\n        print('i am bar')\n    \n    bar()\n\n&#x200B;\n\nand [world.py](https://world.py):\n\n    from hello import foo\n\nWhen I run the command, `python` [`world.py`](https://world.py) I didn't expect the `bar()` line to execute. I thought I'm just importing the `foo` function definition into the [world.py](https://world.py) file. Can anyone explain how and why this is happening?", "id": "140d9ha", "title": "Why does Python run an entire module when you only import one function from it?", "traffic_rate": 153.13037037037037}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "I'd say it's normal behaviour in Python and, by extension, MicroPython. Once a module is imported, it's added to the global module list and will not be imported again, even if the file itself has changed. Renaming the file makes you import it under the new name, so Python thinks it's a completely different module and adds it to the list. I assume here that the Pico is not reset before running a new project, which is weird, but not impossible and depends entirely on how the VS Code extension works. I know that Thonny forces a soft reset before running any file, probably to avoid some problems, including the one you're experiencing.\n\nI've never experience that Python does not recompile a library file that hac been modified. But I guess something else is happening here.   \n\n\nIf I disconnect and reconnect the RPI Pico, the changes appear.  \n\n\nBut thank you, horuable. \"I assume here that the Pico is not reset before running a new project\".   \n\n\nI tired:  \n* Change a library file (in root folder)\n* MicroPico: Reset > Soft\n* MicroPico: Upload project to Pico\n* VS Code: Run main project file\nWorks!\n\nQuite annoying though. And if this is the right way to do it, it should probably be documented MicroPico how-to-get-started..\n\nAFAIK Python never reloaded modules that were previously imported and always used the version that was already loaded in memory. There are ways to force reload, but they're exclusive to Python and don't work with MicroPython. Reconnecting Pico or resetting it clears the memory, so the module can be loaded again, with the changes that were made.\n\nAs for the documentation, RPi recommends using Thonny for MicroPython development, so I doubt they would be willing to add third party VS Code extension to their documentation.\n\nYes, you are quite right.  This is my first micropython project, so it just didn't occur to me that it wasn't starting \"from scratch\" each time I pressed play.   \n\n\nBut the way the system behaves, it all makes sense now. What I experienced as \"cached\" was just \"imported\" in a running python module.   \n\n\nJust a shame that the MicroPico didn't bundle this in one operation.   \n\n\nBut thank you both! I have a better understanding now.  :)", "id": "kp1w5bh", "owner_tier": 0.5, "score": 0.9999999980000001}, {"content": "I have used vs code micropico for over a year on raspberry pi and find it very stable and ideal for programming.  I have a similar scenario where I have supporting project files, and re-upload them when needed by running \u201cupload project to pico\u201d.  (Supporting files have been html and py files).  All works well. \n\nYou may want to ensure the supporting file types you want uploaded are standard and defined in micropico settings.  Also ensure the files are in the main project folder,  or in nested subfolders.\n\nCorrection: last sentence should read NOT in nested subfolder.", "id": "kp2kbki", "owner_tier": 0.1, "score": -1.999999987845058e-09}], "link": "https://www.reddit.com/r/raspberrypipico/comments/1ajlr85/micropico_for_vs_code_changing_library_files_dont/", "question": {"content": "When I change the main file, all updates take effect when I debug or run the code on my Raspberry Pi Pico.   \n\n\nBut when I change any of my library files, there is no change on the program running on my Pico. And I do use 'MicroPico: Upload project to Pico' before testing.   \n\n\nHowever, if I rename changed file from [mylib.py](https://mylib.py), to [mylib2.py](https://mylib2.py), save all referencing files, and then upload project to Pico, suddenly my changes take effect. \n\n&#x200B;\n\nAnyone else experiencing this?   \nIs there a fix? Or is this a bug I should report?\n\n&#x200B;\n\n*(Similar, but not the same question as* [*VS Code (Micropico) Workflow*](https://www.reddit.com/r/raspberrypipico/comments/174zrg7/vs_code_micropico_workflow/)*)*", "id": "1ajlr85", "title": "Micropico (for VS Code): Changing library files don't update", "traffic_rate": 8.432283464566929}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "[`collections` is also a standard Python module](https://docs.python.org/3.7/library/collections.html#module-collections), that's probably why.\n\nIf you inspect the collections module, it should become clear that it's not the one from your `collections.py` at first. `importlib` probably uses a different path resolution method for modules.\n\nIf you don't want to rename your module, you could investigate using a package so you could use relative imports.\n\nAh, that clears it up. Thanks!", "id": "ex98obh", "owner_tier": 0.1, "score": 0.9999999980000001}, {"content": "Hello! I'm a bot!\n\nIt looks to me like your post might be better suited for r/learnpython, \na sub geared towards questions and learning more about python. \nThat said, I am a bot and it is hard to tell.\nPlease follow the subs rules and guidelines when you do post there, it'll help you get better answers faster.\n\nShow /r/learnpython the code you have tried and describe where you are stuck. \n\nYou can also ask this question in the [Python discord](https://discord.gg/3Abzge7), \na large, friendly community focused around the Python programming language, open to those who wish to learn the language \nor improve their skills, as well as those looking to help others. \n\n\n\n***\n\n[^(README)](https://github.com/CrakeNotSnowman/redditPythonHelper) \n^(|)\n[^(FAQ)](https://github.com/CrakeNotSnowman/redditPythonHelper/blob/master/FAQ.md) \n^(|)\n^(this bot is written and managed by /u/IAmKindOfCreative) \n\n\n\n^(This bot is currently under development and experiencing changes to improve its usefulness)", "id": "ex94x4i", "owner_tier": 0.3, "score": -1.999999987845058e-09}], "link": "https://www.reddit.com/r/Python/comments/crtfps/why_are_my_imports_not_working_without_importlib/", "question": {"content": "I have three files - `models.py`, `tasks.py`, and `collections.py`. `tasks.py` imports the other two. It works just fine for the models file, but doesn't work for collections:\n    \n    import collections    \n    from models import FirstModel, SecondModel\n\n    # First / Second model can be used just fine, but accessing a variable from the collections file throws this: \n    # AttributeError: module 'collections' has no attribute 'COL_A' \n    \n\nHowever, if I use `importlib.reload`, it starts working fine:\n\n    import importlib\n    import collections\n    importlib.reload(collections)\n    \n    # collections.COL_A can be accessed normally.\n\nCan anyone help me understand what's happening here? Coming from the JS world, I've been scratching my head for the last half hour.", "id": "crtfps", "title": "Why are my imports not working without importlib?", "traffic_rate": 207.942496260595}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": ">does Python even require such a directive?\n\nNo, python rarely cares about things like this", "id": "go7jtli", "owner_tier": 0.3, "score": 0.6666666633333334}, {"content": "You don't need to worry about importing the same library multiple times.\n\nIt's done as efficiently as possible... (usually actually importing only once)\n\nI read that the garbage collection in Python was a non-issue as it is handled on the back end or something and the programmer will almost never have to even think about it. This led me to question whether multiple imports would be an issue.\n\nSo, even though I might import a library twice or more times just to make the code in separate modules work, the back end is smart enough to only import it once when the program is executed? Nice! One less thing to worry about!", "id": "go7jcic", "owner_tier": 0.7, "score": 0.6666666633333334}, {"content": "Each import creates something like a separate namespace, so you will never have to worry about this. It may use more RAM if something is imported twice, but if your module requires it and your main file also requires it, you have no choice so there's no point worrying about it.\n\n> It may use more RAM if something is imported twice\n\nThis is also something I eventually want to avoid. Perhaps I could refactor the text wrap code so that it doesn't require the library, or streamline it so it's not so bulky. The more I think about it, the more I believe someone already invented this wheel... I'm almost certain that there may be a separate library which handles pygame text operations...\n\nYou can import just the parts you want, for example\n\nfrom library import function\n\nI don't know if that reduces RAM usage, but worth investigating.\n\nHonestly if resources are that important Python is the wrong language anyway. An eight byte integer uses something like 28 bytes of RAM. There are things you can do to work more efficiently but you're just fighting the language when you could be using one that's better suited.\n\nI'm guessing you don't want to move away from python since you're using PyGame. If you know C or C++ you could write some helper code in those languages, and then use it in python via the ctypes module (or various other methods).", "id": "go7lb3i", "owner_tier": 0.7, "score": 0.9999999966666667}, {"content": "You may find [this importlib tutorial](https://realpython.com/python-import/) of interest.", "id": "go9h9ny", "owner_tier": 0.3, "score": -3.3333333130750966e-09}], "link": "https://www.reddit.com/r/learnpython/comments/losdq6/do_i_have_to_worry_about_importing_a_library/", "question": {"content": "SOLVED! (And then some)\n\nI'm experimenting with pygame, and I want to put a rather large function which handles text wrapping into its own file and import it into the main file. However, it also relies on pygame for the font objects. I am aware that in C and probably a few other languages there needs to be compiler directives such as \"#ifndef\" to prevent duplicate imports. Being an interpreted rather than compiled language, does Python even require such a directive?", "id": "losdq6", "title": "Do I have to worry about importing a library multiple times?", "traffic_rate": 153.13037037037037}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "For external modules like the google module you're talking about, the issue is the interpreter. If you always and forever want to use the same interpreter when you're using pycharm, you can [configure a system interpreter](https://www.jetbrains.com/help/pycharm/configuring-local-python-interpreters.html). This should make it so that your desired interpreter is always used as the base interpreter for any new projects. \n\nI don't know why re isn't importing as this module is a built in module. I guess it could be that a new project does not have an interpreter associated with it at all. In that case configuring the system interpreter should fix it. \n\nAlso, what system are you on and how do you manage your python versions?\n\nThank you! Good to know about the option to configure system interpreters.\n\nMy O/S is Win 10.  For this project I used 3.6 which I had installed after downloading from [python.org](https://python.org) just prior to the project.\n\nI was able to get the google module working again by switching the python version in project interpreter back to 3.6 - not sure why but it was set to 3.7 just now before I did that.  I also redid the pip-install google.\n\nThankfully re is importing again now, I'm not sure what it was that fixed that but I can get my code to execute again so all good.\n\nEdit: I think I figured out why Pycharm was stating that the modules were not defined.  Looking at File/Settings/Project/Python Interpreter I have multiple installations of Python 3.6 on my system.  As far as I can tell, the interpreter was updated to 3.7 somehow (I'm not sure how that happened).  Then when I changed to 3.6, I initially changed to the wrong one - i.e. one where the modules I needed were not present in the python folder in Windows.  By switching the python interpreter to the correct installation of python where the modules (e.g. the google module) are installed, I was able to execute my script without getting an error that modules are not defined.\n\nI'm still not sure why re was coming back as not defined though because as lanemik mentioned it is a built in module.\n\nI recommend learning about virtual environments. PyCharm will set one up for you super easily. You install every dependency you need on the virtual environment and things like updating python on your machine, or uninstalling an old version, won\u2019t break your production environment. \n\nBonus tip: keep track of every library you install (and the version!) in a text file, so if you ever share the application you can make sure changes between versions of your dependencies don\u2019t break your functionality!\n\nThanks for the great tip, yes I definitely need to do that because I think it's at the root of my module issues", "id": "i7xeoij", "owner_tier": 0.5, "score": 0.9999999980000001}], "link": "https://www.reddit.com/r/learnpython/comments/ult5g3/why_would_pycharm_fail_to_find_modules_that/", "question": {"content": "I'm an infrequent coder and am relatively new to Python.  I'm using Pycharm and have found importing modules to be one of the biggest 'casual user' pain points.\n\nAn issue that I'm facing currently is that code I wrote about a month ago which executed fine then won't execute now.  I'm getting errors stating that modules are not defined.  These modules are imported by global functions which are used in my script.  For example the re module and google module are supposedly not defined now even though I could import them without an issue last time I executed the script.\n\nI'm not sure why this is happening.  I haven't opened Pycharm since it worked about a month ago.  Perhaps Pycharm auto-updated in the interim though I'm not sure.\n\nAre there settings within Pycharm which I should configure to ensure nothing changes between (infrequent) uses?  For example, do I need to configure Pycharm not to auto-update which version of Python my projects use as interpreter?  Do people generally set Pycharm itself not to auto-update, or do you have to be on the lookout for updates it applies so that you can change your settings to fix stuff like the above?\n\nIn the current case one of my problems (Pycharm thinking the google module is not defined) was resolved by changing the Python interpreter for my project from 3.7 back to 3.6 in project settings.  I can't figure out why it thinks re isn't defined though.  When I open the global function which is importing re, the import works fine in that script.  When the calling script imports re directly that works fine.  It's just when it calls the global script, the re import within the global script doesn't work.", "id": "ult5g3", "title": "Why would Pycharm fail to find modules that previously imported without a problem?", "traffic_rate": 153.17222222222222}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "Regardless of how you import a module, the entire module is loaded into your program.\n\nThe variations in import statements determine how the names in the module are made available to your code.\n\nWhen you do something like `import time`, you must reference the contents of that module using the module name e.g. `time.time`.\n\nWhen you do like `from time import time` or `from time import *`, you can reference the same function as `time`, e.g. without the module name.\n\n>\t\u00a0from time import *\n\nPlease don\u2019t encourage people to do this. It\u2019s bad practice.\n\nDamn, I always just assumed it was about optimizing memory usage by picking individual classes!\n\nfrom * import *\n\nWhy?\n\nis it okay tho if you import your own module? for example:\n\n> from MyClasses import *\n\nthis way you can easily keep your classes in a separate file but also use them as if they're in the same file\n\nHey just wondering, why is this bad practice?\n\nfrom * import * as foo\n\nhttps://giphy.com/gifs/success-dem-u8u0R51ND9L2\n\nCan confirm after doing this my computer hates me now\n\nwildcard imports can result in name clashes that results in code that runs differently depending on which order the imports are imported\n\n    \u279c  cat a.py\n    def hello():\n        print('hello from a!')\n    \n    \u279c  cat b.py\n    def hello():\n        print('hello from b!')\n    \n    \u279c  cat run1.py\n    from a import *\n    from b import *\n    hello()\n    \u279c  cat run2.py\n    from b import *\n    from a import *\n    hello()\n    \u279c  python3 run1.py\n    hello from b!\n    \u279c  python3 run2.py\n    hello from a!\n\nas a user you have no idea where `hello` comes from. it's better to always quality your imports, either through using `libraryname.function()` or `from libraryname import function` so it's obvious where it came from", "id": "iaxf71s", "owner_tier": 0.3, "score": 0.999999999970238}, {"content": "you mean why they do `from module import x, y, z` instead of `import module`?\nBecause they don't care about the rest and if you do selective import you don't have to type in the module.\n\nor maybe you are asking why they don't import all modules every time?\n\nSo say I\u2019m importing flask. Usually I would do From flask import flask. Should I just do import flask?\n\n> Should I just do import flask?\n\nYou should do what is best for your situation.  Do you care about anything else in the top level `flask` package?\n\nIf not then you would just have to type `flask.flask` to use it instead of just `flask`.\n\nWhat makes more sense for your code?\n\nYou should import so that it remains obvious where the code you are running is located.\n\nFor example, `from flask import Flask`, when I use `Flask()` in my code, it's still pretty obvious that function belongs to the flask module. Similarly for things in the standard library: `randint()` and `permutations()`, as an example, are relatively unique and commonly known, so they can be assumed to be identifiable.\n\nHowever, is `sqrt()` from `math` or `numpy`? In this case, `import math; math.sqrt()` is probably more clear than `from math import sqrt; sqrt()`.\n\nAt the extreme end, consider modules that duplicate built-in functions: `from numpy import sum` now changes what happens when you call `sum()` in your code. As `sum()` is a builtin, very few readers are going to assume that a bare `sum()` call doesn't refer to the built in function. In this case I would say it's imperative that you call using the module name if using the numpy version.", "id": "iax7k4e", "owner_tier": 0.7, "score": 0.17857142854166666}, {"content": "personally I avoid importing things that are not modules, because I prefer to keep namespaces in my code. It makes it immediately clear that I am using a dependency.", "id": "iay4sgd", "owner_tier": 0.7, "score": 0.08035714282738095}, {"content": "To avoid polluting your namespace. \n\nLet\u2019s say moduleA has a function called doIt() that you intend to use. ModuleB also has a doIt() function, but you\u2019re using moduleB\u2019s doThisInstead() function. \n\nIf you import both modules, you\u2019ll have 2 functions named doIt() for no reason. Additionally, anytime you use either function you\u2019ll have to call it by entering moduleA.doIt(), which is a lot more to type out than doIt() potentially hundreds of times.\n\nThat won\u2019t pollute your namespace because you need the module\u2019s name to access everything in each case. Using from x import a actually creates this potential issue.\n\n    from x import a\n    from y import a\n\n    # access to x.a() is lost\n    a()\n\nI don't understand what you're saying. What import method are you advocating? If you did `import moduleA` and `import moduleB`, how does that pollute the namespace?\n\nBut this is why aliasing exists.\n\n    from x import a as x_a\n    from y import a as y_a\n\nYes, I agree; but the point is `import x` doesn't pullute the program's namespace.", "id": "iay5nl9", "owner_tier": 0.7, "score": 0.12202380949404762}, {"content": "Why don't I eat the whole cake? I don't need it and it could cause issues. It is delicious though...\n\nwhat issues would it cause?\n\nExcept you DO end up eating the whole cake regardless of how you import. That's the point both OP and top-upvoted answer is making.\n\nKeeping your code both readable and maintainable is an important consideration.\n1. If I'm trying to read the code, I have no idea where that function came from.\n2. If multiple modules have the same class or function name, I could (have) use the wrong one.", "id": "iazd5xa", "owner_tier": 0.5, "score": 0.05059523806547619}, {"content": "Huh.. Learn something new every day. I've been toying with Python for a while now and I always kind of assumed it was to save time/resources from loading entire modules by doing like \"from x import y\" instead of just \"import x\". Didn't realize it was loading the entire thing regardless. This may change how I do things in the future.", "id": "ib06ebr", "owner_tier": 0.3, "score": 0.035714285684523804}, {"content": "To add to the discussion: READABILITY. It can be helpful for somebody to explicitly import only the utilities of a module that they are going to use, so right off the bat I can know what to expect.\n\nAlso, if I see a bunch of imports from deep within a library, I know it's going to be doing some advanced things in the code below.\n\nLastly, if you ```from module import *``` from a library I don't know very well, I have to read the code much more slowly looking for functions I don't know the names of.", "id": "ib084nz", "owner_tier": 0.1, "score": 0.035714285684523804}, {"content": "Do you mean in every script?", "id": "iax1zp4", "owner_tier": 0.7, "score": 0.03273809520833333}, {"content": "Many libraries can use the same name for their functions.  You may call the function from the wrong lib if you import everything.  You\u2019d have to call them explicitly to avoid confusion", "id": "iaxps1w", "owner_tier": 0.5, "score": 0.03273809520833333}, {"content": "This is a good question actually. Sure, stuff like asyncio takes ages to load (comparatively), but whether or not you import math, time and/or random makes no practical difference when actually using the script, even if you don't need any of the functions. It's perhaps some psychological thing that makes people minimalist about stuff like this, to the point that they use linters to check for unused imports or get fuzzy over this in reviews. I guess one benefit of only ever importing what you need is documentation. \"import math?\" \"Ah, math stuff happens here\".\n\nIt doesn\u2019t make a difference anyways because when you import from a module the entire module is still loaded at run time, and the unused parts of the module are deleted. There\u2019s no time saving difference between \u201cfrom x import y\u201d and \u201cimport x\u201d. I usually prefer to import the entire module because it becomes more clear where you functions are coming from.\n\n> and the unused parts of the module are deleted.\n\nNothing in the imported module is deleted since it's very expensive to figure out what is \"unused\".\n\nI have been told that, I\u2019ve never fact checked it. From what I have been told though when you import a library all functions and classes of the library are loaded into memory. When you specify which ones you want, they\u2019re all loaded but then the unused ones are subsequently removed. If this is not true is there any way you can link me anything that shows that? I genuinely would love to see the inner workings\n\nThe import mechanism [is documented here](https://docs.python.org/3/reference/import.html), but that's hard to read.  Searching on \"python import mechanism\" gets hits but may not cover the subject in depth.\n\nApart from the difficulty of deciding which parts of a module are unused there is also a module caching mechanism.  Doing an import of a module a second time uses the cached module from the first import, speeding things up.  Deleting unused parts of a module would make module caching unworkable.  That would make code like this inefficient and slow due to multiple imports of the same module:\n\n    from math import sin    # so we don't have to use \"math.sin()\" a lot, just \"sin()\"\n    import math             # for all other little used functions", "id": "iaxk0tt", "owner_tier": 0.5, "score": 0.041666666636904756}, {"content": "maybe its a file they wrote and they know everything in it. other times, could be they'd rather get a direct reference to everything in a file. it can get confusing though if its over used. if you have a lot of code and do that for many modules it can be hard to tell where something came from. i think doing what you suggested is ideal, but in some circumstances, it might be worth it to do from module import etc", "id": "iaxknhv", "owner_tier": 0.3, "score": 0.029761904732142856}, {"content": "It's just easier that way, if you only need 1 specific part of the module, why not just type from genericpath import exists, instead of typing genericpath.exists 20 times or something..       \n         \nOr I'll do you one better you can just import it as whichever name you want, you can say from genericpath import exists as ex, then you could just type ex(path) to check if it's true or not, saves lots of typing, or sometimes makes it easier to understand what exactly it does.         \n         \nIt could also be that if you compile it for release, like as an exe with pyinstaller, and you package it as 1 file that maybe (I'm not sure about this one but I'm just guessing) it includes all the modules you import in your code, so it might result in a bigger than necessary binary if you just import everything (but again i never actually checked that so I'm just guessing)", "id": "iaye7pt", "owner_tier": 0.7, "score": 0.029761904732142856}, {"content": "You\u2019ve already gotten plenty of high-quality answers. So I\u2019ll just add - What\u2019s really gonna bake your noodle is when you see people doing things like this:\n\n    import numpy as np\n    from numpy import nan", "id": "iayxvgo", "owner_tier": 0.7, "score": 0.029761904732142856}, {"content": "Some common reasons are that you only need one small part of it and don\u2019t want to type it all out. \n\n    from getpass import getpass\n    from pprint import pprint\n\n    password = getpass()\n    pprint(thatdict)\n\nVs\n\n    import getpass\n    import pprint \n\n    password = getpass.getpass()\n    pprint.pprint(thatdict)\n\nIf there\u2019s only one class in a module that you need, it makes it easier to type and read. \n\nFor example, I work in networking and made a library called `nwtools`. Within it, I have classes for working with different platforms (mostly shortcuts for dealing with other libraries). If I\u2019m working on a script that only uses my Clearpass API module (`nwtools.cppm()`), I\u2019d `from nwtools import cppm` because I don\u2019t want to have to type out `nwtools.cppm` every time.\n\ncan still do with import wildcard\n\n`from x import *` is generally recommended against unless you *really* know the package. Very easy to have overlapping namespaces. \n\nPEP8 has this to say on it:\n\n>\tWildcard imports (from <module> import *) should be avoided, as they make it unclear which names are present in the namespace, confusing both readers and many automated tools. There is one defensible use case for a wildcard import, which is to republish an internal interface as part of a public API (for example, overwriting a pure Python implementation of an interface with the definitions from an optional accelerator module and exactly which definitions will be overwritten isn\u2019t known in advance).", "id": "iazccvs", "owner_tier": 0.9, "score": 0.035714285684523804}, {"content": "Odds are that if you\u2019re doing that then your eyes are bigger than your stomach.", "id": "iazj55m", "owner_tier": 0.3, "score": 0.029761904732142856}, {"content": "I think ive read importing individual functions or classes from a module cuts down on the time it takes for the program to call those functions/classes, and speeds up execution time. Please correct me if I'm mistaken", "id": "ib21u37", "owner_tier": 0.1, "score": 0.029761904732142856}, {"content": "Save working memory (RAM)", "id": "iax2us1", "owner_tier": 0.7, "score": -2.9761907224415804e-11}], "link": "https://www.reddit.com/r/learnpython/comments/v3akjc/why_dont_people_always_import_all_of_a_module/", "question": {"content": "why don't people always do \"import time\" or \"import random\"?", "id": "v3akjc", "title": "why don't people always import all of a module", "traffic_rate": 153.17222222222222}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "reddit"}, {"answers": [{"content": "\r\n    The only barrier between DLLs could be the access modifier internal. And even this barrier can be broken via reflection, but you don't need it at all.\n\r\nFirst of all, you should not think in terms of DLLs. The central modularity concept of .NET is assembly, and \"DLL\" is nothing but a file naming convention; as to the file itself, it's nothing but a module of an assembly. Strictly speaking, each assembly can be composed from several modules, more than one, but usually you deal with only single-module assemblies; this is what Visual Studio creates by default.\n\r\nIf you use several assemblies in your application, they all are reference each other to be loaded through the main application assembly, directly or not, you access things in exact same way as all code was in the same assembly, with only one difference: internal declarations make types and type member accessible between any types of the same assembly, but access across assemblies requires public or internal. Please see:\nAccess Modifiers (C# Programming Guide)[^],\nAccess Modifiers (C# Reference)[^],\nUnderstanding and Using Assemblies and Namespaces in .NET[^].\n\r\nThat's all. I don't think I need to cover reflection topics.\n\r\n[EDIT]\n\r\nI scratched out my sentence about reflection above after I read the comment quoted below.\n\nMember 11326763 wrote:\r\nI can't pass it from the main program , or call one dll from another one, because I only write the plugins (dll's) to the system.\r\nAnd each dll implement a complex module , and I can't mix between them (the dll's load by reflection in running mode) .\r\nSo if you have any elegant solution I will happy.If it comes to plug-ins, I have to cover approaches based on reflection. Please see my past answers on related topics, all referenced in this one: Access a custom object that resides in plug in dll[^].\n\r\nThese topics are relatively complicated, especially if you have a need to unload some plug-ins to reload different once; I hope you don't.\n\r\nOne alternative approach is using the Microsoft framework for extensibility, MEF:\nManaged Extensibility Framework \u2014 Wikipedia, the free encyclopedia[^],\nManaged Extensibility Framework \u2014 Home[^],\nManaged Extensibility Framework (MEF)[^].\n\r\nStarting with Visual Studio 2010 and .NET v.4, you don't need to download MEF from CodePlex, it is already bundled.\n\n\u2014SA\n", "id": "2_1075043_3", "owner_tier": 0.9, "score": 5.0}], "link": "https://www.codeproject.com/Questions/1075039/How-to-transfer-data-between-two-different-dlls-in", "question": {"content": "\r\n\t\t\t    Hello !\r\nI have 3 diffrent dll's that runinig in the same process in the same app domain.\r\nThe dll's are use as plugins for enterprise software that execute the dlls.\r\nThe dlls are running on the same machine.\r\nI can pass data from the enterprise software to the dlls but I can't pass data from one dll to the another.\r\nI can change the dlls but I cant merge between them.\r\nI can't make a change in the enterprise software.\r\nHow I can pass data from one dll to the another in running mode (I need to pass data in high freq).\r\nThanks\r\n\t\t    ", "id": "1075039", "title": "How to transfer data between two different dlls in the same app domain", "traffic_rate": 0}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "codeproject", "tags": ["C#"]}, {"answers": [{"content": "\r\n    I'm pretty late to this, but I have a real solution and can explain why!\n\r\nIt turns out that LocalReport here is using .NET Remoting to dynamically create a sub appdomain and run the report in order to avoid a leak internally somewhere. We then notice that, eventually, the report will release all the memory after 10 to 20 minutes. For people with a lot of PDFs being generated, this isn't going to work. However, the key here is that they are using .NET Remoting. One of the key parts to Remoting is something called \"Leasing\". Leasing means that it will keep that Marshal Object around for a while since Remoting is usually expensive to setup and its probably going to be used more than once. LocalReport RDLC is abusing this.\n\r\nBy default, the leasing time is... 10 minutes! Also, if something makes various calls into it, it adds another 2 minutes to the wait time! Thus, it can randomly be between 10 and 20 minutes depending how the calls line up. Luckily, you can change how long this timeout happens. Unluckily, you can only set this once per app domain... Thus, if you need remoting other than PDF generation, you will probably need to make another service running it so you can change the defaults. To do this, all you need to do is run these 4 lines of code at startup:\n\n\r\nLifetimeServices.LeaseTime = TimeSpan.FromSeconds(5);\r\nLifetimeServices.LeaseManagerPollTime = TimeSpan.FromSeconds(5);\r\nLifetimeServices.RenewOnCallTime = TimeSpan.FromSeconds(1);\r\nLifetimeServices.SponsorshipTimeout = TimeSpan.FromSeconds(5);\r\n\r\nYou'll see the memory use start to rise and then within a few seconds you should see the memory start coming back down. Took me days with a memory profiler to really track this down and realize what was happening.\n\r\nYou can't wrap ReportViewer in a using statement (Dispose crashes), but you should be able to if you use LocalReport directly. After that disposes, you can call GC.Collect() if you want to be doubly sure you are doing everything you can to free up that memory.\n\r\nHope this helps!\r\n", "id": "2_3132481_1", "owner_tier": 0.1, "score": 5.0}, {"content": "\r\n    Hi, I am able to come out with a workaround after many tests. I added below codes into my application and also app.config file:\n\n\r\n            rpvBaseReport.LocalReport.ExecuteReportInCurrentAppDomain(AppDomain.CurrentDomain.Evidence);           \r\nrpvBaseReport.LocalReport.AddTrustedCodeModuleInCurrentAppDomain(\"assembly name here\");\n\r\nAs for the app.config:\n\n\r\n<runtime>\r\n<NetFx40_LegacySecurityPolicy enabled=\"true\" />\r\n</runtime>\n\r\nAs whenever an event is fired(e.g. click on submit button to fetch data from db and render it into RDLC), a new instance will get created in a new app domain. Thus memory will keep on shoot up and although the resource will get released using proper codes(e.g. Dispose()), it will just get rid of the latest app domain while the previous app domains created will still be there in application cache. \r\nForcibly ask the RDLC to use only one app domain will prevent a new app domain from being created and thus reduce the memory usage and it will get released every time the form is closed.\r\nPlease feel free to correct me or add on any points that I have missed out. Thank you.\r\n", "id": "2_1213559_1", "owner_tier": 0.1, "score": 0}], "link": "https://www.codeproject.com/Questions/1213225/Memory-usage-shoot-up-when-using-RDLC", "question": {"content": "\r\n\t\t\t    Hi, I have a reporting RDLC designed for WinForms. I noticed whenever the RDLC is getting loaded with data, the memory will shoot up by approx. 20MB per request from database. Below are my scenario:\r\n1. Open up a winform with RDLC in it.\r\n2. Click submit button to trigger db call to get data.\r\n3. RDLC is loading ti display data.(this is where the memory started to shoot up by 20MB).\r\n4. Click again the submit button with same parameter, RDLC will reload again(memory shoot up by another ~20MB)\n\r\nI have cleared off any datasource prior RDLC load. Below are my codes:\n\n\r\nprotected Microsoft.Reporting.WinForms.ReportViewer rpvBaseReport;\n\n\r\nrpvBaseReport.ProcessingMode = ProcessingMode.Local;\r\nrpvBaseReport.LocalReport.SetBasePermissionsForSandboxAppDomain(new PermissionSet(PermissionState.Unrestricted));\r\nrpvBaseReport.LocalReport.DataSources.Clear();\r\n\r\nrpvBaseReport.LocalReport.DataSources.Add(reportDataSource);\r\n//further logic here\r\nrpvBaseReport.RefreshReport();\n\r\nAny idea would be welcomed. Thank you.\n\nWhat I have tried:\n\r\n1. Used Performance Profiler to track Memory Usage.\r\n2. Search internet for solution, have tried ReleaseSandBoxAppDomain(), Dispose() but to no avail.\r\n\t\t    ", "id": "1213225", "title": "Memory usage shoot up when using RDLC", "traffic_rate": 0}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "codeproject", "tags": ["C#", "RDLC"]}, {"answers": [{"content": "\r\n    No, you cannot do it, because all modules currently loaded for execution are protected by the OS from deletion or any modifications, by apparent reasons.\n\r\nHowever, you can do something similar. You can add an assembly to the currently running process if you load it using reflection. Removing/replacing such assembly is also possible, but this is much harder. There is no such functionality as \"unloading\" of any already loaded assembly. This is done for the purpose of reliability. It's hard to remove the assembly safely, because some other assemblies my still reference some objects in the assembly which is not needed anymore, and this is so hard detect that such functionality as unloading the assembly is not available in CLR.\n\r\nAt the same time, the assembly can be unloaded indirectly, if it is loaded in a separate Application Domain. You can unload the whole application domain, with all its assemblies. But it will make programming considerably harder, because Application Domains are isolated from each other as well as the processes; all objects live in separate isolated address spaces. Communication across application domain means using IPC. The class System.AppDomain provides simplified IPC facility which simplifies the communications, but this is still not quite trivial.\n\r\nI explained most of the detail relevant to such approach to programming in my past answers. I referenced them in this one: Access a custom object that resides in plug in dll[^].\n\n\u2014SA\n", "id": "2_1060457_2", "owner_tier": 0.9, "score": 5.0}, {"content": "\n \n\r\n Yes,sometimes necessary to replace a DLL with a newer version. Before replacing a DLL, perform a version check to ensure that you are replacing an older version with a newer version. It is possible to replace a DLL that is in use. The method you use to replace DLLs that are in use depends on the operating system you are using. On Windows XP and later, applications should use Isolated Applications and Side-by-side Assemblies.\r\n\r\nIt is not necessary to restart the computer if you perform the following steps:\r\n\r\n1.Use the MoveFileEx function to rename the DLL being replaced. Do not specify MOVEFILE_COPY_ALLOWED, and make sure the renamed file is on the same volume that contains the original file. You could also simply rename the file in the same directory by giving it a different extension.\r\n\r\n2.Copy the new DLL to the directory that contains the renamed DLL. All applications will now use the new DLL.\r\n\r\n3.Use MoveFileEx with MOVEFILE_DELAY_UNTIL_REBOOT to delete the renamed DLL.\r\n\r\nNOTE : Before you make this replacement, applications will use the original DLL until it is unloaded. After you make the replacement, applications will use the new DLL. When you write a DLL, you must be careful to ensure that it is prepared for this situation, especially if the DLL maintains global state information or communicates with other services. If the DLL is not prepared for a change in global state information or communication protocols, updating the DLL will require you to restart the computer to ensure that all applications are using the same version of the DLL.\n\n[Reference^]\r\n", "id": "2_1060452_2", "owner_tier": 0.1, "score": 1.0}], "link": "https://www.codeproject.com/Questions/1060437/Is-it-possible-to-replace-net-dll-file-while-clien", "question": {"content": "\r\n\t\t\t    I copied one .net dll file to my server and every client want to register that dll with the same path using regasm /codebase example.dll. now everything working fine but sometimes i want to do some modification in this dll so i am trying to replace that dll but i cannot do it. always it says \"The action can't be completed because the folder or a file in it is open in another program\" message. i think some clients are using this application while i am updating it so please help me to solve this problem.\r\nNote: I don't want to close application that which is using by my clients. means without closing application i want to do this.\r\n\t\t    ", "id": "1060437", "title": "Is it possible to replace .net dll file while client using it?", "traffic_rate": 0}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "codeproject", "tags": ["C#"]}, {"answers": [{"content": "\r\n    That's because your code is hogging the UI (startup) thread. While the UI thread is busy running your code it cannot process the application message pump and cannot repaint anything, including your label.\n\r\nYou have to move your work to a background thread, a Task or BackgroundWorker. This will free up the UI thread to maintain the UI. Your background code has to marshal called back to the UI thread to update things like your label.\n\r\nSomething like this[^].\r\n", "id": "2_1151036_1", "owner_tier": 0.7, "score": 2.5}, {"content": "\r\n    use Application.DoEvents Method (System.Windows.Forms)[^] \nC#\n\r\n TextBox.Text = s;\r\nApplication.DoEvents();\n", "id": "2_1152198_1", "owner_tier": 0.3, "score": 2.25}, {"content": "\r\n    For this type of thing, perhaps another thread is overkill. Look at adding a timer to the form, that fires at an interval of 1 second. That way, you are still on the UI thread when it is activated, so yu don't need to marshal the setting of the label text, and you don't need to do any Sleep calls to delay proceeding, as the call is only fired at the selected interval.\r\n", "id": "2_1151523_1", "owner_tier": 0.3, "score": 3.0}, {"content": "\r\n    I found another solution on the internet and am posting it here in case anyone is interested.  I created a Label on the WinForm and named it LabelBox.  The following code worked to output the number as it changed between sleeps.\n\nC#\n\r\namespace First_WinFormsTest\r\n{\r\n\r\n    public partial class Form1 : Form\r\n\r\n    {\r\n        public Form1()\r\n        {\r\n            InitializeComponent();\r\n            Thread t = new Thread(new ThreadStart(ChangeLabel));\r\n            t.Start();\r\n        }\r\n        private void ChangeLabel()\r\n        {\r\n            for (int i=0; i<20; i++)\r\n            {\r\n                SetLabelText(i);\r\n                Thread.Sleep(1000);\r\n\r\n            }\r\n        }\r\n        private delegate void SetLabelTextDelegate(int number);\r\n        private void SetLabelText( int number)\r\n        {\r\n            if (this.InvokeRequired)\r\n            {\r\n                this.BeginInvoke(new SetLabelTextDelegate(SetLabelText), new object[] { number});\r\n                return;\r\n            }\r\n            LabelBox.Text = number.ToString();\r\n        }\r\n    }\r\n}\n", "id": "2_1151486_1", "owner_tier": 0.1, "score": 1.0}], "link": "https://www.codeproject.com/Questions/1151034/Update-a-label-while-running", "question": {"content": "\r\n\t\t\t    I am building a simple real time app to test a GPS module using WinForms.  I would like to send current data from the GPS to a label or text box continuously to validate performance.  I have tried a simple program to test how to do this, shown below:\n\nC#\n\r\n    public partial class Form1 : Form\r\n    {\r\n        public Form1()\r\n        {\r\n            int i;\r\n            string s;\r\n            InitializeComponent();\r\n            for (i=0; i<20; i++)\r\n            {\r\n                s = String.Format(\"Curent value of i {0}\", i);\r\n                //                FirstLabel.Text = \"This is a test\";\r\n                FirstLabel.Text = s;\r\n                FirstLabel.Refresh();\r\n\r\n                TextBox.Text = s;\r\n                TextBox.Refresh();\r\n                \r\n                \r\n                Thread.Sleep(1000);\r\n             \r\n            }\r\n//            FirstLabel.Text = \"This is a test\";\r\n//            Thread.Sleep(1000);\r\n//            FirstLabel.Text = \"Hello World\";\r\n        }\n\r\nWhen I do this the winform screen only shows up after the loop is complete with the last string i=19 displayed.  What I want to happen is to display the winform continuously and have the contents of the boxes increment from 0 to 19 once each second.  I have looked through a lot of posts and thought the TextBox.Refresh(); would to the trick but evidently not.  Should be really simple but I can't figure out what to do.  Any help would be greatly appreciated.\n\nWhat I have tried:\n\r\nWhat I have tried described above.\r\n\t\t    ", "id": "1151034", "title": "Update a label while running", "traffic_rate": 0}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "codeproject", "tags": ["C#"]}, {"answers": [{"content": "\r\n    I thought of a very easy work-around that might work for others. My underlying problem was due to how Windows caches the icons of application shortcuts. This was preventing me from changing the taskbar icon at runtime. Which is certainly possible. So instead of having the start shortcut pointing directly at the main application exe, I am pointing the shortcut to a launcher application that shells out to the main application. This way, the main application exe is never launched from a shortcut. Thus, the icon on the taskbar can be changed at runtime. This is working very well for me.\r\n", "id": "2_600060_1", "owner_tier": 0.1, "score": 3.0}, {"content": "\r\n    I am having the exact same issue but I never realized that it was happening because of a \"Shortcut\". I noticed this behavior when I would pin my application to the windows 10 task bar. If I don't pin the application, I can simply change the taskbar icon by using {this.Icon = new Icon(\"my icon path\")} and it works as expected. Once I pin the application, the icon will not change. As the original poster mentioned, this also seems to happen if you create a shortcut to the application (and not pin it to the taskbar). \n\r\nNone of the proposed solutions above seem to actually solve the issue and the \"chosen solution\" was a hack of a work around by someone who was in desperate need of a solution but was not offered any.\n\r\nUnfortunately this is also not a solution but I am attempting to revive this issue as it is still unresolved but the original poster has made a connection that could be key to solving this (a shortcut to the application prevents the taskbar icon from changing).\n\r\nThere also seems to be some unhelpful comments by a few individuals claiming that this has been solved, which it hasn't (only a workaround provided by the original poster), or that it's impossible, which it isn't since there are many examples of applications that change the taskbar icon as a form of notification (outlook when you have unread emails or express vpn when you are connected to a VPN).\n\r\nThe issues as far as I can tell revolves specifically around windows behavior when a shortcut to an application exists (or pinned to taskbar which I assume is creating a shortcut somewhere). Without the shortcut, it is very much possible for the taskbar icon to be changes as I mentioned above.\n\r\nIs anyone familiar enough with this specific windows behavior to help overcome this challenge?\r\n", "id": "2_5295661_1", "owner_tier": 0.1, "score": 0}, {"content": "\r\n    Please see my comment to the question. Why?\n\r\nNow, just some notes. The form icon is a different thing, you can really change it easily during runtime. It may even make some sense (different mode of operation, different part of functionality). The icon shown in the Taskbar is a different thing, it is called application icon. As OS uses it, it should be stored in the PE module (file) in some universal way, not specific to .NET. The application icon is actually build in application manifest. For an assembly, this is stored in a module, the one holding an application manifest for the assembly. (Visual Studio supports only creation of the assembles with one module per assembly, but compiling on lower level will allow you to have more then one per assembly, but only one of them will hold the manifest; it's called \"main assembly module\".)\n\r\nThe MSBuild uses the icon file in this build step: http://msdn.microsoft.com/en-us/library/microsoft.build.tasks.generateapplicationmanifest.aspx[^].\n\r\nThat said, unlike the form icon, this icon is readonly. And, as you should know, the executable module loaded for execution cannot be modified, no matter how high your permissions are. This is an important protection feature of most modern OS.\n\r\nAnd even if you could change this icon by some means (no, I don't think it's possible), it would defeat the purpose of them. OS controls rely on this icon to keep your application well-recognizable; it would not get any notifications if you could change it, because this is not how things are designed.\n\n\u2014SA\n", "id": "2_600042_1", "owner_tier": 0.9, "score": 1.0}, {"content": "\r\n    Application won't show you taskbar in runtime until you have any shortcuts to it.\r\nIf you get rid of all shortcuts and run from Runtime folder, it will work fine...\r\nBut this is not what we need.\n\r\nnobody anywhere didn't provide for solution what... what a shame....\r\n", "id": "2_5272646_1", "owner_tier": 0.1, "score": 0.5}], "link": "https://www.codeproject.com/Questions/600037/Changeplusiconplusdisplayedplusinplustaskbarplusat", "question": {"content": "\r\n\t\t\t    I have a Windows 7 application where I need to change the icon displayed on the main form and the icon that is displayed by Windows on the taskbar at runtime.  \n\r\nIn code I am simply changing the Form.Icon property and this works no problem if I run the app from the EXE.  The icon changes in the form and on the taskbar no problem. \n\r\nHowever, if I run the app from a desktop shortcut the icon only changes in the main form and the icon shown on the taskbar never changes.  Apparently Windows is loading the taskbar icon from a cache. The only suggestions I can find on how to refresh the cached taskbar icon are to delete the iconcache and then restart windows.  This solution obviously will not work for changing the icon at runtime.\n\r\nDoes any one know how change the taskbar icon at runtime for an app launched via a desktop shortcut???  I am guessing there are some api functions that will work, but I cannot figure it out.\r\n\t\t    ", "id": "600037", "title": "Change icon displayed in taskbar at runtime", "traffic_rate": 0}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "codeproject", "tags": ["Windows", ".NET", "Win7", "icon"]}, {"answers": [{"content": "\r\n    We can't tell - we do not know what you did last time it worked to stop it working.\r\nHowever, you can try adding it back in: Right click the solution in the Solution explorer, and select \"Add...Existing Project\". Follow the dialogs to put your project back in the solution.\r\n", "id": "2_523695_1", "owner_tier": 0.9, "score": 2.5}, {"content": "\r\n    right click on solutions files in solution explorer and right click then choose reload project. it will recover old files\r\n", "id": "2_523706_2", "owner_tier": 0.1, "score": 0.4090909090909091}, {"content": "\r\n    The most common cause I've seen of this issue is failing to run Visual Studio in administrator mode. Many projects, such as websites, require admin mode to load.\r\n", "id": "2_5320574_1", "owner_tier": 0.1, "score": 0}, {"content": "\r\n    close application then delete .vs file and reopen the visual studio\r\n", "id": "2_5292765_2", "owner_tier": 0.1, "score": 0.3475}, {"content": "\r\n    In my case, run visual studio in admin mode solved it.\r\nApparently, I was earlier running VS in admin mode to allow \"attach to process\" while running local IIS\r\n", "id": "2_5164916_1", "owner_tier": 0.1, "score": 0.4366666666666667}, {"content": "\r\n    you also open your project from the documents where the window application is saved ,i think if you run the application from the document then vs2010 and then the winform something u will be able to recover all the files!!!\r\n", "id": "2_523701_2", "owner_tier": 0.1, "score": 0.5}, {"content": "\r\n    Change the name of the folder back to what it was, and then it will work.\r\n", "id": "2_5254680_1", "owner_tier": 0.1, "score": 1.0}, {"content": "\r\n    I got the same problem. Before the project become unloaded I had another error about file name. A word file it read had a very long name and the error was like \"file name can not be longer than 260 characters.\" Because of this error I couldn't open my controller classes etc. \r\nThe word file was in temp folder and I deleted it then I had to do nothing but open the project again.\r\n", "id": "2_5297172_1", "owner_tier": 0.1, "score": 0.5}], "link": "https://www.codeproject.com/Questions/523582/solutionplusfilepluswasplusunloaded", "question": {"content": "\r\n\t\t\t    i opened my windows application solutions file at today morning its showing the project file was unloaded in the solution explorer ., but it was working fine till yesterday night., now what happened why i am getting this error now i am unable to open my project please help me out\r\n\t\t    ", "id": "523582", "title": "Project file was unloaded", "traffic_rate": 0}, "saved_time": "Tue, 16 Jul 2024 04:00:34 GMT", "source": "codeproject", "tags": ["VS2008", "Visual-Studio"]}]}